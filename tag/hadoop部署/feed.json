{
    "version": "https://jsonfeed.org/version/1",
    "title": "艾瑞可erik • All posts by \"hadoop部署\" tag • All posts by \"undefined\" categories",
    "description": "一只PHP开发的程序猿，偶尔做做运维、Goland、Python、Java、摄影、画画、写作、顺便睡觉，反正整站都搞过。",
    "home_page_url": "https://erik.xyz",
    "items": [
        {
            "id": "https://erik.xyz/2017/06/29/hadoop2-8-0-de-bu-shu-an-zhuang-jiao-cheng/",
            "url": "https://erik.xyz/2017/06/29/hadoop2-8-0-de-bu-shu-an-zhuang-jiao-cheng/",
            "title": "hadoop2.8.0的部署安装教程",
            "date_published": "2017-06-29T00:27:00.000Z",
            "content_html": "<p>Hadoop部署准备 本地vmware安装 Linux系统家族中 centos7 下载地址<a href=\"http://101.110.118.58/isoredirect.centos.org/centos/7/isos/x86\\_64/CentOS-7-x86\\_64-Minimal-1611.iso\">http://101.110.118.58/isoredirect.centos.org/centos/7/isos/x86\\_64/CentOS-7-x86\\_64-Minimal-1611.iso</a>   Java对应版本1.8.0_121   Hadoop版本2.8.0下载地址 <a href=\"http://mirror.bit.edu.cn/apache/hadoop/common/\">http://mirror.bit.edu.cn/apache/hadoop/common/</a> 可以根据自己喜好的版本下载</p>\n<h1 id=\"1-基本配置\"><a href=\"#1-基本配置\" class=\"headerlink\" title=\"1.基本配置\"></a>1.基本配置</h1><p>首先安装一个centos7并配置好java Java环境配置 我的java安装地址 /usr/java/ jdk1.8.0_121   编辑java环境 vi ~/.bash_profile 添加或修改 export JAVA_HOME=/usr/java/jdk1.8.0_121 export PATH=$JAVA_HOME/bin:$PATH 执行 . ~/.bash_profile 使变量生效  <span id=\"more\"></span></p>\n<h1 id=\"2-ssh配置\"><a href=\"#2-ssh配置\" class=\"headerlink\" title=\"2.ssh配置\"></a>2.ssh配置</h1><p>先 yum install ssh  安装   然后执行 ssh-keygen -t dsa -P ‘’ -f ~/.ssh/id_dsa 生成密匙</p>\n<h1 id=\"3-hadoop配置\"><a href=\"#3-hadoop配置\" class=\"headerlink\" title=\"3.hadoop配置\"></a>3.hadoop配置</h1><p>把下载好的hadoop解压出来。（我的地址在/roo目录,即完整地址/root/hadoop）   配置环境变量 vi ~/.bash_profile export HADOOP_HOME=/root/hadoop export PATH=$JAVA_HOME/bin:$PATH:$HOME/bin:$HADOOP_HOME/bin 执行 . ~/.bash_profile 使变量生效  </p>\n<h1 id=\"4-hadoop文件配置\"><a href=\"#4-hadoop文件配置\" class=\"headerlink\" title=\"4.hadoop文件配置\"></a>4.hadoop文件配置</h1><p>首先给本机命名个名字：例如我这边是s204   就执行 hostnamectl set-hostname s204 变更主机名字   然后在/root/hadoop目录下 依次执行编辑</p>\n<h2 id=\"vim-etc-hadoop-core-site-xml\"><a href=\"#vim-etc-hadoop-core-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/core-site.xml\"></a>vim etc/hadoop/core-site.xml</h2><p>  在<configuration></configuration>中加入 <property> <name>fs.defaultFS</name> <value>hdfs://s204:9000</value> </property> <property> <name>hadoop.tmp.dir</name> <value>file:/root/hadoop/tmp</value> </property> <property> <name>io.file.buffer.size</name> <value>131702</value> </property> <property> <name>hadoop.proxyuser.hadoop.hosts</name> <value>*</value> </property>   <property> <name>hadoop.proxyuser.hadoop.groups</name> <value>*</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-hdfs-site-xml\"><a href=\"#vim-etc-hadoop-hdfs-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/hdfs-site.xml\"></a>vim etc/hadoop/hdfs-site.xml</h2><p>在<configuration></configuration>中加入   <property> <name>dfs.namenode.name.dir</name> <value>file:/root/hadoop/hdfs/name</value> </property> <property> <name>dfs.datanode.data.dir</name> <value>file:/root/hadoop/hdfs/data</value> </property> <property> <name>dfs.replication</name> <value>3</value> </property> <property> <name>dfs.namenode.secondary.http-address</name> <value>s204:9001</value> </property> <property> <name>dfs.webhdfs.enabled</name> <value>true</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-mapred-site-xml\"><a href=\"#vim-etc-hadoop-mapred-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/mapred-site.xml\"></a>vim etc/hadoop/mapred-site.xml</h2><p>在<configuration></configuration>中加入   <property> <name>mapreduce.framework.name</name> <value>yarn</value> </property> <property> <name>mapreduce.jobhistory.address</name> <value>s204:10020</value> </property> <property> <name>mapreduce.jobhistory.webapp.address</name> <value>s204:19888</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-yarn-site-xml\"><a href=\"#vim-etc-hadoop-yarn-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/yarn-site.xml\"></a>vim etc/hadoop/yarn-site.xml</h2><p>在<configuration></configuration>中加入 <property> <name>yarn.nodemanager.aux-services</name> <value>mapreduce_shuffle</value> </property> <property> <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name> <value>org.apache.hadoop.mapred.ShuffleHandler</value> </property> <property> <name>yarn.resourcemanager.address</name> <value>s204:8032</value> </property> <property> <name>yarn.resourcemanager.scheduler.address</name> <value>s204:8030</value> </property> <property> <name>yarn.resourcemanager.resource-tracker.address</name> <value>s204:8031</value> </property> <property> <name>yarn.resourcemanager.admin.address</name> <value>s204:8033</value> </property> <property> <name>yarn.resourcemanager.webapp.address</name> <value>s204:8088</value> </property> <property> <name>yarn.nodemanager.resource.memory-mb</name> <value>6078</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-yarn-env-sh\"><a href=\"#vim-etc-hadoop-yarn-env-sh\" class=\"headerlink\" title=\"vim etc/hadoop/yarn-env.sh\"></a>vim etc/hadoop/yarn-env.sh</h2><p>  中找到 export JAVA_HOME 去掉注释 编辑java地址 export JAVA_HOME=/usr/java/jdk1.8.0_121   找到JAVA_HEAP_MAX=-Xmx1000m 改为 JAVA_HEAP_MAX=-Xmx1024m  </p>\n<h2 id=\"vim-etc-hadoop-slaves\"><a href=\"#vim-etc-hadoop-slaves\" class=\"headerlink\" title=\"vim etc/hadoop/slaves\"></a>vim etc/hadoop/slaves</h2><p>  清空添加 s204    </p>\n<h1 id=\"网络配置\"><a href=\"#网络配置\" class=\"headerlink\" title=\"网络配置\"></a>网络配置</h1><p>我这ip是 192.168.5.9   编辑网络固定ip vim /etc/sysconfig/network-scripts/ifcfg-ens33   指定固定ip   TYPE=”Ethernet” #BOOTPROTO=”dhcp” DEFROUTE=”yes” PEERDNS=”yes” PEERROUTES=”yes” IPV4_FAILURE_FATAL=”no” IPV6INIT=”yes” IPV6_AUTOCONF=”yes” IPV6_DEFROUTE=”yes” IPV6_PEERDNS=”yes” IPV6_PEERROUTES=”yes” IPV6_FAILURE_FATAL=”no” IPV6_ADDR_GEN_MODE=”stable-privacy” NAME=”ens33” UUID=”b9fe1e5c-be20-47f1-a2d3-e12f5ddb6aa1” DEVICE=”ens33” ONBOOT=”yes” IPADDR0=192.168.5.9 PREFIX0=24 GATEWAY0=192.168.5.2 DNS1=114.114.114.114   然后重启网络 systemctl  restart  network   执行 ip add  查看网络ip是否和设定的一致  </p>\n<h1 id=\"Hadopp启动\"><a href=\"#Hadopp启动\" class=\"headerlink\" title=\"Hadopp启动\"></a>Hadopp启动</h1><p>  进入/root/hadoop目录   执行编译 ./bin/hdfs namenode –format   结果倒数第五行出现 Exiting with status 0 则为成功   然后启动 ./sbin/start-all.sh   启动完毕执行./bin/hdfs dfsadmin –report 查看是否有节点 如果返回 无法连接则为启动失败   执行systemctl stop firewalld.service关闭防火墙  在浏览器输入s204:8088则可以看到hadoop界面  </p>\n<h1 id=\"其他节点配置\"><a href=\"#其他节点配置\" class=\"headerlink\" title=\"其他节点配置\"></a>其他节点配置</h1><p>以上配置完毕后，关闭centos7 然后完全克隆，在新克隆的系统中，更改ip地址和主机名 其中hadoop配置文件 etc/hadoop/hdfs-site.xml  中 <property> <name>dfs.datanode.data.dir</name> <value>file:/root/hadoop/hdfs/data</value> </property>   的file地址不能一样。 我这边三个地址分别为 file:/root/hadoop/hdfs/data file:/root/hadoop/hdfs/data/205 file:/root/hadoop/hdfs/data/206   克隆完毕，配置文件和ip、主机名修改好后。在s204机器中编辑 vim etc/hadoop/slaves 加入 s205 s206   复制ssh令牌免密登录 例如复制到s205 scp ~/.ssh/authorized_keys root@s205:~/.ssh/   其他另个机器也一样操作   另外几个机器也要编译一下   然后在s204停止hadoop   ./sbin/stop-all.sh   再次启动./sbin/start-all.sh   在浏览器就可以看到三个节点。</p>\n",
            "tags": [
                "hadoop",
                "hadoop2.8.0",
                "hadoop安装教程",
                "hadoop安装详细教程",
                "hadoop教程",
                "hadoop部署"
            ]
        }
    ]
}