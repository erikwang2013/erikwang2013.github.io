{
    "version": "https://jsonfeed.org/version/1",
    "title": "艾瑞可erik • All posts by \"mysql\" tag • All posts by \"undefined\" categories",
    "description": "一只PHP开发的程序猿，偶尔做做运维、Goland、Python、Java、摄影、画画、写作、顺便睡觉，反正整站都搞过。",
    "home_page_url": "https://erik.xyz",
    "items": [
        {
            "id": "https://erik.xyz/2024/11/11/mysql-redis-consistency/",
            "url": "https://erik.xyz/2024/11/11/mysql-redis-consistency/",
            "title": "如何下保证MySQL数据库与Redis缓存数据一致性？",
            "date_published": "2024-11-11T01:58:00.000Z",
            "content_html": "<p>有时候感觉MySQL我们懂了，Redis我们懂了，但是面试的时候一直答不好，经常被难住，问题在哪呢？</p>\n<p>答案是：面试官考的不是专项能力，而是多项技术结合应用能力。</p>\n<p>就拿<strong>并发场景下如何保证MySQL与Redis缓存一致性？</strong>这个面试官常见的拷打考点举例。</p>\n<p>对于读多写少并且要求高性能的业务逻辑，我们通常在应用服务器访问MySQL数据库的中间加上一层<strong>Redis缓存层</strong>，以提高数据的查询效率，减轻MySQL数据库的压力，避免在MySQL出现性能瓶颈。<br><span id=\"more\"></span><br><img src=\"/img/2024/2024111101.png\" alt=\"https://erik.xyz\"></p>\n<p>该问题，如果在数据存储后，只读场景下是不会出现MySQL与Redis缓存的一致性问题的，所以真正需要考虑的是<strong>并发读写场景</strong>下的数据一致性问题。</p>\n<p>如果我们不加分析，单独利用MySQL和Redis的知识进行回答并发场景下如何保证MySQL与Redis缓存一致性？很难把这个问题回答好，因为看起来很简单的方案实际上是漏洞百出的。</p>\n<h4 id=\"简单方案下的漏洞百出\"><a href=\"#简单方案下的漏洞百出\" class=\"headerlink\" title=\"简单方案下的漏洞百出\"></a>简单方案下的漏洞百出</h4><p>我们先看下简单的更新数据库、删除缓存和更新缓存方案下，会出现什么问题？</p>\n<p><img src=\"/img/2024/2024111102.png\" alt=\"https://erik.xyz\"></p>\n<h4 id=\"更新缓存，再更新数据库\"><a href=\"#更新缓存，再更新数据库\" class=\"headerlink\" title=\"更新缓存，再更新数据库\"></a>更新缓存，再更新数据库</h4><p>先说结论：不考虑。</p>\n<p>原因是更新缓存成功后，数据库可能更新失败，出现数据库为旧值，缓存为新值。导致后续的所有的读请求，在缓存未过期或缓存未重新正确更新的情况下，会一直保持了数据的完全不一致！并且当前数据库中的值为旧值，而业务数据的正确性应该以数据库的为准。</p>\n<p>那么如果更新缓存成功后，数据库可能更新失败，我们<strong>重新更新缓存</strong>是不是可以了？</p>\n<p><img src=\"/img/2024/2024111103.png\" alt=\"https://erik.xyz\"></p>\n<p>抛开需要重新更新缓存时，要单表或多表重新查询数据，再更新数据带来的性能问题，还可能期间有数据变更再次陷入脏数据的情况。实际上仍然还是会出现并发一致性问题。</p>\n<p>只要缓存进行了更新，后续的读请求<strong>在更新数据库前、更新数据库失败并准备更新缓存前</strong>，基本上都能命中缓存情况，而这时返回的数据都是未落库的脏数据。</p>\n<p><img src=\"/img/2024/2024111104.png\" alt=\"https://erik.xyz\"></p>\n<h4 id=\"更新数据库，再更新缓存\"><a href=\"#更新数据库，再更新缓存\" class=\"headerlink\" title=\"更新数据库，再更新缓存\"></a>更新数据库，再更新缓存</h4><p>不考虑。</p>\n<p>原因是当数据库更新成功后，缓存更新失败，出现数据库为最新值，缓存为旧值。导致后续的所有的读请求，在缓存未过期或缓存未重新正确更新的情况下，会一直保持了数据的完全不一致！</p>\n<p><img src=\"/img/2024/2024111105.png\" alt=\"https://erik.xyz\"></p>\n<p>该方案就算在更新数据库、更新缓存都成功的情况下，还是会存在并发引发的一致性问题，如下图所示（点击图片查看大图）：<br><img src=\"/img/2024/2024111106.png\" alt=\"https://erik.xyz\"></p>\n<p>可以看到在并发多写多读的场景下数据存在的不一致性问题。</p>\n<h4 id=\"先删除缓存，再更新数据库\"><a href=\"#先删除缓存，再更新数据库\" class=\"headerlink\" title=\"先删除缓存，再更新数据库\"></a>先删除缓存，再更新数据库</h4><p>不考虑，但是通过使用<strong>延时双删策略</strong>后可以考虑。</p>\n<p>采用“<strong>先删除缓存，再更新数据库</strong>”的方案是一种常见的方法来尝试解决这个问题的策略。</p>\n<p>这种方法逻辑较为简单，易于理解和实现，理论上删除旧缓存后，下次读取时将从数据库获取最新数据。</p>\n<p>但在并发的极端情况下，删除缓存成功后，如果再有大量的并发请求进来，那么便会直接请求到数据库中，对数据库造成巨大的压力。而且此方案还是可能会发生数据不一致性问题。</p>\n<p><img src=\"/img/2024/2024111107.png\" alt=\"https://erik.xyz\"></p>\n<p>通过上图发现在删除缓存后，如果有并发读请求1.1进来，那么查询缓存肯定是不存在，则去读取数据库，但因为此时更新数据库x=10的操作2.更新数据库还未完成，所以读取到的仍然是旧值x=5并设置缓存后，在2.更新数据库完成后，数据是新值10，而缓存是旧值，造成了数据不一致的问题。</p>\n<p>对此我们可以先进行一波的小优化，那就是<strong>延时双删策略</strong>。即在更新数据库之后，先延迟等待一下（等待时间参考该读请求的响应时间+几十毫秒），再继续删除缓存。这样做的目的是确保读请求结束（已经在1.2读库中读取到了旧数据，后续会在该请求中更新缓存），写请求可以删除读请求造成的缓存脏数据，保证再删除缓存之后的所有读请求都能读到最新值。</p>\n<p><img src=\"/img/2024/2024111108.png\" alt=\"https://erik.xyz\"></p>\n<p>可以看出此优化方案关键点在于等待多长时间后，再次删除缓存尤为重要，但是这个时间都是根据历史查询请求的响应时间判断的，实际情况会有浮动。这也导致如果等待的延时时间过短，则仍然会出现数据不一致的情况；等待延迟时间过长，则导致延迟期间出现数据不一致的时间变长。</p>\n<p>另外<strong>延时双删策略</strong>还需要考虑如果再次删除缓存失败的情况如何处理？</p>\n<p>因为删除失败将导致后续的所有的读请求，在缓存未过期或缓存未重新正确更新的情况下，会一直保持了数据的完全不一致！这个在下文的技术优化方案继续讨论。</p>\n<h4 id=\"先更新数据库，再删除缓存\"><a href=\"#先更新数据库，再删除缓存\" class=\"headerlink\" title=\"先更新数据库，再删除缓存\"></a>先更新数据库，再删除缓存</h4><p>比较推荐。</p>\n<p>采用的“先更新数据库，再删除缓存”策略，跟“先删除缓存，再更新数据库”中我们进行<strong>延时双删策略</strong>的小优化基本一样，仍然需要考虑删除缓存失败的情况如何处理。</p>\n<p>单纯从“先更新数据库，再删除缓存”和“先删除缓存，再更新数据库”对比起来。在大多数情况下，“先更新数据库，再删除缓存”被认为是一个更好的选择，原因如下：</p>\n<p>1.<strong>数据的一致性</strong>：这种方法更倾向于保持数据的最终一致性，即使缓存删除失败，也能保证数据的一致性不会长期受损。</p>\n<p>2.<strong>用户体验</strong>：在“先删除缓存，再更新数据库”的情况下，如果数据库更新失败，用户可能会一直看到旧数据，直到缓存过期。相比之下，“先更新数据库，再删除缓存”可以在某种程度上避免这种情况。</p>\n<p>但该方案同样也会出现数据不一致性问题，如下图所示。</p>\n<p><img src=\"/img/2024/2024111109.png\" alt=\"https://erik.xyz\"></p>\n<p>当数据库的数据被更新后，缓存也被删除。接下来的出现读请求3.1和写请求3.2同时进来。</p>\n<p>读请求先读了缓存发现缓存无命中，则查询数据库并在准备更新缓存时，3.2写请求已经完成了数据的更新和删除缓存的动作，之后3.1读请求才更新了缓存。最后导致了数据库中的值未新值，缓存中的值为旧值。</p>\n<h4 id=\"优化后方案\"><a href=\"#优化后方案\" class=\"headerlink\" title=\"优化后方案\"></a>优化后方案</h4><p>从上面的简单方案方案中，似乎没有一种方案真正能解决并发场景下MySQL数据与Redis缓存数据一致性的问题。</p>\n<p>这里有个说明下，如果业务要求必须要满足<strong>强一致性</strong>，那么不管如何优化缓存策略，都无法满足，而最好的办法是不用缓存。</p>\n<p>强一致性：它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大。</p>\n<p>解决方案是读写串行化，而此方案会大大增加系统的处理效率，吞吐量也会大大降低。</p>\n<p>另外在大型分布式系统中，其实分布式事务大多数情况都不会使用，因为维护成本太高了、复杂度也高。所以在分布式系统，我们一般都会推崇最终一致性，即这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态。</p>\n<p>现在我们接着继续优化..</p>\n<h4 id=\"延迟双删策略-重试机制\"><a href=\"#延迟双删策略-重试机制\" class=\"headerlink\" title=\"延迟双删策略+重试机制\"></a>延迟双删策略+重试机制</h4><p>从上面简单方案下的漏洞百出下的先删除缓存，再更新数据库中，我们可以看出来其实<strong>延迟双删策略</strong>，算是融合“先删除缓存，再更新数据库”和“先更新数据库，再删除缓存”的策略，可以解决大部分的数据一致性的业务逻辑处理问题。</p>\n<p>但我们前面还遗留了一个待解决的问题：如果再次<strong>删除缓存失败的情况如何处理</strong>？</p>\n<p>——-当然是补救去继续删除这个缓存Key了，而补救方法则是<strong>重试</strong>。</p>\n<p><strong>重试机制</strong>可以在当前中启动新协程（Golang中属于用户态的轻量级线程）中进行重试；也可以放到消息队列中进行重试；还可以是先启动新协程重试3次，重试失败后继续放到消息队列中重试，如下图展示的是放到消息队列中进行重试。</p>\n<p>新协程中进行重试需要注意的是使用的新上下文context.Background()，而不是当前请求的上下文。</p>\n<p>一般消息队列会支持高可靠性的队列，例如 RabbitMQ、Kafka 等。这些消息队列提供了非常强的消息传递、异步处理和持久化功能，可以有效地解决数据同步的问题。</p>\n<p><img src=\"/img/2024/2024111110.png\" alt=\"https://erik.xyz\"></p>\n<p>此方案仍然存在一些需要，如：选择合适的延迟等待时间进行删除缓存；协程中重试删除缓存次数、间隔时间；消息队列中删除失败缓存失败后是否需要重试等。</p>\n<h4 id=\"读取binlog异步删除缓存\"><a href=\"#读取binlog异步删除缓存\" class=\"headerlink\" title=\"读取binlog异步删除缓存\"></a>读取binlog异步删除缓存</h4><p>重试删除缓存机制还可以吧，就是会造成好多业务代码入侵。</p>\n<p>其实，还可以这样优化：</p>\n<p>1.通过Canal将binlog日志采集发送到MQ队列来异步淘汰key。</p>\n<p>2.删除缓存的应用程序通过ACK手动机制确认处理这条更新消息，删除缓存，保证数据缓存一致性。</p>\n<p><img src=\"/img/2024/2024111111.png\" alt=\"https://erik.xyz\"></p>\n<p>异步淘汰key相比于等新对比缓存数据并更新会简单一些，因为可能一份缓存数据涉及多张表的数据查询、聚合、排序等。</p>\n<p>尽管该方案看起来也不错了，但是因为引入额外的组件（如Canal、消息队列）复杂性增加了也不少，需要维护和监控这些组件的运行状态，保证组件运行正常。</p>\n<h4 id=\"定时任务\"><a href=\"#定时任务\" class=\"headerlink\" title=\"定时任务\"></a>定时任务</h4><p>在某些业务场景的需求下，也可以通过定时任务的方式进行 Redis 和 MySQL 的数据同步。</p>\n<p>具体做法是通过定时任务从 Redis 中读取数据，然后跟 MySQL 中的数据进行比对，如果 Redis 中数据有变化，则进行同步。</p>\n<p><img src=\"/img/2024/2024111112.png\" alt=\"https://erik.xyz\"></p>\n<p>这种方式虽然实现起来比较简单，但需要注意同步的时效性，如果时间间隔设置不当，可能会导致同步的数据丢失或者不准确。</p>\n<h4 id=\"双写一致性\"><a href=\"#双写一致性\" class=\"headerlink\" title=\"双写一致性\"></a>双写一致性</h4><p>在更新数据库的同时也更新缓存/删除缓存，即所谓的“<strong>双写</strong>”。</p>\n<p>这样可以确保在数据库更新后，缓存中的数据也是最新的，从而减少数据不一致的时间窗口。</p>\n<p><img src=\"/img/2024/2024111113.png\" alt=\"https://erik.xyz\"></p>\n<p><strong>并发控制</strong>：在高并发场景下，多个请求同时对同一个数据进行更新时，如果没有妥善处理并发控制，可能会导致数据不一致的问题。所以这里引入了分布式锁和事务操作：</p>\n<p><strong>使用分布式锁</strong>：在执行双写操作之前，获取一个分布式锁（如Zookeeper、Redis的SETNX命令等），确保同一时刻只有一个线程/进程能够执行双写操作。</p>\n<p><strong>事务处理</strong>：对于支持事务的缓存系统（如Redis的MULTI/EXEC命令）和MySQL事务，可以将Redis缓存和MySQL更新操作放入事务中，确保要么全部成功，要么全部失败。</p>\n<p>当然在“双写”的策略中，除了并发控制外，可以结合上面提到的重试、定时策略进行组合，以应对极端情况下的数据不一致性问题。</p>\n<p>另外也可以处理失败的逻辑上加入告警机制，及时通知开发和运维人员。</p>\n<p>转载自：<a href=\"https://mp.weixin.qq.com/s/sG7xDtLKLtlnu9ntpc5hdw\">皇子谈技术</a></p>\n",
            "tags": [
                "mysql",
                "redis",
                "数据一致性"
            ]
        },
        {
            "id": "https://erik.xyz/2024/07/22/sql-performance-optimization/",
            "url": "https://erik.xyz/2024/07/22/sql-performance-optimization/",
            "title": "SQL性能优化的47个小技巧，果断收藏！",
            "date_published": "2024-07-22T04:44:34.000Z",
            "content_html": "<p><strong>1、先了解MySQL的执行过程</strong></p>\n<p>了解了MySQL的执行过程，我们才知道如何进行sql优化。</p>\n<p>1.客户端发送一条查询语句到服务器；</p>\n<p>2.服务器先查询缓存，如果命中缓存，则立即返回存储在缓存中的数据；</p>\n<p>3.未命中缓存后，MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树，MySQL解析器将使用MySQL语法进行验证和解析。例如，验证是否使用了错误的关键字，或者关键字的使用是否正确；</p>\n<p>4.预处理是根据一些MySQL规则检查解析树是否合理，比如检查表和列是否存在，还会解析名字和别名，然后预处理器会验证权限；</p>\n<p>5.根据执行计划查询执行引擎，调用API接口调用存储引擎来查询数据；</p>\n<p>6.将结果返回客户端，并进行缓存；<br><span id=\"more\"></span></p>\n<p><img src=\"/img/2024/202405201.png\" alt=\"erik.xyz\"></p>\n<p><strong>2、数据库常见规范</strong></p>\n<p>1.所有数据库对象名称必须使用小写字母并用下划线分割；</p>\n<p>2.所有数据库对象名称禁止使用mysql保留关键字；</p>\n<p>3.数据库对象的命名要能做到见名识意，并且最后不要超过32个字符；</p>\n<p>4.临时库表必须以tmp<em>为前缀并以日期为后缀，备份表必须以bak</em>为前缀并以日期(时间戳)为后缀；</p>\n<p>5.所有存储相同数据的列名和列类型必须一致；</p>\n<p><strong>3、所有表必须使用Innodb存储引擎</strong></p>\n<p>没有特殊要求（即Innodb无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用Innodb存储引擎（mysql5.5之前默认使用Myisam，5.6以后默认的为Innodb）。</p>\n<p>Innodb 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。</p>\n<p><strong>4、每个Innodb表必须有个主键</strong></p>\n<p>Innodb是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。</p>\n<p>Innodb是按照主键索引的顺序来组织表的</p>\n<p>1.不要使用更新频繁的列作为主键，不适用多列主键；</p>\n<p>2.不要使用UUID、MD5、HASH、字符串列作为主键（无法保证数据的顺序增长）；</p>\n<p>3.主键建议使用自增ID值；</p>\n<p><strong>5、数据库和表的字符集统一使用UTF8</strong></p>\n<p>兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储emoji表情的需要，字符集需要采用utf8mb4字符集。</p>\n<p><strong>6、查询SQL尽量不要使用select *，而是具体字段</strong></p>\n<p>select *的弊端：</p>\n<p>1.增加很多不必要的消耗，比如CPU、IO、内存、网络带宽；</p>\n<p>2.增加了使用覆盖索引的可能性；</p>\n<p>3.增加了回表的可能性；</p>\n<p>4.当表结构发生变化时，前端也需要更改；</p>\n<p>5.查询效率低；</p>\n<p><strong>7、避免在where子句中使用 or 来连接条件</strong></p>\n<p>1.使用or可能会使索引失效，从而全表扫描；</p>\n<p>2.对于or没有索引的salary这种情况，假设它走了id的索引，但是走到salary查询条件时，它还得全表扫描；</p>\n<p>3.也就是说整个过程需要三步：全表扫描+索引扫描+合并。如果它一开始就走全表扫描，直接一遍扫描就搞定；</p>\n<p>4.虽然mysql是有优化器的，处于效率与成本考虑，遇到or条件，索引还是可能失效的；</p>\n<p><strong>8、尽量使用数值替代字符串类型</strong></p>\n<p>1.因为引擎在处理查询和连接时会逐个比较字符串中每一个字符；</p>\n<p>2.而对于数字型而言只需要比较一次就够了；</p>\n<p>3.字符会降低查询和连接的性能，并会增加存储开销；</p>\n<p><strong>9、使用varchar代替char</strong></p>\n<p>1.varchar变长字段按数据内容实际长度存储，存储空间小，可以节省存储空间；</p>\n<p>2.char按声明大小存储，不足补空格；</p>\n<p>3.其次对于查询来说，在一个相对较小的字段内搜索，效率更高；</p>\n<p><strong>10、财务、银行相关的金额字段必须使用decimal类型</strong></p>\n<ul>\n<li><p>非精准浮点：float,double</p>\n</li>\n<li><p>精准浮点：decimal</p>\n</li>\n</ul>\n<p>1.Decimal类型为精准浮点数，在计算时不会丢失精度；</p>\n<p>2.占用空间由定义的宽度决定，每4个字节可以存储9位数字，并且小数点要占用一个字节；</p>\n<p>3.可用于存储比bigint更大的整型数据；</p>\n<p><strong>11、避免使用ENUM类型</strong></p>\n<ul>\n<li><p>修改ENUM值需要使用ALTER语句；</p>\n</li>\n<li><p>ENUM类型的ORDER BY操作效率低，需要额外操作；</p>\n</li>\n<li><p>禁止使用数值作为ENUM的枚举值；</p>\n</li>\n</ul>\n<p><strong>12、去重distinct过滤字段要少</strong></p>\n<p>1.带distinct的语句占用cpu时间高于不带distinct的语句</p>\n<p>2.当查询很多字段时，如果使用distinct，数据库引擎就会对数据进行比较，过滤掉重复数据</p>\n<p>3.然而这个比较、过滤的过程会占用系统资源，如cpu时间</p>\n<p><strong>13、where中使用默认值代替null</strong></p>\n<p>1.并不是说使用了is null或者 is not null就会不走索引了，这个跟mysql版本以及查询成本都有关；</p>\n<p>2.如果mysql优化器发现，走索引比不走索引成本还要高，就会放弃索引，这些条件 !=，&lt;&gt;，is null，is not null经常被认为让索引失效；</p>\n<p>3.其实是因为一般情况下，查询的成本高，优化器自动放弃索引的；</p>\n<p>4.如果把null值，换成默认值，很多时候让走索引成为可能，同时，表达意思也相对清晰一点；</p>\n<p><strong>14、避免在where子句中使用!=或&lt;&gt;操作符</strong></p>\n<p>1.使用!=和&lt;&gt;很可能会让索引失效</p>\n<p>2.应尽量避免在where子句中使用!=或&lt;&gt;操作符，否则引擎将放弃使用索引而进行全表扫描实</p>\n<p>3.现业务优先，实在没办法，就只能使用，并不是不能使用</p>\n<p><strong>15、inner join 、left join、right join，优先使用inner join</strong></p>\n<p>三种连接如果结果相同，优先使用inner join，如果使用left join左边表尽量小。</p>\n<ul>\n<li><p>inner join 内连接，只保留两张表中完全匹配的结果集；</p>\n</li>\n<li><p>left join会返回左表所有的行，即使在右表中没有匹配的记录；</p>\n</li>\n<li><p>right join会返回右表所有的行，即使在左表中没有匹配的记录；</p>\n</li>\n</ul>\n<p>为什么？</p>\n<ul>\n<li>如果inner join是等值连接，返回的行数比较少，所以性能相对会好一点；</li>\n<li>使用了左连接，左边表数据结果尽量小，条件尽量放到左边处理，意味着返回的行数可能比较少；</li>\n<li>这是mysql优化原则，就是小表驱动大表，小的数据集驱动大的数据集，从而让性能更优；</li>\n</ul>\n<p><strong>16、提高group by语句的效率</strong></p>\n<p>1、反例</p>\n<p>先分组，再过滤<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select job, avg（salary） from employee group by jobhaving job =&#x27;develop&#x27; or job = &#x27;test&#x27;;</span><br></pre></td></tr></table></figure></p>\n<p>2、正例</p>\n<p>先过滤，后分组<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select job，avg（salary） from employee where job =&#x27;develop&#x27; or job = &#x27;test&#x27; group by job;</span><br></pre></td></tr></table></figure></p>\n<p>3、理由</p>\n<p>可以在执行到该语句前，把不需要的记录过滤掉</p>\n<p><strong>17、清空表时优先使用truncate</strong></p>\n<p>truncate table在功能上与不带 where子句的 delete语句相同：二者均删除表中的全部行。但 truncate table比 delete速度快，且使用的系统和事务日志资源少。</p>\n<p>delete语句每次删除一行，并在事务日志中为所删除的每行记录一项。truncate table通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。</p>\n<p>truncate table删除表中的所有行，但表结构及其列、约束、索引等保持不变。新行标识所用的计数值重置为该列的种子。如果想保留标识计数值，请改用 DELETE。如果要删除表定义及其数据，请使用 drop table语句。</p>\n<p>对于由 foreign key约束引用的表，不能使用 truncate table，而应使用不带  where子句的 DELETE 语句。由于 truncate table不记录在日志中，所以它不能激活触发器。</p>\n<p>truncate table不能用于参与了索引视图的表。</p>\n<p><strong>18、操作delete或者update语句，加个limit或者循环分批次删除</strong></p>\n<p>（1）降低写错SQL的代价</p>\n<p>清空表数据可不是小事情，一个手抖全没了，删库跑路？如果加limit，删错也只是丢失部分数据，可以通过binlog日志快速恢复的。</p>\n<p>（2）SQL效率很可能更高</p>\n<p>SQL中加了limit 1，如果第一条就命中目标return， 没有limit的话，还会继续执行扫描表。</p>\n<p>（3）避免长事务</p>\n<p>delete执行时,如果age加了索引，MySQL会将所有相关的行加写锁和间隙锁，所有执行相关行会被锁住，如果删除数量大，会直接影响相关业务无法使用。</p>\n<p>（4）数据量大的话，容易把CPU打满</p>\n<p>如果你删除数据量很大时，不加 limit限制一下记录数，容易把cpu打满，导致越删越慢。</p>\n<p>（5）锁表</p>\n<p>一次性删除太多数据，可能造成锁表，会有lock wait timeout exceed的错误，所以建议分批操作。</p>\n<p><strong>19、UNION操作符</strong></p>\n<p>UNION在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。实际大部分应用中是不会产生重复的记录，最常见的是过程表与历史表UNION。如：<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select username,tel from userunionselect departmentname from department</span><br></pre></td></tr></table></figure><br>这个SQL在运行时先取出两个表的结果，再用排序空间进行排序删除重复的记录，最后返回结果集，如果表数据量大的话可能会导致用磁盘进行排序。推荐方案：采用UNION ALL操作符替代UNION，因为UNION ALL操作只是简单的将两个结果合并后就返回。</p>\n<p><strong>20、SQL语句中IN包含的字段不宜过多</strong></p>\n<p>MySQL的IN中的常量全部存储在一个数组中，这个数组是排序的。如果值过多，产生的消耗也是比较大的。如果是连续的数字，可以使用between代替，或者使用连接查询替换。</p>\n<p><strong>21、批量插入性能提升</strong></p>\n<p>（1）多条提交</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INSERT INTO user (id,username) VALUES(1,&#x27;哪吒编程&#x27;);INSERT INTO user (id,username) VALUES(2,&#x27;妲己&#x27;);</span><br></pre></td></tr></table></figure>\n<p>（2）批量提交<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INSERT INTO user (id,username) VALUES(1,&#x27;哪吒编程&#x27;),(2,&#x27;妲己&#x27;);</span><br></pre></td></tr></table></figure></p>\n<p>默认新增SQL有事务控制，导致每条都需要事务开启和事务提交，而批量处理是一次事务开启和提交，效率提升明显，达到一定量级，效果显著，平时看不出来。</p>\n<p><strong>22、表连接不宜太多，索引不宜太多，一般5个以内</strong></p>\n<p>（1）表连接不宜太多，一般5个以内</p>\n<p>1.关联的表个数越多，编译的时间和开销也就越大</p>\n<p>2.每次关联内存中都生成一个临时表</p>\n<p>3.应该把连接表拆开成较小的几个执行，可读性更高</p>\n<p>4.如果一定需要连接很多表才能得到数据，那么意味着这是个糟糕的设计了</p>\n<p>5.阿里规范中，建议多表联查三张表以下</p>\n<p>（2）索引不宜太多，一般5个以内</p>\n<p>1.索引并不是越多越好，虽其提高了查询的效率，但却会降低插入和更新的效率；</p>\n<p>2.索引可以理解为一个就是一张表，其可以存储数据，其数据就要占空间；</p>\n<p>3.索引表的数据是排序的，排序也是要花时间的；</p>\n<p>4.insert或update时有可能会重建索引，如果数据量巨大，重建将进行记录的重新排序，所以建索引需要慎重考虑，视具体情况来定；</p>\n<p>5.一个表的索引数最好不要超过5个，若太多需要考虑一些索引是否有存在的必要；</p>\n<p><strong>23、禁止给表中的每一列都建立单独的索引</strong></p>\n<p>真有这么干的，我也是醉了。</p>\n<p>2万字带你精通MySQL索引</p>\n<p><strong>24、如何选择索引列的顺序</strong></p>\n<p>建立索引的目的是：希望通过索引进行数据查找，减少随机IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。</p>\n<p>区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）。</p>\n<p>尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO性能也就越好）。</p>\n<p>使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）。</p>\n<p><strong>25、对于频繁的查询优先考虑使用覆盖索引</strong></p>\n<p>覆盖索引：就是包含了所有查询字段(where,select,ordery by,group by包含的字段)的索引。</p>\n<p>覆盖索引的好处：</p>\n<p>（1）避免Innodb表进行索引的二次查询</p>\n<p>Innodb是以聚集索引的顺序来存储的，对于Innodb来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。</p>\n<p>而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了IO操作，提升了查询效率。</p>\n<p>（2）可以把随机IO变成顺序IO加快查询效率</p>\n<p>由于覆盖索引是按键值的顺序存储的，对于IO密集型的范围查找来说，对比随机从磁盘读取每一行的数据IO要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的IO转变成索引查找的顺序IO。</p>\n<p><strong>26、建议使用预编译语句进行数据库操作</strong></p>\n<p>预编译语句可以重复使用这些计划，减少SQL编译所需要的时间，还可以解决动态SQL所带来的SQL注入的问题。</p>\n<p>只传参数，比传递SQL语句更高效。</p>\n<p>相同语句可以一次解析，多次使用，提高处理效率。</p>\n<p><strong>27、避免产生大事务操作</strong></p>\n<p>大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对MySQL的性能产生非常大的影响。</p>\n<p>特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批。</p>\n<p><strong>28、避免在索引列上使用内置函数</strong></p>\n<p>使用索引列上内置函数，索引失效。</p>\n<p><strong>29、组合索引</strong></p>\n<p>排序时应按照组合索引中各列的顺序进行排序，即使索引中只有一个列是要排序的，否则排序性能会比较差。<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">create index IDX_USERNAME_TEL on user(deptid,position,createtime);select username,tel from user where deptid= 1 and position = &#x27;java开发&#x27; order by deptid,position,createtime desc; </span><br></pre></td></tr></table></figure></p>\n<p>实际上只是查询出符合 deptid= 1 and position = ‘java开发’条件的记录并按createtime降序排序，但写成order by createtime desc性能较差。</p>\n<p><strong>30、复合索引最左特性</strong></p>\n<p>（1）创建复合索引<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ALTER TABLE employee ADD INDEX idx_name_salary (name,salary)</span><br></pre></td></tr></table></figure><br>（2）满足复合索引的最左特性，哪怕只是部分，复合索引生效<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT * FROM employee WHERE NAME=&#x27;哪吒编程&#x27;</span><br></pre></td></tr></table></figure><br>（3）没有出现左边的字段，则不满足最左特性，索引失效<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT * FROM employee WHERE salary=5000</span><br></pre></td></tr></table></figure><br>（4）复合索引全使用，按左侧顺序出现 name,salary，索引生效<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT * FROM employee WHERE NAME=&#x27;哪吒编程&#x27; AND salary=5000</span><br></pre></td></tr></table></figure><br>（5）虽然违背了最左特性，但MySQL执行SQL时会进行优化，底层进行颠倒优化<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT * FROM employee WHERE salary=5000 AND NAME=&#x27;哪吒编程&#x27;</span><br></pre></td></tr></table></figure><br>（6）理由<br>复合索引也称为联合索引，当我们创建一个联合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。</p>\n<p>联合索引不满足最左原则，索引一般会失效。</p>\n<p><strong>31、必要时可以使用force index来强制查询走某个索引</strong></p>\n<p>有的时候MySQL优化器采取它认为合适的索引来检索SQL语句，但是可能它所采用的索引并不是我们想要的。这时就可以采用forceindex来强制优化器使用我们制定的索引。</p>\n<p><strong>32、优化like语句</strong></p>\n<p>模糊查询，程序员最喜欢的就是使用like，但是like很可能让你的索引失效。</p>\n<ul>\n<li><p>首先尽量避免模糊查询，如果必须使用，不采用全模糊查询，也应尽量采用右模糊查询， 即like ‘…%’，是会使用索引的；</p>\n</li>\n<li><p>左模糊like ‘%…’无法直接使用索引，但可以利用reverse + function index的形式，变化成 like ‘…%’；</p>\n</li>\n<li><p>全模糊查询是无法优化的，一定要使用的话建议使用搜索引擎。</p>\n</li>\n</ul>\n<p><strong>33、统一SQL语句的写法</strong></p>\n<p>对于以下两句SQL语句， 程序员认为是相同的，数据库查询优化器认为是不同的。<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select * from user;select * From USER;</span><br></pre></td></tr></table></figure></p>\n<p>这都是很常见的写法，也很少有人会注意，就是表名大小写不一样而已。然而，查询解析器认为这是两个不同的SQL语句，要解析两次，生成两个不同的执行计划，作为一名严谨的Java开发工程师，应该保证两个一样的SQL语句，不管在任何地方都是一样的。</p>\n<p><strong>34、不要把SQL语句写得太复杂</strong></p>\n<p>经常听到有人吹牛逼，我写了一个800行的SQL语句，逻辑感超强，我们还开会进行了SQL讲解，大家都投来了崇拜的目光。。。</p>\n<p>一般来说，嵌套子查询、或者是3张表关联查询还是比较常见的，但是，如果超过3层嵌套的话，查询优化器很容易给出错误的执行计划，影响SQL效率。SQL执行计划是可以被重用的，SQL越简单，被重用的概率越大，生成执行计划也是很耗时的。</p>\n<p><strong>35、将大的DELETE，UPDATE、INSERT 查询变成多个小查询</strong></p>\n<p>能写一个几十行、几百行的SQL语句是不是显得逼格很高？然而，为了达到更好的性能以及更好的数据控制，你可以将他们变成多个小查询。</p>\n<p><strong>36、关于临时表</strong></p>\n<p>1.避免频繁创建和删除临时表，以减少系统表资源的消耗；</p>\n<p>2.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log；</p>\n<p>3.如果数据量不大，为了缓和系统表的资源，应先create table，然后insert；</p>\n<p>4.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除。先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。</p>\n<p><strong>37、使用explain分析你SQL执行计划</strong></p>\n<p>（1）type</p>\n<p>1.system：表仅有一行，基本用不到；</p>\n<p>2.const：表最多一行数据配合，主键查询时触发较多；</p>\n<p>3.eq_ref：对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型；</p>\n<p>4.ref：对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取；</p>\n<p>5.range：只检索给定范围的行，使用一个索引来选择行。当使用=、&lt;&gt;、&gt;、&gt;=、&lt;、&lt;=、IS NULL、&lt;=&gt;、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range；</p>\n<p>6.index：该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小；</p>\n<p>7.all：全表扫描；</p>\n<p>8.性能排名：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all。</p>\n<p>9.实际sql优化中，最后达到ref或range级别。</p>\n<p>（2）Extra常用关键字</p>\n<ul>\n<li><p>Using index：只从索引树中获取信息，而不需要回表查询；</p>\n</li>\n<li><p>Using where：WHERE子句用于限制哪一个行匹配下一个表或发送到客户。除非你专门从表中索取或检查所有行，如果Extra值不为Using where并且表联接类型为ALL或index，查询可能会有一些错误。需要回表查询。</p>\n</li>\n<li><p>Using temporary：mysql常建一个临时表来容纳结果，典型情况如查询包含可以按不同情况列出列的GROUP BY和ORDER BY子句时；</p>\n</li>\n</ul>\n<p><strong>38、读写分离与分库分表</strong></p>\n<p>当数据量达到一定的数量之后，限制数据库存储性能的就不再是数据库层面的优化就能够解决的；这个时候往往采用的是读写分离与分库分表同时也会结合缓存一起使用，而这个时候数据库层面的优化只是基础。</p>\n<p>读写分离适用于较小一些的数据量；分表适用于中等数据量；而分库与分表一般是结合着用，这就适用于大数据量的存储了，这也是现在大型互联网公司解决数据存储的方法之一。</p>\n<p><strong>39、使用合理的分页方式以提高分页的效率</strong><br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select id,name from user limit 100000, 20</span><br></pre></td></tr></table></figure></p>\n<p>使用上述SQL语句做分页的时候，随着表数据量的增加，直接使用limit语句会越来越慢。<br>此时，可以通过取前一页的最大ID，以此为起点，再进行limit操作，效率提升显著。<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select id,name from user where id&gt; 100000 limit 20</span><br></pre></td></tr></table></figure></p>\n<p><strong>40、尽量控制单表数据量的大小，建议控制在500万以内。</strong></p>\n<p>500万并不是MySQL数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。<br>可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小。</p>\n<p><strong>41、谨慎使用Mysql分区</strong></p>\n<ul>\n<li><p>表分区表在物理上表现为多个文件，在逻辑上表现为一个表；</p>\n</li>\n<li><p>谨慎选择分区键，跨分区查询效率可能更低；</p>\n</li>\n<li><p>建议采用物理分表的方式管理大数据。</p>\n</li>\n</ul>\n<p><strong>42、尽量做到冷热数据分离，减小表的宽度</strong></p>\n<p>Mysql限制每个表最多存储4096列，并且每一行数据的大小不能超过65535字节。</p>\n<p>减少磁盘IO,保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的IO）；</p>\n<p>更有效的利用缓存，避免读入无用的冷数据；</p>\n<p>经常一起使用的列放到一个表中（避免更多的关联操作）。</p>\n<p><strong>43、禁止在表中建立预留字段</strong></p>\n<p>1.预留字段的命名很难做到见名识义；</p>\n<p>2.预留字段无法确认存储的数据类型，所以无法选择合适的类型；</p>\n<p>3.对预留字段类型的修改，会对表进行锁定；</p>\n<p><strong>44、禁止在数据库中存储图片，文件等大的二进制数据</strong></p>\n<p>通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机IO操作，文件很大时，IO操作很耗时。</p>\n<p>通常存储于文件服务器，数据库只存储文件地址信息。</p>\n<p><strong>45、建议把BLOB或是TEXT列分离到单独的扩展表中</strong></p>\n<p>Mysql内存临时表不支持TEXT、BLOB这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，Mysql还是要进行二次查询，会使sql性能变得很差，但是不是说一定不能使用这样的数据类型。</p>\n<p>如果一定要使用，建议把BLOB或是TEXT列分离到单独的扩展表中，查询时一定不要使用select * 而只需要取出必要的列，不需要TEXT列的数据时不要对该列进行查询。</p>\n<p><strong>46、TEXT或BLOB类型只能使用前缀索引</strong></p>\n<p>因为MySQL对索引字段长度是有限制的，所以TEXT类型只能使用前缀索引，并且TEXT列上是不能有默认值的。</p>\n<p><strong>47、一些其它优化方式</strong></p>\n<p>（1）当只需要一条数据的时候，使用limit 1：<br>limit 1可以避免全表扫描，找到对应结果就不会再继续扫描了。</p>\n<p>（2）如果排序字段没有用到索引，就尽量少排序</p>\n<p>（3）所有表和字段都需要添加注释使用comment从句添加表和列的备注，从一开始就进行数据字典的维护。</p>\n<p>（4）SQL书写格式，关键字大小保持一致，使用缩进。</p>\n<p>（5）修改或删除重要数据前，要先备份。</p>\n<p>（6）很多时候用 exists 代替 in 是一个好的选择</p>\n<p>（7）where后面的字段，留意其数据类型的隐式转换。</p>\n<p>（8）尽量把所有列定义为NOT NULL:<br>NOT NULL列更节省空间，NULL列需要一个额外字节作为判断是否为 NULL的标志位。NULL列需要注意空指针问题，NULL列在计算和比较的时候，需要注意空指针问题。</p>\n<p>（9）伪删除设计</p>\n<p>（10）索引不适合建在有大量重复数据的字段上，比如性别，排序字段应创建索引</p>\n<p>（11）尽量避免使用游标：<br>因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。</p>\n<p>转载自：<a href=\"https://mp.weixin.qq.com/s/zGneQEY8_P3nL0nGI8tCFg\">哪吒编程</a></p>\n",
            "tags": [
                "mysql",
                "sql",
                "sql优化"
            ]
        },
        {
            "id": "https://erik.xyz/2023/05/15/mysql-top-log/",
            "url": "https://erik.xyz/2023/05/15/mysql-top-log/",
            "title": "MYSQL 最朴素的监控方式",
            "date_published": "2023-05-15T14:24:00.000Z",
            "content_html": "<p>对于当前数据库的监控方式有很多，分为数据库自带、商用、开源三大类，每一种都有各自的特色；而对于 mysql 数据库由于其有很高的社区活跃度，监控方式更是多种多样，不管哪种监控方式最核心的就是监控数据，获取得到全面的监控数据后就是灵活的展示部分。那我们今天就介绍一下完全采用 mysql 自有方式采集获取监控数据，在单体下达到最快速、方便、损耗最小。<br><span id=\"more\"></span><br>本次文章完全使用 mysql 自带的 show 命令实现获取，从 connects、buffercache、lock、SQL、statement、Database throughputs、serverconfig7 大方面全面获取监控数据。</p>\n<ol>\n<li><p>连接数（Connects）</p>\n<ul>\n<li><p>最大使用连接数：show status like ‘Max_used_connections’</p>\n</li>\n<li><p>当前打开的连接数：show status like ‘Threads_connected’</p>\n</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li><p>缓存（bufferCache）</p>\n<ul>\n<li>未从缓冲池读取的次数：show status like ‘Innodb_buffer_pool_reads’</li>\n<li>从缓冲池读取的次数：show status like ‘Innodb_buffer_pool_read_requests’</li>\n<li>缓冲池的总页数：show status like ‘Innodb_buffer_pool_pages_total’</li>\n<li>缓冲池空闲的页数：show status like ‘Innodb_buffer_pool_pages_free’</li>\n<li>缓存命中率计算：（1-Innodb_buffer_pool_reads/Innodb_buffer_pool_read_requests）*100%</li>\n<li>缓存池使用率为：((Innodb_buffer_pool_pages_total-Innodb_buffer_pool_pages_free）/Innodb_buffer_pool_pages_total）*100%</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li><p>锁（lock）</p>\n<ul>\n<li>锁等待个数：show status like ‘Innodb_row_lock_waits’</li>\n<li>平均每次锁等待时间：show status like ‘Innodb_row_lock_time_avg’</li>\n<li>查看是否存在表锁：show open TABLES where in_use&gt;0；有数据代表存在锁表，空为无表锁</li>\n</ul>\n<p>备注：锁等待统计得数量为累加数据，每次获取得时候可以跟之前得数据进行相减，得到当前统计得数据</p>\n</li>\n<li><p>SQL</p>\n<ul>\n<li>查看 mysql 开关是否打开：show variables like ‘slow_query_log’，ON 为开启状态，如果为 OFF，set global slow_query_log=1 进行开启</li>\n<li>查看 mysql 阈值：show variables like ‘long_query_time’，根据页面传递阈值参数，修改阈值 set global long_query_time=0.1</li>\n<li>查看 mysql 慢 sql 目录：show variables like ‘slow_query_log_file’</li>\n<li>格式化慢 sql 日志：mysqldumpslow -s at -t 10 /export/data/mysql/log/slow.log 注：此语句通过 jdbc 执行不了，属于命令行执行。意思为：显示出耗时最长的 10 个 SQL 语句执行信息，10 可以修改为 TOP 个数。显示的信息为：执行次数、平均执行时间、SQL 语句</li>\n</ul>\n<p>备注：当 mysqldumpslow 命令执行失败时，将慢日志同步到本地进行格式化处理。</p>\n</li>\n<li><p>statement</p>\n<ul>\n<li>insert 数量：show status like ‘Com_insert’</li>\n<li>delete 数量：show status like ‘Com_delete’</li>\n<li>update 数量：show status like ‘Com_update’</li>\n<li>select 数量：show status like ‘Com_select’</li>\n</ul>\n</li>\n<li><p>吞吐（Database throughputs）</p>\n<ul>\n<li>发送吞吐量：show status like ‘Bytes_sent’</li>\n<li>接收吞吐量：show status like ‘Bytes_received’</li>\n<li>总吞吐量：Bytes_sent+Bytes_received</li>\n</ul>\n</li>\n<li><p>数据库参数（serverconfig）</p>\n<p> show variables</p>\n</li>\n<li><p>慢 SQL</p>\n</li>\n</ol>\n<p>慢 SQL 指的是 MySQL 慢查询，具体指运行时间超过 long_query_time 值的 SQL。我们常听 MySQL 中有二进制日志 binlog、中继日志 relaylog、重做回滚日志 redolog、undolog 等。针对慢查询，还有一种慢查询日志 slowlog，用来记录在 MySQL 中响应时间超过阀值的语句。慢 SQL 对实际生产业务影响是致命的，所以测试人员在性能测试过程中，对数据库 SQL 语句执行情况实施监控，给开发提供准确的性能优化意见显得尤为重要。那怎么使用 Mysql 数据库提供的慢查询日志来监控 SQL 语句执行情况，找到消耗较高的 SQL 语句，以下详细说明一下慢查询日志的使用步骤：</p>\n<ul>\n<li>确保打开慢 SQL 开关 slow_query_log</li>\n<li>设置慢 SQL 域值 long_query_time 这个 long_query_time 是用来定义慢于多少秒的才算 “慢查询”，注意单位是秒，我通过执行 sql 指令 set long_query_time=1 来设置了 long_query_time 的值为 1, 也就是执行时间超过 1 秒的都算慢查询，如下：</li>\n<li>查看慢 SQL 日志路径</li>\n<li>通过慢 sql 分析工具 mysqldumpslow 格式化分析慢 SQL 日志 mysqldumpslow 慢查询分析工具，是 mysql 安装后自带的，可以通过./mysqldumpslow —help 查看使用参数说明</li>\n</ul>\n<p>常见用法：</p>\n<ol>\n<li>取出使用最多的 10 条慢查询 ./mysqldumpslow -s c -t 10 /export/data/mysql/log/slow.log</li>\n<li><p>取出查询时间最慢的 3 条慢查询 ./mysqldumpslow -s t -t 3 /export/data/mysql/log/slow.log</p>\n<p>注意：使用 mysqldumpslow 的分析结果不会显示具体完整的 sql 语句，只会显示 sql 的组成结构；假如: SELECT FROM sms_send WHERE service_id=10 GROUP BY content LIMIT 0, 1000; mysqldumpslow 命令执行后显示：Count: 2 Time=1.5s (3s) Lock=0.00s (0s) Rows=1000.0 (2000), vgos_dba[vgos_dba]@[10.130.229.196]SELECT FROM sms_send WHERE service_id=N GROUP BY content LIMIT N, N</p>\n</li>\n</ol>\n<p>mysqldumpslow 的分析结果详解：</p>\n<ul>\n<li>Count：表示该类型的语句执行次数，上图中表示 select 语句执行了 2 次。</li>\n<li>Time：表示该类型的语句执行的平均时间（总计时间）</li>\n<li>Lock：锁时间 0s。</li>\n<li>Rows：单次返回的结果数是 1000 条记录，2 次总共返回 2000 条记录。<br>通过这个工具就可以查询出来哪些 sql 语句是慢 SQL，从而反馈研发进行优化，比如加索引，该应用的实现方式等。</li>\n</ul>\n<h5 id=\"常见慢-SQL-排查\"><a href=\"#常见慢-SQL-排查\" class=\"headerlink\" title=\"常见慢 SQL 排查\"></a>常见慢 SQL 排查</h5><ol>\n<li><p>不使用子查询</p>\n<p>SELECT FROM t1 WHERE id (SELECT id FROM t2 WHERE name=’hechunyang’); 子查询在 MySQL5.5 版本里，内部执行计划器是这样执行的：先查外表再匹配内表，而不是先查内表 t2，当外表的数据很大时，查询速度会非常慢。在 MariaDB10/MySQL5.6 版本里，采用 join 关联方式对其进行了优化，这条 SQL 会自动转换为 SELECT t1. FROM t1 JOIN t2 ON t1.id = t2.id; 但请注意的是：优化只针对 SELECT 有效，对 UPDATE/DELETE 子 查询无效， 生产环境尽量应避免使用子查询。</p>\n</li>\n<li><p>避免函数索引</p>\n<p>SELECT FROM t WHERE YEAR(d) &gt;= 2016; 由于 MySQL 不像 Oracle 那样⽀持函数索引，即使 d 字段有索引，也会直接全表扫描。应改为 &gt; SELECT FROM t WHERE d &gt;= ‘2016-01-01’;</p>\n</li>\n<li><p>用 IN 来替换 OR 低效查询</p>\n<p>慢 SELECT FROM t WHERE LOC_ID = 10 OR LOC_ID = 20 OR LOC_ID = 30; 高效查询 &gt; SELECT FROM t WHERE LOC_IN IN (10,20,30);</p>\n</li>\n<li><p>LIKE 双百分号无法使用到索引</p>\n<p>SELECT FROM t WHERE name LIKE ‘%de%’; 使用 SELECT FROM t WHERE name LIKE ‘de%’;</p>\n</li>\n<li><p>分组统计可以禁止排序</p>\n<p>SELECT goods_id,count() FROM t GROUP BY goods_id; 默认情况下，MySQL 对所有 GROUP BY col1，col2… 的字段进⾏排序。如果查询包括 GROUP BY，想要避免排序结果的消耗，则可以指定 ORDER BY NULL 禁止排序。使用 SELECT goods_id,count () FROM t GROUP BY goods_id ORDER BY NULL;</p>\n</li>\n<li><p>禁止不必要的 ORDER BY 排序</p>\n<p>SELECT count(1) FROM user u LEFT JOIN user_info i ON u.id = i.user_id WHERE 1 = 1 ORDER BY u.create_time DESC; 使用 SELECT count (1) FROM user u LEFT JOIN user_info i ON u.id = i.user_id;</p>\n</li>\n</ol>\n<p>9.总结</p>\n<ul>\n<li>任何东西不应过重关注其外表，要注重内在的东西，往往绚丽的外表下会有对应的负担和损耗。</li>\n<li>mysql 数据库的监控支持通过 SQL 方式从 performance_schema 库中访问对应的表数据，前提是初始化此库并开启监控数据写入。</li>\n<li>对于监控而言，不在于手段的多样性，而需要明白监控的本质，以及需要的监控项内容，找到符合自身项目特色的监控方式。</li>\n<li>在选择监控工具对 mysql 监控时，需要关注监控工具本身对于数据库服务器的消耗，不要影响到其自身的使用。</li>\n</ul>\n<p>链接：<a href=\"https://my.oschina.net/u/4090830/blog/5564849\">https://my.oschina.net/u/4090830/blog/5564849</a></p>\n",
            "tags": [
                "mysql",
                "mysql监控"
            ]
        },
        {
            "id": "https://erik.xyz/2020/06/20/mysql-top-sun/",
            "url": "https://erik.xyz/2020/06/20/mysql-top-sun/",
            "title": "MySQL性能指标及计算方法",
            "date_published": "2020-06-20T07:48:00.000Z",
            "content_html": "<p>绝大多数MySQL性能指标可以通过以下两种方式获取：</p>\n<p>（1）mysqladmin</p>\n<p>使用mysqladmin extended-status命令获得的MySQL的性能指标，默认为累计值。如果想了解当前状态，需要进行差值计算；加上参数 —relative(-r)，就可以看到各个指标的差值，配合参数—sleep(-i)就可以指定刷新的频率。</p>\n<span id=\"more\"></span>\n<p>（2）Show global status</p>\n<p>可以列出MySQL服务器运行各种状态值，累计值。</p>\n<p>mysqladmin extended-status命令及show global status得到的指标项特别多。实际应用中，重点关注以下性能指标：</p>\n<p>tps/qps</p>\n<p>tps: Transactions Per Second，每秒事务数；</p>\n<p>qps: Queries Per Second每秒查询数；</p>\n<h5 id=\"通常有两种方法计算tps-qps：\"><a href=\"#通常有两种方法计算tps-qps：\" class=\"headerlink\" title=\"通常有两种方法计算tps/qps：\"></a>通常有两种方法计算tps/qps：</h5><p>方法1：</p>\n<p>基于 com_commit、com_rollback 计算tps，基于 questions 计算qps。</p>\n<pre><code>TPS = Com_commit/s + Com_rollback/s\n</code></pre><p>其中，</p>\n<pre><code>Com_commit /s= mysqladmin extended-status --relative --sleep=1|grep -w Com_commit\nCom_rollback/s = mysqladmin extended-status --relative --sleep=1|grep -w Com_rollback\nQPS 是指MySQL Server 每秒执行的Query总量，通过Questions (客户的查询数目)状态值每秒内的变化量来近似表示，所以有：\nQPS = mysqladmin extended-status --relative --sleep=1|grep -w Questions\n</code></pre><p>仿照上面的方法还可以得到，mysql每秒select、insert、update、delete的次数等，如：</p>\n<pre><code>Com_select/s = mysqladmin extended-status --relative --sleep=1|grep -w Com_select\nCom_select/s：平均每秒select语句执行次数\nCom_insert/s：平均每秒insert语句执行次数\nCom_update/s：平均每秒update语句执行次数\nCom_delete/s：平均每秒delete语句执行次数\n</code></pre><p>方法2:</p>\n<p>基于com_%计算tps ,qps</p>\n<pre><code>tps= Com_insert/s + Com_update/s + Com_delete/s\nqps=Com_select/s + Com_insert/s + Com_update/s + Com_delete/s\n</code></pre><h5 id=\"线程状态\"><a href=\"#线程状态\" class=\"headerlink\" title=\"线程状态\"></a>线程状态</h5><pre><code>* threads_running：\n当前正处于激活状态的线程个数\n\n* threads_connected：\n当前连接的线程的个数\n\n### 流量状态\n* Bytes_received/s：\n平均每秒从所有客户端接收到的字节数，单位KB\n\n* Bytes_sent/s：\n平均每秒发送给所有客户端的字节数，单位KB\n</code></pre><h5 id=\"innodb文件读写次数\"><a href=\"#innodb文件读写次数\" class=\"headerlink\" title=\"innodb文件读写次数\"></a>innodb文件读写次数</h5><pre><code>* innodb_data_reads：\ninnodb平均每秒从文件中读取的次数\n\n* innodb_data_writes：\ninnodb平均每秒从文件中写入的次数\n\n* innodb_data_fsyncs：\ninnodb平均每秒进行fsync()操作的次数\n</code></pre><h5 id=\"innodb读写量\"><a href=\"#innodb读写量\" class=\"headerlink\" title=\"innodb读写量\"></a>innodb读写量</h5><pre><code>* innodb_data_read：\ninnodb平均每秒钟读取的数据量，单位为KB\n\n* innodb_data_written：\ninnodb平均每秒钟写入的数据量，单位为KB\n</code></pre><h5 id=\"innodb缓冲池状态\"><a href=\"#innodb缓冲池状态\" class=\"headerlink\" title=\"innodb缓冲池状态\"></a>innodb缓冲池状态</h5><pre><code>* innodb_buffer_pool_reads: \n平均每秒从物理磁盘读取页的次数 \n\n* innodb_buffer_pool_read_requests: \n\n平均每秒从innodb缓冲池的读次数（逻辑读请求数）\n* innodb_buffer_pool_write_requests: \n\n平均每秒向innodb缓冲池的写次数\n* innodb_buffer_pool_pages_dirty: \n\n平均每秒innodb缓存池中脏页的数目\n* innodb_buffer_pool_pages_flushed: \n\n* innodb_buffer_read_hit_ratio = ( 1 - Innodb_buffer_pool_reads/Innodb_buffer_pool_read_requests) * 100\ninnodb缓冲池的读命中率\n\n* Innodb_buffer_usage =  ( 1 - Innodb_buffer_pool_pages_free / Innodb_buffer_pool_pages_total) * 100\nInnodb缓冲池的利用率\n</code></pre><h5 id=\"innodb日志\"><a href=\"#innodb日志\" class=\"headerlink\" title=\"innodb日志\"></a>innodb日志</h5><pre><code>innodb_os_log_fsyncs: \n平均每秒向日志文件完成的fsync()写数量\n\ninnodb_os_log_written: \n平均每秒写入日志文件的字节数\n\ninnodb_log_writes: \n平均每秒向日志文件的物理写次数\n\ninnodb_log_write_requests: \n平均每秒日志写请求数\ninnodb行\n\ninnodb_rows_deleted: \n平均每秒从innodb表删除的行数\n\ninnodb_rows_inserted: \n平均每秒从innodb表插入的行数\n\ninnodb_rows_read: \n平均每秒从innodb表读取的行数\n\ninnodb_rows_updated: \n平均每秒从innodb表更新的行数\n\ninnodb_row_lock_waits:  \n一行锁定必须等待的时间数\n\ninnodb_row_lock_time: \n行锁定花费的总时间，单位毫秒\n\ninnodb_row_lock_time_avg: \n行锁定的平均时间，单位毫秒\nMyISAM读写次数\n\nkey_read_requests: \nMyISAM平均每秒钟从缓冲池中的读取次数\n\nKey_write_requests: \nMyISAM平均每秒钟从缓冲池中的写入次数\n\nkey_reads : \nMyISAM平均每秒钟从硬盘上读取的次数\n\nkey_writes : \nMyISAM平均每秒钟从硬盘上写入的次数\n</code></pre><h5 id=\"MyISAM缓冲池\"><a href=\"#MyISAM缓冲池\" class=\"headerlink\" title=\"MyISAM缓冲池\"></a>MyISAM缓冲池</h5><pre><code>MyISAM平均每秒key buffer利用率\nKey_usage_ratio =Key_blocks_used/(Key_blocks_used+Key_blocks_unused)*100\n\nMyISAM平均每秒key buffer读命中率\nKey_read_hit_ratio=(1-Key_reads/Key_read_requests)*100\n\nMyISAM平均每秒key buffer写命中率\nKey_write_hit_ratio =(1-Key_writes/Key_write_requests)*100\n临时表\n\nCreated_tmp_disk_tables: \n服务器执行语句时在硬盘上自动创建的临时表的数量\n\nCreated_tmp_tables: \n服务器执行语句时自动创建的内存中的临时表的数量\n\nCreated_tmp_disk_tables/Created_tmp_tables比值最好不要超过10%，如果Created_tmp_tables值比较大，可能是排序句子过多或者连接句子不够优化\n</code></pre><h5 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h5><pre><code>slow_queries: \n执行时间超过long_query_time秒的查询的个数（重要）\n\nsort_rows: \n已经排序的行数\n\nopen_files: \n打开的文件的数目\n\nopen_tables: \n当前打开的表的数量\n\nselect_scan: \n对第一个表进行完全扫描的联接的数量\n此外，还有一些性能指标不能通过mysqladmin extended-status或show global status直接得到，但是十分重要。\n</code></pre><h5 id=\"response-time-响应时间\"><a href=\"#response-time-响应时间\" class=\"headerlink\" title=\"response time: 响应时间\"></a>response time: 响应时间</h5><p>Percona提供了tcprstat工具统计响应时间，此功能默认是关闭的，可以通过设置参数query_response_time_stats=1打开这个功能。</p>\n<p>有两种方法查看响应时间：</p>\n<p>（1）通过命令SHOW QUERY_RESPONSE_TIME查看响应时间统计；</p>\n<p>（2）通过INFORMATION_SCHEMA里面的表QUERY_RESPONSE_TIME来查看。</p>\n<h5 id=\"Slave-delay-备库延迟\"><a href=\"#Slave-delay-备库延迟\" class=\"headerlink\" title=\"Slave delay: 备库延迟\"></a>Slave delay: 备库延迟</h5><p>可以在slave节点上执行show slave status\\G命令，Seconds_Behind_Master项的值即为slave当前的延时量，单位秒。</p>\n<p>原文地址：<br><a href=\"https://www.cnblogs.com/yuyue2014/p/3679628.html\">https://www.cnblogs.com/yuyue2014/p/3679628.html</a></p>\n",
            "tags": [
                "mysql",
                "mysql性能"
            ]
        },
        {
            "id": "https://erik.xyz/2019/04/23/mysql-fen-ku-fen-biao/",
            "url": "https://erik.xyz/2019/04/23/mysql-fen-ku-fen-biao/",
            "title": "mysql分库分表",
            "date_published": "2019-04-23T04:28:00.000Z",
            "content_html": "<p><strong>分库分表</strong></p>\n<blockquote>\n</blockquote>\n<p>php工作5年了,大部分场景都是业务层。说白了就是增删改查。也知道数据库大数据处理分库分表，一般是水平分表和垂直分表，实操是不可能的，今天看了一篇文章<a href=\"https://mp.weixin.qq.com/s/QFlUPS8X0errMwpxdBMHvg\">《分库分表？如何做到永不迁移数据和避免热点？》</a>，思路一下顺畅了。</p>\n<blockquote>\n</blockquote>\n<p> 一般来说mysql一个表大概数据量在100W查询速度跟不上了。<span id=\"more\"></span>如果每天的数据量有100W那数据这个块就要做处理了。我之前的思路是这样想的：</p>\n<blockquote>\n</blockquote>\n<p> 一个表固定分100w数据，每个表用数据id做范围分配。然后查询的时候根据id找表，但是这样有个问题，如果同一个用户数据在不同的表里，这时要查询用户的所有数据，就要连表查询，实际上分表查询是有时间和范围限制的，不存在一次性拿出所有数据的情况。（而我参加面试的时候有个面试官直接给了一个这样的问题：<br> “我这有一亿数据，一次性拿出来，用mysql如何实现。”我顿时懵逼了，没法实现，代码层可能实现，数据库查询我还真不知道。）</p>\n<blockquote>\n</blockquote>\n<p>  <strong>根据上面我看的文章介绍这是range范围方案</strong><br>   <img src=\"https://erik.xyz/wp-content/uploads/2019/2019-04-23_170042.jpg\" alt=\"\"></p>\n<p>   除了查询问题，还有一个热点问题。某个时间段数据量大增的情况，一个表就扛不住了。</p>\n<blockquote>\n</blockquote>\n<p>  <em>_文章中还介绍了hash取模法 </em>_<br>   <img src=\"https://erik.xyz/wp-content/uploads/2019/2019-04-23_171040.jpg\" alt=\"\"></p>\n<p>   hash取模法容易导致数据迁移问题，如果数据量大迁移的成本是比较高的。</p>\n<p>   <strong>根据文章介绍可以先做个范围分组，然后根据分组在用hash取模分表放数据</strong><br>   <img src=\"https://erik.xyz/wp-content/uploads/2019/2019-04-23_180531.jpg\" alt=\"\"></p>\n<p>   <em>_最终表的设计如 </em>_<br>   <img src=\"https://erik.xyz/wp-content/uploads/2019/2019-04-23_180824.jpg\" alt=\"\"></p>\n",
            "tags": [
                "mysql",
                "分库分表"
            ]
        },
        {
            "id": "https://erik.xyz/2016/03/01/mysql-shu-ju-ku-ru-he-xuan-ze-cun-chu-yin-qing/",
            "url": "https://erik.xyz/2016/03/01/mysql-shu-ju-ku-ru-he-xuan-ze-cun-chu-yin-qing/",
            "title": "mysql数据库如何选择存储引擎",
            "date_published": "2016-03-01T09:50:00.000Z",
            "content_html": "<p>针对不同的业务需求来选择mysql存储引擎。 1.采用MyISAM引擎</p>\n<ul>\n<li>R/W&gt;100:1且updae相对较少。</li>\n<li>并发不高，不需要事务。</li>\n<li>表数据量小。</li>\n<li>硬件资源有限。</li>\n</ul>\n<p>2.采用InnoDB引擎<span id=\"more\"></span></p>\n<ul>\n<li>R/W比较小，频繁更新大字段。</li>\n<li>表数据量超过1000W,并发高。</li>\n<li>安全性和可用性要求高。</li>\n</ul>\n<p>3.采用Memory引擎</p>\n<ul>\n<li>有足够的内存。</li>\n<li>对数据一致性要求不高，如在线人数和Session等应用。</li>\n<li>需要定期归档的数据。</li>\n</ul>\n",
            "tags": [
                "mysql",
                "mysql存储",
                "mysql引擎",
                "mysql数据表设计选择"
            ]
        },
        {
            "id": "https://erik.xyz/2016/03/01/you-guan-mysql-you-hua-de-zhun-ze/",
            "url": "https://erik.xyz/2016/03/01/you-guan-mysql-you-hua-de-zhun-ze/",
            "title": "有关mysql优化的准则",
            "date_published": "2016-03-01T09:29:00.000Z",
            "content_html": "<p>前辈们总结的经验，学习、学习。 </p>\n<p>1.尽量避免在列上进行运算，这样会导致索引失效。 </p>\n<p>例如：SELECT <em> FROM t WHERE YEAR(d) &gt;=2011; 优化为：SELECT </em> FROM t WHERE d &gt;=’2011-01-01’;</p>\n<p>2.使用JOIN时，应该用小结果集驱动大结果集。</p>\n<p>同时把复杂的JOIN查询拆分成多个QUERY。因为JOIN多个 表时，可能导致更多的锁定和堵塞。 SELECT * FROM a JOIN b ON a.id=b.id LEFT JOIN c ON c.time=a.date LEFT JOIN d ON c.pid=d.aid LEFT JOIN e ON e.cid=a.did<br><span id=\"more\"></span></p>\n<p>3.LIKE模糊查询的使用，避免%% </p>\n<p>例如：SELECT <em> FROM t WHERE name LIKE ‘%de%’; 优化为：SELECT </em> FROM t WHERE name &gt;=’de’ AND name&lt;’df’; </p>\n<p>4.仅列出需要查询的字段，这对速度不会有明显影响，主要考虑节省内存。 </p>\n<p>5.使用批量插入语句节省交互 </p>\n<p>例如： INTO t (id,name) VALUES (1,’a’); INSERT INTO t (id,name) VALUES (2,’b’); INSERT INTO t (id,name) VALUES (3,’c’); 优化：INSERT INTO t (id,name) VALUES (1,’a’),(2,’b’),(3,’c’); </p>\n<p>6.limit的基数比较大时使用between </p>\n<p>SELECT <em> FROM article AS article ORDER BY id LIMIT 100000,10; 优化：SELECT </em> FROM article AS article WHERE id BETWEEN 100000 AND 100010 ORDER BY id; </p>\n<p>7.不要使用rand函数获取多条随机记录 </p>\n<p>SELECT <em> FROM table ORDER BY rand() LIMIT 20; 优化： SELECT </em> FROM ‘table’ AS t1 JOIN (SELECT ROUND (RAND() * ((SELECT MAX(id) FROM ‘table’)-(SELECT MIN(id) FROM ‘table’ )) + (SELECT MIN(id) FROM ‘table’ )) AS id) AS t2 WHERE t1.id&gt;=t2.id ORDER BY t1.id LIMIT 1; </p>\n<p>8.避免使用NULL </p>\n<p>9.不要使用count(id),而应该是count(*) </p>\n<p>10.不要做无谓的排序，而应尽可能在索引中完成排序。</p>\n",
            "tags": [
                "mysql",
                "mysql优化",
                "mysql读写优化",
                "数据库优化，mysql语句优化"
            ]
        },
        {
            "id": "https://erik.xyz/2015/05/28/zai-php-zhong-you-guan-mysql-de-yi-xie-han-shu/",
            "url": "https://erik.xyz/2015/05/28/zai-php-zhong-you-guan-mysql-de-yi-xie-han-shu/",
            "title": "在PHP中有关mysql的一些函数",
            "date_published": "2015-05-28T07:39:00.000Z",
            "content_html": "<p>PHP中的MYSQL常用函数总结 </p>\n<p>1、mysql_connect()-建立数据库连接 格式： resource mysql_connect([string hostname [:port] [:/path/to/socket] [, string username] [, string password]]) </p>\n<p>例： $conn = @mysql_connect(“localhost”, “username”, “password”) or die(“不能连接到Mysql Server”);</p>\n<p>说明：使用该连接必须显示的关闭连接 <span id=\"more\"></span></p>\n<p>2、mysql_pconnect()-建立数据库连接 格式： resource mysql_pconnect([string hostname [:port] [:/path/to/socket] [, string username] [, string password]]) 例： $conn = @mysql_pconnect(“localhost”, “username”, “password”) or dir(“不能连接到Mysql Server”); 说明：使用该连接函数不需要显示的关闭连接，它相当于使用了连接池 </p>\n<p>3、mysql_close()-关闭数据库连接 例： $conn = @mysql_connect(“localhost”, “username”, “password”) or die(“不能连接到Mysql Server”); @mysql_select_db(“MyDatabase”) or die(“不能选择这个数据库，或数据库不存在”); echo “你已经连接到MyDatabase数据库”; mysql_close(); </p>\n<p>4、mysql_select_db()-选择数据库 格式： boolean mysql_select_db(string db_name [, resource link_id]) 例： $conn = @mysql_connect(“localhost”, “username”, “password”) or die(“不能连接到Mysql Server”); @mysql_select_db(“MyDatabase”) or die(“不能选择这个数据库，或数据库不存在”); </p>\n<p>5、mysql_query()-查询MySQL 格式： resource mysql_query (string query, [resource link_id]) 例： $linkId = @mysql_connect(“localhost”, “username”, “password”) or die(“不能连接到Mysql Server”); @mysql_select_db(“MyDatabase”) or die(“不能选择这个数据库，或者数据库不存在”); $query = “select * from MyTable”; $result = mysql_query($query); mysql_close(); 说明：若SQL查询执行成功，则返回资源标识符，失败时返回FALSE。若执行更新成功，则返回TRUE，否则返回FALSE</p>\n<p>6、mysql_db_query()-查询MySQL 格式： resource mysql_db_query(string database, string query [, resource link_id]) 例： $linkId = @mysql_connect(“localhost”, “username”, “password”) or die(“不能连接到MysqlServer”); $query = “select * from MyTable”; $result = mysql_db_query(“MyDatabase”, $query); mysql_close(); 说明：为了使代码清晰，不推荐使用这个函数调用 </p>\n<p>7、mysql_result()-获取和显示数据 格式： mixed mysql_result (resource result_set, int row [, mixed field]) 例： $query = “select id, name from MyTable order by name”; $result = mysql_query($query); for($count=0;$count&lt;=mysql_numrows($result);$count++) { $c_id = mysql_result($result, 0, “id”); $c_name = mysql_result($result, 0, “name”); echo $c_id,$c_name; } 说明：最简单、也是效率最低的数据获取函数 </p>\n<p>8、mysql_fetch_row()-获取和显示数据 格式： array mysql_fetch_row (resource result_set) 例： $query = “select id, name from MyTable order by name”; $result = mysql_query($query); while (list($id, $name) = mysql_fetch_row($result)) { echo(“Name: $name ($id) <br />“); } 说明：函数从result_set中获取整个数据行，将值放在一个索引数组中。通常会结使list()函数使用 </p>\n<p>9、mysql_fetch_array()-获取和显示数据 格式： array mysql_fetch_array (resource result_set [, int result_type]) 例： $query = “select id, name from MyTable order by name”; $result = mysql_query($query); while($row = mysql_fetch_array($result, MYSQL_ASSOC)) { $id = $row[“id”]; $name = $row[“name”]; echo “Name: $name ($id) <br />“; } 又例： $query = “select id, name from MyTable order by name”; $result = mysql_query($query); while($row = mysql_fetch_array($result, MYSQL_NUM)) { $id = $row[0]; $name = $row[1]; echo “Name: $name ($id) <br />“; } 说明： result_type的值有： MYSQL_ASSOC: 字段名表示键，字段内容为值 MYSQL_NUM: 数值索引数组，操作与mysql_fetch_ros()函数一样 MYSQL_BOTH: 即作为关联数组又作为数值索引数组返回。result_type的默认值。 </p>\n<p>10、mysql_fetch_assoc()-获取和显示数据 格式： array mysql_fetch_assoc (resource result_set) 相当于调用 mysql_fetch_array(resource, MYSQL_ASSOC);</p>\n<p>11、mysql_fetch_object()-获取和显示数据 格式： object mysql_fetch_object(resource result_set) 例： $query = “select id, name from MyTable order by name”; while ($row = mysql_fetch_object($result)) { $id = $row-&gt;id; $name = $row-&gt;name; echo “Name: $name ($id) <br />“; } 说明：返回一个对象，在操作上与mysql_fetch_array()相同 </p>\n<p>12、mysql_num_rows()-所选择的记录的个数 格式： int mysql_num_rows(resource result_set) 例： query = “select id, name from MyTable where id &gt; 65”; $result = mysql_query($query); echo “有”.mysql_num_rows($result).”条记录的ID大于65”; 说明：只在确定select查询所获取的记录数时才有用。 </p>\n<p>13、mysql_affected_rows()－受Insert,update,delete影响的记录的个数 格式： int mysql_affected_rows([resource link_id]) 例： $query = “update MyTable set name=’CheneyFu’ where id&gt;=5”; $result = mysql_query($query); echo “ID大于等于5的名称被更新了的记录数：”.mysql_affected_rows(); 说明：该函数获取受INSERT,UPDATE或DELETE更新语句影响的行数 </p>\n<p>14、mysql_list_dbs()-获取数据库列表信息 格式： resource mysql_list_dbs([resource link_id]) 例： mysql_connect(“localhost”, “username”, “password”); $dbs = mysql_list_dbs(); echo “Databases: <br />“; while (list($db) = mysql_fetch_rows($dbs)) { echo “$db <br />“; } 说明：显示所有数据库名称 </p>\n<p>15、mysql_db_name()-获取数据库名 格式： string mysql_db_name(resource result_set, integer index) 说明：该函数获取在mysql_list_dbs()所返回result_set中位于指定index索引的数据库名 </p>\n<p>16、mysql_list_tables()-获取数据库表列表 格式： resource mysql_list_tables(string database [, resource link_id]) 例： mysql_connect(“localhost”, “username”, “password”); $tables = mysql_list_tables(“MyDatabase”); while (list($table) = mysql_fetch_row($tables)) { echo “$table <br />“; } 说明：该函数获取database中所有表的表名 17、mysql_tablename()-获取某个数据库表名 格式： string mysql_tablename(resource result_set, integer index) 例： mysql_connect(“localhost”, “username”, “password”); $tables = mysql_list_tables(“MyDatabase”); $count = -1; while (++$count &lt; mysql_numrows($tables)) { echo mysql_tablename($tables, $count).”<br />“; } 说明：该函数获取mysql_list_tables()所返回result_set中位于指定index索引的表名 18、mysql_fetch_field()-获取字段信息 格式： object mysql_fetch_field(resource result [, int field_offset]) 例： mysql_connect(“localhost”, “username”, “password”); mysql_select_db(“MyDatabase”); $query = “select * from MyTable”;</p>\n",
            "tags": [
                "php",
                "mysql",
                "mysql函数",
                "php中mysql函数"
            ]
        },
        {
            "id": "https://erik.xyz/2015/01/09/wei-mysql-zeng-jia-http-rest-ke-hu-duan-mysql-udf-han-shu-mysql-udf-http-1-0-fa-bu/",
            "url": "https://erik.xyz/2015/01/09/wei-mysql-zeng-jia-http-rest-ke-hu-duan-mysql-udf-han-shu-mysql-udf-http-1-0-fa-bu/",
            "title": "为 MySQL 增加 HTTP/REST 客户端：MySQL UDF 函数 mysql-udf-http 1.0 发布",
            "date_published": "2015-01-09T14:38:00.000Z",
            "content_html": "<p>文章作者：张宴 Mysql-udf-http 是一款简单的MySQL用户自定义函数（UDF, User-Defined Functions），具有http_get()、http_post()、http_put()、http_delete()四个函数，可以在 MySQL数据库中利用HTTP协议进行REST相关操作。 项目网址：<a href=\"http://code.google.com/p/mysql-udf-http/\">http://code.google.com/p/mysql-udf-http/</a> 中文说明：<a href=\"http://blog.zyan.cc/mysql-udf-http/\">http://blog.zyan.cc/mysql-udf-http/</a> 使用环境：Linux操作系统，支持的MySQL版本：5.1.x 和 5.5.x。5.0.x未经测试。 软件作者：张宴<span id=\"more\"></span></p>\n<hr>\n<p><strong>一、REST架构风格：</strong> REST（Representational State Transfer）是一种轻量级的Web Service架构风格，其实现和操作明显比SOAP和XML-RPC更为简洁，可以完全通过HTTP协议实现，还可以利用缓存Cache来提高响应速 度，性能、效率和易用性上都优于SOAP协议。REST最早是由 Roy Thomas Fielding 博士2000年在论文《<a href=\"http://www.ics.uci.edu/%7Efielding/pubs/dissertation/top.htm\">Architectural Styles and the Design of Network-based Software Architectures</a>》中提出的，<a href=\"http://mysql-udf-http.googlecode.com/files/REST_cn.pdf\">中文译文全文PDF点此下载</a>。另外，<a href=\"http://www.infoq.com/cn/articles/rest-introduction\">有篇译文</a>对REST做了一个简化说明。 目前，REST架构风格的常见实现是基于HTTP协议及其四种基本方法（如POST、GET、PUT和DELETE）的。有人将HTTP协议的四种方法 与CRUD原则相对应，CRUD原则对于资源只需要四种行为：Create（创建）、Read（读取）、Update（更新）和Delete（删除）就可 以完成对其操作和处理。 </p>\n<p><a href=\"http://zyan.cc/attachment/201009/crud.png\"><img src=\"http://zyan.cc/attachment/201009/crud.png\" alt=\"点击在新窗口中浏览此图片\" title=\"点击在新窗口中浏览此图片\"></a></p>\n<p><a href=\"http://zyan.cc/attachment/201009/rest.jpg\"><img src=\"http://zyan.cc/attachment/201009/rest.jpg\" alt=\"点击在新窗口中浏览此图片\" title=\"点击在新窗口中浏览此图片\"></a> </p>\n<p>在Mysql-udf-http中，四个函数http_post()、http_get()、http_put()、http_delete()分别对应HTTP协议的POST、GET、PUT、DELETE四种方法。 REST是一种架构风格，而不是协议或标准。HTTP协议“POST、GET、PUT、DELET”四种方法与CRUD原则“Create、Read、 Update、Delete”四种行为的一一对应关系只是一种架构设计习惯，而不是规范。因此，POST方法也可以用来更新资源，PUT方法也可以用来创 建资源，这就要看具体应用程序作者的定义了。例如<a href=\"http://zyan.cc/post/362/\">Tokyo Tyrant</a>除了支持Memcached协议外，还支持REST方式存取，PUT代表创建和更新，GET代表读取，DELETE代表删除（<a href=\"http://zyan.cc/post/362/\">关于Tokyo Tyrant的安装使用请点击这儿</a>）。 目前国内外流行的Web 2.0应用API接口中，很多都支持REST架构风格。例如：<a href=\"http://open.t.sina.com.cn/wiki/index.php/API%E6%96%87%E6%A1%A3\">新浪微博开放平台</a>、<a href=\"http://wiki.dev.renren.com/wiki/API\">人人网API</a>、Google OpenID、Flickr、Twitter、eBay、Facebook、Last.fm、del.icio.us、Yahoo Search、Amazon S3、Amazon EC2、Digg、Microsoft Bing、FriendFeed、PayPal、Foursquare，<a href=\"http://www.programmableweb.com/apis/directory/1?protocol=REST\">更多…</a> 当记录数成百上千万条时，通常采用 MySQL 分表减低数据库压力。但是，全部数据按点击数、精华、积分排序显示等功能，在MySQL 分表中则无法实现。编写 Mysql-udf-http 的最初目的，是为了在项目开发中，将 MySQL 各分表的数据自动同步到我们的 <a href=\"http://zyan.cc/tcsql/\">TCSQL</a> 高速列表数据库，用来做列表查询、显示，内容页则根据ID直接查询各 MySQL 分表的内容。由于HTTP协议的通用性，通过 Mysql-udf-http 可以做更多的事情。 <strong>通过Mysql-udf-http，你可以在MySQL中利用触发器，将MySQL的数据同步到支持REST的应用上。</strong>例如你有一个独立博客，你可以在文章表创建MySQL触发器，这样，在发表文章时，就可以将文章标题、URL自动同步到新浪微博、Twitter。你想用 <a href=\"http://zyan.cc/post/362/\">Tokyo Tyrant</a> 做缓存，也可以利用MySQL触发器在发生增、删、改时，将数据自动同步到 <a href=\"http://zyan.cc/post/362/\">Tokyo Tyrant</a>。详细配置方法本文第4节中会有介绍。</p>\n<hr>\n<p><strong>二、Mysql-udf-http的安装与使用：</strong> <strong>1. 在Linux系统上安装Mysql-udf-http</strong> 注意：“/usr/local/webserver/mysql/”是你的MySQL安装路径，如果你的MySQL安装路径不同，请自行修改。</p>\n<pre><code>ulimit -SHn 65535 \n\nwget http://curl.haxx.se/download/curl-7.21.1.tar.gz\n\ntar zxvf curl-7.21.1.tar.gz cd curl-7.21.1/ \n\n./configure --prefix=/usr \n\nmake &amp;&amp; make install \n\ncd ../\n\necho &quot;/usr/local/webserver/mysql/lib/mysql/&quot; &gt; /etc/ld.so.conf.d/mysql.conf /sbin/ldconfig \n\nwget http://mysql-udf-http.googlecode.com/files/mysql-udf-http-1.0.tar.gz \n\ntar zxvf mysql-udf-http-1.0.tar.gz \n\ncd mysql-udf-http-1.0/\n\n./configure --prefix=/usr/local/webserver/mysql --with-mysql=/usr/local/webserver/mysql/bin/mysql_config \n\nmake &amp;&amp; make install cd ../\n</code></pre><hr>\n<p><strong>2. 通过命令行登陆进入MySQL</strong></p>\n<p>/usr/local/webserver/mysql/bin/mysql -S /tmp/mysql.sock</p>\n<hr>\n<p><strong>3. 创建MySQL自定义函数</strong> mysql&gt;</p>\n<p><a href=\"http://zyan.cc/#\">view plain</a><a href=\"http://zyan.cc/#\">print</a><a href=\"http://zyan.cc/#\">?</a></p>\n<pre><code>create function http_get returns string soname &#39;mysql-udf-http.so&#39;;\ncreate function http_post returns string soname &#39;mysql-udf-http.so&#39;;\ncreate function http_put returns string soname &#39;mysql-udf-http.so&#39;;\ncreate function http_delete returns string soname &#39;mysql-udf-http.so&#39;;\n</code></pre><hr>\n<p><strong>4. 使用方法</strong> <strong>I. 函数描述：</strong> mysql&gt;</p>\n<p><a href=\"http://zyan.cc/#\">view plain</a><a href=\"http://zyan.cc/#\">print</a><a href=\"http://zyan.cc/#\">?</a></p>\n<pre><code>SELECT http_get(&#39;&lt;url&gt;&#39;);\nSELECT http_post(&#39;&lt;url&gt;&#39;, &#39;&lt;data&gt;&#39;);\nSELECT http_put(&#39;&lt;url&gt;&#39;, &#39;&lt;data&gt;&#39;);\nSELECT http_delete(&#39;&lt;url&gt;&#39;);\n</code></pre><p><strong>II. 示例 A：</strong> mysql&gt;</p>\n<p><a href=\"http://zyan.cc/#\">view plain</a><a href=\"http://zyan.cc/#\">print</a><a href=\"http://zyan.cc/#\">?</a></p>\n<pre><code>/* HTTP GET、POST方式提交关键词“xoyo”到百度移动搜索 */\nSELECT http_get(&#39;http://m.baidu.com/s?word=xoyo&amp;pn=0&#39;);\nSELECT http_post(&#39;http://m.baidu.com/s&#39;,&#39;word=xoyo&amp;pn=0&#39;);\n\n/* 新浪微博开放平台：获取新浪用户ID为103500的最近一条微博内容 */\nSELECT http_get(&#39;http://api.t.sina.com.cn/statuses/user_timeline/103500.json?count=1&amp;source=1561596835&#39;) AS data;\n/* 新浪微博开放平台：发表一条微博 */\nSELECT http_post(&#39;http://your\\_sina\\_uid:your_password@api.t.sina.com.cn/statuses/update.xml?source=1561596835&#39;, &#39;status=Thins is sina weibo test information&#39;);\n\n/* Tokyo Tyrant 写入、读取、删除操作 */\nSELECT http_put(&#39;http://192.168.8.34:1978/key&#39;, &#39;This is value&#39;);\nSELECT http_get(&#39;http://192.168.8.34:1978/key&#39;);\nSELECT http_delete(&#39;http://192.168.8.34:1978/key&#39;);\n</code></pre><p><strong>III. 示例</strong> <strong>通过MySQL触发器，利用mysql-udf-http和第三方UDF函数lib_mysqludf_json，自动同步数据到 Tokyo Tyrant。</strong> <strong>(1). 下载安装 lib_mysqludf_json 修改版：</strong> 以下安装包适合32位Linux操作系统：</p>\n<pre><code>wget http://mysql-udf-http.googlecode.com/files/lib_mysqludf_json-i386.tar.gz\n\ntar zxvf lib_mysqludf_json-i386.tar.gz \ncd lib_mysqludf_json-i386/ \n\n# 如果你的MySQL安装路径不是/usr/local/webserver/mysql/，请修改以下路径。 \n\ncp -f lib_mysqludf_json.so  /usr/local/webserver/mysql/lib/mysql/plugin/lib_mysqludf_json.so\n\ncd ../\n</code></pre><p>以下安装包适合64位Linux操作系统：</p>\n<pre><code>wget http://mysql-udf-http.googlecode.com/files/lib_mysqludf_json-x86_64.tar.gz\n\ntar zxvf lib_mysqludf_json-x86_64.tar.gz cd lib_mysqludf_json-x86_64/ \n\n# 如果你的MySQL安装路径不是/usr/local/webserver/mysql/，请修改以下路径。\n\ncp -f lib_mysqludf_json.so /usr/local/webserver/mysql/lib/mysql/plugin/lib_mysqludf_json.so \n\ncd ../\n\n# 通过命令行登陆进入MySQL：\n\n/usr/local/webserver/mysql/bin/mysql -S /tmp/mysql.sock\n</code></pre><p>mysql&gt;</p>\n<p><a href=\"http://zyan.cc/#\">view plain</a><a href=\"http://zyan.cc/#\">print</a><a href=\"http://zyan.cc/#\">?</a></p>\n<pre><code>create function lib\\_mysqludf\\_json_info returns string soname &#39;lib\\_mysqludf\\_json.so&#39;;\ncreate function json_array returns string soname &#39;lib\\_mysqludf\\_json.so&#39;;\ncreate function json_members returns string soname &#39;lib\\_mysqludf\\_json.so&#39;;\ncreate function json_object returns string soname &#39;lib\\_mysqludf\\_json.so&#39;;\ncreate function json_values returns string soname &#39;lib\\_mysqludf\\_json.so&#39;;\n</code></pre><p>lib_mysqludf_json的详细用法请访问：<a href=\"http://www.mysqludf.org/lib_mysqludf_json/\">http://www.mysqludf.org/lib_mysqludf_json/</a> <strong>(2). 创建测试表</strong> mysql&gt;</p>\n<p><a href=\"http://zyan.cc/#\">view plain</a><a href=\"http://zyan.cc/#\">print</a><a href=\"http://zyan.cc/#\">?</a></p>\n<pre><code>SET NAMES UTF8;\nUSE test;\nCREATE TABLE IF NOT EXISTS `mytable` (\n  `id` int(10) NOT NULL AUTO_INCREMENT,\n  `addtime` int(10) NOT NULL,\n  `title` varchar(255) CHARACTER SET utf8 NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=MyISAM DEFAULT CHARSET=utf8 AUTO_INCREMENT=1;\n</code></pre><p><strong>(3). 为测试表创建触发器：</strong> mysql&gt;</p>\n<p><a href=\"http://zyan.cc/#\">view plain</a><a href=\"http://zyan.cc/#\">print</a><a href=\"http://zyan.cc/#\">?</a></p>\n<pre><code>  /* INSERT插入操作的触发器 */\n  DELIMITER |\n  DROP TRIGGER IF EXISTS mytable_insert;\n  CREATE TRIGGER mytable_insert\n  AFTER INSERT ON mytable\n  FOR EACH ROW BEGIN\n      SET @tt_json = (SELECT json_object(id,addtime,title) FROM mytable WHERE id = NEW.id LIMIT 1);\n      SET @tt_resu = (SELECT http_put(CONCAT(&#39;http://192.168.8.34:1978/&#39;, NEW.id), @tt_json));\n  END |\n  DELIMITER ;\n\n  /* UPDATE更新操作的触发器 */\n DELIMITER |\n  DROP TRIGGER IF EXISTS mytable_update;\n  CREATE TRIGGER mytable_update\n  AFTER UPDATE ON mytable\n  FOR EACH ROW BEGIN\n     SET @tt_json = (SELECT json_object(id,addtime,title) FROM mytable WHERE id = OLD.id LIMIT 1);\n      SET @tt_resu = (SELECT http_put(CONCAT(&#39;http://192.168.8.34:1978/&#39;, OLD.id), @tt_json));\n  END |\n  DELIMITER ;\n\n  /* DELETE删除操作的触发器 */\n  DELIMITER |\n  DROP TRIGGER IF EXISTS mytable_delete;\n  CREATE TRIGGER mytable_delete\n  AFTER DELETE ON mytable\n  FOR EACH ROW BEGIN\n      SET @tt_resu = (SELECT http_delete(CONCAT(&#39;http://192.168.8.34:1978/&#39;, OLD.id)));\n  END |\n  DELIMITER ;\n</code></pre><p><strong>(4). 将 MySQL 表和 Tokyo Tyrant 关联进行查询：</strong> mysql&gt;</p>\n<p><a href=\"http://zyan.cc/#\">view plain</a><a href=\"http://zyan.cc/#\">print</a><a href=\"http://zyan.cc/#\">?</a></p>\n<pre><code> SELECT id,addtime,title,http_get(CONCAT(&#39;http://192.168.8.34:1978/&#39;,id)) AS tt FROM mytable ORDER BY id DESC LIMIT 0,5;\n</code></pre><hr>\n<p><strong>5. 如何删除mysql-udf-http UDF函数：</strong> mysql&gt;</p>\n<p><a href=\"http://zyan.cc/#\">view plain</a><a href=\"http://zyan.cc/#\">print</a><a href=\"http://zyan.cc/#\">?</a></p>\n<pre><code>drop function http_get;\ndrop function http_post;\ndrop function http_put;\ndrop function http_delete;\n</code></pre><p>原文链接：<a href=\"http://blog.zyan.cc/mysql-udf-http/\">http://blog.zyan.cc/mysql-udf-http/</a>]function http_delete;</p>\n",
            "tags": [
                "数据库",
                "mysql",
                "数据表"
            ]
        },
        {
            "id": "https://erik.xyz/2014/12/22/wei-mysql-she-zhi-cha-xun-chao-shi/",
            "url": "https://erik.xyz/2014/12/22/wei-mysql-she-zhi-cha-xun-chao-shi/",
            "title": "为MySQL设置查询超时",
            "date_published": "2014-12-22T13:03:00.000Z",
            "content_html": "<p>作者: <a href=\"http://www.laruence.com\">Laruence</a> 昨天有人在群里问, MySQL是否可以设置读写超时(非连接超时), 如果可以就可以避免一条SQL执行过慢, 导致PHP超时错误. 这个, 其实可以有. 只不过稍微要麻烦点. 首先, 在libmysql中, 是提供了MYSQL_OPT_READ_TIMEOUT设置项的, 并且libmysql中提供了设置相关设置项的API, mysql_options:<span id=\"more\"></span></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int STDCALL</span><br><span class=\"line\">  mysql_options(MYSQL *mysql,enum mysql_option option, const void *arg)</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    DBUG_ENTER(&quot;mysql_option&quot;);</span><br><span class=\"line\">    DBUG_PRINT(&quot;enter&quot;,(&quot;option: %d&quot;,(int) option));</span><br><span class=\"line\">    switch (option) &#123;</span><br><span class=\"line\">    case MYSQL\\_OPT\\_CONNECT_TIMEOUT:</span><br><span class=\"line\">      mysql-&gt;options.connect_timeout= *(uint*) arg;</span><br><span class=\"line\">      break;</span><br><span class=\"line\">    /\\*\\* 读超时时间 */</span><br><span class=\"line\">   case MYSQL\\_OPT\\_READ_TIMEOUT:</span><br><span class=\"line\">      mysql-&gt;options.read_timeout= *(uint*) arg;</span><br><span class=\"line\">      break;</span><br><span class=\"line\">    case MYSQL\\_OPT\\_WRITE_TIMEOUT:</span><br><span class=\"line\">      mysql-&gt;options.write_timeout= *(uint*) arg;</span><br><span class=\"line\">      break;</span><br><span class=\"line\">    case MYSQL\\_OPT\\_COMPRESS:</span><br><span class=\"line\">      mysql-&gt;options.compress= 1;</span><br><span class=\"line\"></span><br><span class=\"line\">     /\\* 以下省略 */</span><br></pre></td></tr></table></figure>\n<p>但是, 可惜的是, 目前只有mysqli扩展, 把mysql_options完全暴露给了PHP:<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PHP_FUNCTION(mysqli_options)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"> /\\*\\* 有省略 */</span><br><span class=\"line\">     switch (Z\\_TYPE\\_PP(mysql_value)) &#123;</span><br><span class=\"line\">        /\\*\\* 没有任何限制, 直接传递给mysql_options */</span><br><span class=\"line\">        case IS_STRING:</span><br><span class=\"line\">            ret = mysql_options(mysql-&gt;mysql, mysql_option, Z\\_STRVAL\\_PP(mysql_value));</span><br><span class=\"line\">            break;</span><br><span class=\"line\">         default:</span><br><span class=\"line\">            convert\\_to\\_long_ex(mysql_value);</span><br><span class=\"line\">             l_value = Z\\_LVAL\\_PP(mysql_value);</span><br><span class=\"line\">            ret = mysql_options(mysql-&gt;mysql, mysql_option, (char *)&amp;l_value);</span><br><span class=\"line\">            break;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    RETURN_BOOL(!ret);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>但是因为Mysqli并没有导出这个常量, 所以我们需要通过查看MySQL的代码, 得到MYSQL_OPT_READ_TIMEOUT的实际值, 然后直接调用mysql_options:<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">enum mysql_option</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  MYSQL\\_OPT\\_CONNECT_TIMEOUT, MYSQL\\_OPT\\_COMPRESS, MYSQL\\_OPT\\_NAMED_PIPE,</span><br><span class=\"line\">  MYSQL\\_INIT\\_COMMAND, MYSQL\\_READ\\_DEFAULT_FILE, MYSQL\\_READ\\_DEFAULT_GROUP,</span><br><span class=\"line\">  MYSQL\\_SET\\_CHARSET_DIR, MYSQL\\_SET\\_CHARSET_NAME, MYSQL\\_OPT\\_LOCAL_INFILE,</span><br><span class=\"line\">   MYSQL\\_OPT\\_PROTOCOL, MYSQL\\_SHARED\\_MEMORY\\_BASE\\_NAME, MYSQL\\_OPT\\_READ_TIMEOUT,</span><br><span class=\"line\">  MYSQL\\_OPT\\_WRITE_TIMEOUT, MYSQL\\_OPT\\_USE_RESULT,</span><br><span class=\"line\">  MYSQL\\_OPT\\_USE\\_REMOTE\\_CONNECTION, MYSQL\\_OPT\\_USE\\_EMBEDDED\\_CONNECTION,</span><br><span class=\"line\">  MYSQL\\_OPT\\_GUESS_CONNECTION, MYSQL\\_SET\\_CLIENT_IP, MYSQL\\_SECURE\\_AUTH,</span><br><span class=\"line\">  MYSQL\\_REPORT\\_DATA_TRUNCATION, MYSQL\\_OPT\\_RECONNECT,</span><br><span class=\"line\">  MYSQL\\_OPT\\_SSL\\_VERIFY\\_SERVER_CERT</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure><br>可以看到, MYSQL_OPT_READ_TIMEOUT为11. 现在, 我们就可以设置查询超时了:<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?php</span><br><span class=\"line\">$mysqli = mysqli_init();</span><br><span class=\"line\">$mysqli-&gt;options(11 /\\*MYSQL\\_OPT\\_READ_TIMEOUT\\*/, 1);</span><br><span class=\"line\">$mysql-&gt;real_connect(***);</span><br></pre></td></tr></table></figure><br>不过, 因为在libmysql中有重试机制(尝试一次, 重试俩次), 所以, 最终我们设置的超时阈值都会三倍于我们设置的值. 也就是说, 如果我们设置了MYSQL_OPT_READ_TIMEOUT为1, 最终会在3s以后超时结束. 也就是说, 我们目前能设置的最短超时时, 就是3秒… 虽说大了点,, 不过总比没有好, 呵呵 PS: 写了一半的时候, 就发现小黑已经写过一篇了, 所以大家也可以参看这篇<a href=\"http://blog.csdn.net/heiyeshuwu/archive/2010/09/08/5869813.aspx\">PHP访问MySQL查询超时处理</a></p>\n",
            "tags": [
                "php服务器",
                "centos6.5",
                "mysql",
                "mysql设置超时，超时"
            ]
        },
        {
            "id": "https://erik.xyz/2014/11/17/mysql-shu-ju-ku-chang-yong-yu-ju/",
            "url": "https://erik.xyz/2014/11/17/mysql-shu-ju-ku-chang-yong-yu-ju/",
            "title": "mysql数据库常用语句",
            "date_published": "2014-11-17T13:55:00.000Z",
            "content_html": "<p>最近在做ecshop发现mysql忘了一大堆，复习一下。<br>name数据库  name1表格1  依次类推 </p>\n<p>create database name character set ‘utf8’;  创建数据库及编码方式（一键式创建）</p>\n<p>crate database name;  创建数据库 </p>\n<p>show databases;   查看数据库名称（列举数据库） </p>\n<p>use name;  选择数据库（进入数据库） </p>\n<p>drop database name;   删除数据库<br><span id=\"more\"></span><br>update 表格 set 字段1=值1,字段2=值2 where id=number;  更新数据库，字段值如果是具体值要加引号，number是id的数值代称</p>\n<p>ceate table name1(id name email phone);  创建数据表 </p>\n<p>auto_increment 自动编号 </p>\n<p>primary key 主键  </p>\n<p>unique key  约束键 </p>\n<p>desc name1;  查看表格结构   </p>\n<p>show columns from name1;   查看表格结构 </p>\n<p>default max;   默认数值 </p>\n<p>select * from name1;   查看数据表数据</p>\n<p>show create database name;   查看数据库编码</p>\n<p>alter database character set ‘utf8’;    设置数据库编码 </p>\n<p>alter table 表格 modify 字段 新数据类型;     修改字段数据类型 </p>\n<p>alter table 表格 change 字段 新字段 新数据类型;    修改字段和数据类型 </p>\n<p>alter table 表格 add 新字段 数据类型;   添加字段 first 可选参数  将新添加的字段设置为表格的第一个字段 after 将新添加的字段添加到指定的已存在字段之后 alter table 表格 </p>\n<p>drop 字段;   删除字段</p>\n<p>alter table 表格 modify 字段1 数据类型 </p>\n<p>first/after 字段2;   修改字段位置（前/后）</p>\n<p>alter table 表格 add 字段 数据类型 </p>\n<p>first/after;   表格中添加字段在首/末 <!--more--></p>\n<p>alter table 表格 </p>\n<p>ENGINE |CHARSET=MyISAM | utf8;  修改引擎或编码方式 </p>\n<p>alter table 表格</p>\n<p>drop foreign key 外约束键;   删除表的外约束键</p>\n<p>alter table 子表</p>\n<p>drop foregin key 外键;  解除子父表关联 </p>\n<p>alter table 表格 rename 新表格名;  修改表格名 </p>\n<p>select name from 表格; <!--more--> 查询类别 ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————-<br>select distinct 类别 from 表格;   查询字段不得重复 select username from name1 where username=’admin’;    查询数据表中属于字段username的admin <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em>*</em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> select id,usename,email from name1 where id in (1,20) order by username;    查询数据表中字段username的id为1到20的记录  在in前加not则反之 实际应用中比如要查询一个二级管理员登陆且不显示超级管理的管理员列表，剩余的都显示，那么就用到in了 例：select id,username,email from name1 where username not in (“admin”) order by id desc; <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em>**</em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong><br>select id,username from name1 where id between 1 and 20;   查询1到20之间的id数据   between前加not则反之 select id, username from name1 where username like ‘b%’;    查询以b开头的所有数据</p>\n<p>insert name1 (id,user,pwd) values (‘1’,’123’,’admin’);   写入表格数据 select 字段,字段1,字段2 from name1 where 字段2 is null;  查询表中字段2为空的记录的字段、字段1、字段2的值   null前面加not反之 select 字段,字段1 from 表格 where 字段1 like ‘_ <em> </em> _y’;   查询表中以字母y结尾，且y前只有4个字母的记录 select 字段,字段1,字段2,字段3 from name1 where 字段=’值’ and 字段1&gt;=’5’;    查询表中字段的值并且值大于5的记录数据 select 字段,字段1,字段2,字段3 from name1 where 字段=’6’ or 字段=’5’;   查询字段值为5或6的记录数据值,多字段查询（或多条件查询） =select 字段,字段1,字段2,字段3 from name1 where 字段 in(5,6); </p>\n<p>select distinct id from 表;  查询表的id值，并返回id不重复</p>\n<p>select distinct 字段id from 表格;  查询结果不重复</p>\n<p>select  字段 from 表格 order by 字段;   对查询结果升序排序，如果是多列排序在字段后面加逗号（,）分开字段</p>\n<p>select 字段1,字段2  from 表格 order by 字段1 desc;  查询结果按字段1的结果降序排列</p>\n<p>select 字段1,字段2 from 表格 order by 字段1 desc,字段2;  多值不同排列，字段1降序排列，字段2升序排列</p>\n<p>————————————————————————————————————————————————————</p>\n<p>mysqldump -u user -h host -p dbname [tbname,[tbname…]]&gt;filename.sql   tbname表示数据库中的表名，多个表之间空格隔开</p>\n<p>例：mysqldump -u user -h host -p bookDB book&gt;D:/test/book_01.sql   创建book_01.sql的备份</p>\n<p>mysqldump -u user -h host -p —databases [tbname,[tbname…]]&gt;filename.sql  备份多个数据库</p>\n<p>例：mysqldump -u user -h host -p —phone bookDB book&gt;D:/test/book_01_phone.sql   创建book_01_phone.sql的备份，其中包含2个数据库，如果使用—all—databases则是备份所有的数据库</p>\n<p>mysql -u user -p [dbname]&lt;filename.sql  mysql还原</p>\n",
            "tags": [
                "数据库",
                "mysql"
            ]
        }
    ]
}