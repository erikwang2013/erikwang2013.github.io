{
    "version": "https://jsonfeed.org/version/1",
    "title": "艾瑞可erik • All posts by \"hadoop\" tag • All posts by \"undefined\" categories",
    "description": "一只PHP开发的程序猿，偶尔做做运维、Goland、Python、Java、摄影、画画、写作、顺便睡觉，反正整站都搞过。",
    "home_page_url": "https://erik.xyz",
    "items": [
        {
            "id": "https://erik.xyz/2025/07/25/spark-hive-hadoo-combination-guide/",
            "url": "https://erik.xyz/2025/07/25/spark-hive-hadoo-combination-guide/",
            "title": "Spark、Hive、Hadoop选择与组合使用指南",
            "date_published": "2025-07-25T13:36:00.000Z",
            "content_html": "<p>在构建大数据平台时，Spark、Hive 和 Hadoop 的关系是<strong>互补协作</strong>而非互斥。选择哪种技术以及如何组合取决于你的具体需求（数据量、处理速度、查询复杂度、成本、团队技能）。以下是如何选择和结合使用的指南：</p>\n<h2 id=\"核心定位与区别\"><a href=\"#核心定位与区别\" class=\"headerlink\" title=\"核心定位与区别\"></a>核心定位与区别</h2><ol>\n<li><strong>Hadoop (主要指 HDFS + MapReduce/YARN):</strong><ul>\n<li><strong>定位：</strong> 分布式存储(HDFS) + 基础资源管理和批处理框架(MapReduce/YARN)。</li>\n<li><strong>优势：</strong><ul>\n<li><strong>高可靠、高容错的分布式存储 (HDFS):</strong> 存储海量数据的基石。</li>\n<li><strong>成熟的资源管理 (YARN):</strong> 协调集群资源（CPU, 内存）供上层应用（Spark, MapReduce, Hive on MR/Tez）使用。</li>\n<li><strong>极高的可扩展性和成本效益：</strong> 能在廉价硬件上构建大规模集群。</li>\n</ul>\n</li>\n<li><strong>劣势：</strong> MapReduce 计算模型<strong>速度慢</strong>（尤其迭代计算、交互式查询），编程相对复杂。<span id=\"more\"></span></li>\n</ul>\n</li>\n<li><p><strong>Hive:</strong></p>\n<ul>\n<li><strong>定位：</strong> 构建在 Hadoop 之上的<strong>数据仓库框架</strong>。</li>\n<li><strong>优势：</strong><ul>\n<li><strong>类 SQL 接口 (HiveQL):</strong> 极大降低了使用门槛，让熟悉 SQL 的分析师和工程师能处理大数据。</li>\n<li><strong>强大的元数据管理 (Metastore):</strong> 管理表结构、分区、数据类型等，是数据治理的关键。</li>\n<li><strong>批处理优化：</strong> 将 SQL 查询转换为 MapReduce/Tez/Spark 作业执行。</li>\n</ul>\n</li>\n<li><strong>劣势：</strong> 传统上基于 MapReduce/Tez，<strong>延迟较高</strong>，不适合低延迟交互式查询或流处理（虽然有 LLAP 和 Hive on Spark 改进）。</li>\n</ul>\n</li>\n<li><p><strong>Spark:</strong></p>\n<ul>\n<li><strong>定位：</strong> 统一<strong>的、高性能的分布式计算引擎</strong>。</li>\n<li><strong>优势：</strong><ul>\n<li><strong>极快的速度：</strong> 基于内存计算、DAG 执行引擎、高度优化的执行计划，比 MapReduce 快几个数量级。</li>\n<li><strong>统一引擎：</strong> 支持批处理(Spark SQL)、流处理(Spark Streaming, Structured Streaming)、机器学习(MLlib)、图计算(GraphX)。</li>\n<li><strong>易用的 API：</strong> 提供 Scala, Java, Python, R 等多种语言的 API，开发效率高。</li>\n<li><strong>灵活的部署：</strong> 可以在 YARN (Hadoop), Mesos, Kubernetes 或 Standalone 模式上运行。</li>\n<li><strong>与 Hive 集成：</strong> 可以直接读取 Hive Metastore 中的元数据，运行 HiveQL 查询（Spark SQL）。</li>\n</ul>\n</li>\n<li><strong>劣势：</strong> 对内存要求较高，纯内存计算成本可能高于基于磁盘的 MapReduce（但速度优势通常远超成本差异）；非常复杂的计算可能需要更精细的内存调优。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"如何选择？\"><a href=\"#如何选择？\" class=\"headerlink\" title=\"如何选择？\"></a>如何选择？</h2><ol>\n<li><p><strong>存储层：</strong></p>\n<ul>\n<li><strong>HDFS 通常是默认和基石选择：</strong> 如果你需要存储 PB 级甚至 EB 级数据，要求高容错、高可靠、成本效益，<strong>HDFS 几乎是必选项</strong>。它是 Spark 和 Hive 最常见的数据来源和存储目的地。</li>\n<li><strong>替代方案：</strong> 云存储（S3, GCS, ADLS）越来越流行，它们提供无限扩展、按需付费、高可用性，并且 Spark/Hive 都支持直接读写。选择云存储通常能简化运维。</li>\n</ul>\n</li>\n<li><p><strong>计算引擎：</strong></p>\n<ul>\n<li><strong>需要极致的处理速度（批处理、流处理、迭代算法、机器学习）？</strong><ul>\n<li><strong>首选 Spark：</strong> 它在绝大多数计算场景下都远快于 MapReduce/Tez。</li>\n</ul>\n</li>\n<li><strong>主要需求是使用熟悉的 SQL 进行批处理分析和报表，团队 SQL 技能强？</strong><ul>\n<li><strong>Hive 是很好的起点：</strong> 利用其强大的元数据管理和 SQL 接口。但<strong>强烈建议将执行引擎配置为 Spark (Hive on Spark)</strong>，而不是 MapReduce 或 Tez，以获得显著的性能提升。</li>\n<li><strong>Spark SQL：</strong> 也可以直接使用 Spark SQL 来执行 SQL 查询，它同样支持 HiveQL 语法（兼容 Hive Metastore），性能通常优于 Hive on Spark。如果你已经在用 Spark 做其他事情（如 ETL, ML），Spark SQL 是更统一的选择。</li>\n</ul>\n</li>\n<li><strong>需要亚秒级响应的交互式查询？</strong><ul>\n<li><strong>Hive LLAP：</strong> Hive 的 Live Long and Process 模式提供内存缓存和守护进程，加速查询。</li>\n<li><strong>Spark Thrift Server / JDBC/ODBC Server：</strong> 允许 BI 工具通过标准接口连接 Spark SQL 进行交互式查询。</li>\n<li><strong>专用交互式引擎：</strong> 如 Presto, Impala, Druid 等（这些通常也依赖 HDFS/S3 存储和 Hive Metastore）。</li>\n</ul>\n</li>\n<li><strong>需要实时/准实时流处理？</strong><ul>\n<li><strong>Spark Structured Streaming：</strong> 首选的统一引擎方案。</li>\n<li><strong>Flink：</strong> 另一个强大的流处理引擎（Spark 和 Flink 是当前流处理的主流）。</li>\n</ul>\n</li>\n<li><strong>需要做机器学习或图计算？</strong><ul>\n<li><strong>Spark MLlib / GraphX：</strong> Spark 的内置库提供了丰富的功能。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong>元数据管理：</strong></p>\n<ul>\n<li><strong>Hive Metastore (HMS) 是事实标准：</strong> 无论你主要使用 Hive、Spark SQL 还是其他查询引擎（Presto, Impala），<strong>强烈建议使用 Hive Metastore</strong> 来集中管理表结构、分区、数据类型、存储位置等元数据。这保证了不同引擎对数据有一致的视图，是数据治理的基础。Spark 原生支持读写 Hive Metastore。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"典型的组合使用模式\"><a href=\"#典型的组合使用模式\" class=\"headerlink\" title=\"典型的组合使用模式\"></a>典型的组合使用模式</h2><ol>\n<li><p><strong>经典批处理数据仓库 (Hive-Centric):</strong></p>\n<ul>\n<li><strong>存储:</strong> HDFS 或 S3/GCS/ADLS</li>\n<li><strong>元数据:</strong> Hive Metastore</li>\n<li><strong>ETL/计算：</strong><ul>\n<li><em>传统/基础版：</em> Hive on MapReduce/Tez (利用 HiveQL 编写 ETL 和查询逻辑)</li>\n<li><strong>现代/高效版：* </strong>Hive on Spark<strong> (HiveQL -&gt; Spark Job) 或 </strong>Spark SQL** (Spark API/SQL -&gt; Spark Job)</li>\n</ul>\n</li>\n<li><strong>查询：</strong> Hive CLI/Beeline (执行 HiveQL)，Spark SQL Thrift Server (支持 BI 工具连接)</li>\n<li><strong>场景：</strong> 传统的 T+1 数据报表，大规模历史数据分析。</li>\n</ul>\n</li>\n<li><p><strong>高性能统一分析平台 (Spark-Centric):</strong></p>\n<ul>\n<li><strong>存储:</strong> HDFS 或 S3/GCS/ADLS</li>\n<li><strong>元数据:</strong> Hive Metastore (Spark SQL 直接读写 HMS)</li>\n<li><strong>计算：</strong> <strong>Spark</strong> 作为核心引擎<ul>\n<li><em>批处理 ETL:</em> 使用 Spark DataFrame/Dataset API 或 Spark SQL 清洗、转换、加载数据到 Hive 表。</li>\n<li><em>流处理:</em> 使用 Spark Structured Streaming 处理 Kafka 等数据源，结果写入 Hive 表或直接供下游使用。</li>\n<li><em>交互式查询:</em> 通过 Spark Thrift Server 支持 BI 工具连接 Spark SQL。</li>\n<li><em>机器学习:</em> 使用 Spark MLlib 训练模型。</li>\n</ul>\n</li>\n<li><strong>资源管理:</strong> YARN (Hadoop) 或 Kubernetes</li>\n<li><strong>场景：</strong> 需要融合批处理、流处理、机器学习、交互式查询等多种工作负载的现代数据平台。Hive Metastore 提供了统一的数据目录。</li>\n</ul>\n</li>\n<li><p><strong>云原生数据湖：</strong></p>\n<ul>\n<li><strong>存储:</strong> S3, GCS, ADLS (对象存储)</li>\n<li><strong>元数据:</strong> Hive Metastore (托管服务如 AWS Glue Data Catalog 是 HMS 的兼容实现)</li>\n<li><strong>计算：</strong><ul>\n<li><em>Serverless SQL 查询：</em> AWS Athena, Google BigQuery (直接查询 S3/GCS 数据，利用 Glue Catalog 或类似元数据)</li>\n<li><em>自定义处理：</em> <strong>Spark</strong> on EMR/Dataproc/Databricks/Synapse (进行复杂的 ETL、ML、流处理，读写对象存储和元数据服务)</li>\n</ul>\n</li>\n<li><strong>场景：</strong> 利用云服务的弹性、按需付费特性，减少基础设施运维负担。Spark 处理复杂任务，Serverless SQL 处理即席查询。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"总结与关键建议\"><a href=\"#总结与关键建议\" class=\"headerlink\" title=\"总结与关键建议\"></a>总结与关键建议</h2><ol>\n<li><strong>HDFS/对象存储是基石：</strong> 选择适合你的分布式存储（HDFS 或云存储）。</li>\n<li><strong>Hive Metastore 是核心枢纽：</strong> <strong>务必使用</strong> Hive Metastore 或兼容服务（如 AWS Glue）来统一管理元数据，这是打通不同计算引擎的关键。</li>\n<li><strong>Spark 是首选计算引擎：</strong> 对于绝大多数<strong>需要速度</strong>的计算任务（批处理、流处理、ML、交互式SQL），<strong>优先选择 Spark</strong> 替代传统的 MapReduce/Tez。</li>\n<li><strong>Hive 的价值在于 SQL 接口和 Metastore：</strong> 即使主要用 Spark，Hive 的 Metastore 必不可少，HiveQL 接口对于重度 SQL 用户依然有价值（但底层执行应配置为 Spark）。</li>\n<li><strong>Hadoop YARN 是可选的资源管理器：</strong> Spark 可以运行在 YARN、Kubernetes 或 Standalone 上。如果已有 Hadoop 集群，YARN 是自然选择；新建集群，Kubernetes 越来越流行。</li>\n<li><strong>组合是常态：</strong> 几乎没有大型平台只使用其中一种技术。典型组合是：<code>(HDFS/S3) + (Hive Metastore) + (Spark for Processing) + (可选 Hive for SQL interface / LLAP for interactive)</code>。</li>\n</ol>\n<p><strong>简而言之：</strong></p>\n<ul>\n<li><strong>存储数据用什么？</strong> HDFS 或 云存储 (S3/GCS/ADLS)。</li>\n<li><strong>管理表结构用什么？</strong> Hive Metastore (或云服务如 Glue Catalog)。</li>\n<li><strong>跑 ETL、流处理、机器学习、快速 SQL 用什么？</strong> Spark (Spark Core, Spark SQL, Structured Streaming, MLlib)。</li>\n<li><strong>想用熟悉的 SQL 做批处理分析，或者需要加速交互查询？</strong> 可以使用 Hive (但配置 Hive on Spark 或 Hive LLAP)，或者直接用 Spark SQL + Thrift Server。</li>\n</ul>\n<p>根据你的具体场景（数据规模、延迟要求、处理类型、团队技能、预算、云或本地）来调整这些组件的权重和配置。对于新项目，以 Spark 为核心计算引擎，结合 Hive Metastore 和 HDFS/云存储，是最常见且高效的起点。</p>\n",
            "tags": [
                "hadoop",
                "大数据",
                "spark",
                "hive",
                "数据分析"
            ]
        },
        {
            "id": "https://erik.xyz/2017/06/29/hadoop2-8-0-de-bu-shu-an-zhuang-jiao-cheng/",
            "url": "https://erik.xyz/2017/06/29/hadoop2-8-0-de-bu-shu-an-zhuang-jiao-cheng/",
            "title": "hadoop2.8.0的部署安装教程",
            "date_published": "2017-06-29T00:27:00.000Z",
            "content_html": "<p>Hadoop部署准备 本地vmware安装 Linux系统家族中 centos7 下载地址<a href=\"http://101.110.118.58/isoredirect.centos.org/centos/7/isos/x86\\_64/CentOS-7-x86\\_64-Minimal-1611.iso\">http://101.110.118.58/isoredirect.centos.org/centos/7/isos/x86\\_64/CentOS-7-x86\\_64-Minimal-1611.iso</a>   Java对应版本1.8.0_121   Hadoop版本2.8.0下载地址 <a href=\"http://mirror.bit.edu.cn/apache/hadoop/common/\">http://mirror.bit.edu.cn/apache/hadoop/common/</a> 可以根据自己喜好的版本下载</p>\n<h1 id=\"1-基本配置\"><a href=\"#1-基本配置\" class=\"headerlink\" title=\"1.基本配置\"></a>1.基本配置</h1><p>首先安装一个centos7并配置好java Java环境配置 我的java安装地址 /usr/java/ jdk1.8.0_121   编辑java环境 vi ~/.bash_profile 添加或修改 export JAVA_HOME=/usr/java/jdk1.8.0_121 export PATH=$JAVA_HOME/bin:$PATH 执行 . ~/.bash_profile 使变量生效  <span id=\"more\"></span></p>\n<h1 id=\"2-ssh配置\"><a href=\"#2-ssh配置\" class=\"headerlink\" title=\"2.ssh配置\"></a>2.ssh配置</h1><p>先 yum install ssh  安装   然后执行 ssh-keygen -t dsa -P ‘’ -f ~/.ssh/id_dsa 生成密匙</p>\n<h1 id=\"3-hadoop配置\"><a href=\"#3-hadoop配置\" class=\"headerlink\" title=\"3.hadoop配置\"></a>3.hadoop配置</h1><p>把下载好的hadoop解压出来。（我的地址在/roo目录,即完整地址/root/hadoop）   配置环境变量 vi ~/.bash_profile export HADOOP_HOME=/root/hadoop export PATH=$JAVA_HOME/bin:$PATH:$HOME/bin:$HADOOP_HOME/bin 执行 . ~/.bash_profile 使变量生效  </p>\n<h1 id=\"4-hadoop文件配置\"><a href=\"#4-hadoop文件配置\" class=\"headerlink\" title=\"4.hadoop文件配置\"></a>4.hadoop文件配置</h1><p>首先给本机命名个名字：例如我这边是s204   就执行 hostnamectl set-hostname s204 变更主机名字   然后在/root/hadoop目录下 依次执行编辑</p>\n<h2 id=\"vim-etc-hadoop-core-site-xml\"><a href=\"#vim-etc-hadoop-core-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/core-site.xml\"></a>vim etc/hadoop/core-site.xml</h2><p>  在<configuration></configuration>中加入 <property> <name>fs.defaultFS</name> <value>hdfs://s204:9000</value> </property> <property> <name>hadoop.tmp.dir</name> <value>file:/root/hadoop/tmp</value> </property> <property> <name>io.file.buffer.size</name> <value>131702</value> </property> <property> <name>hadoop.proxyuser.hadoop.hosts</name> <value>*</value> </property>   <property> <name>hadoop.proxyuser.hadoop.groups</name> <value>*</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-hdfs-site-xml\"><a href=\"#vim-etc-hadoop-hdfs-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/hdfs-site.xml\"></a>vim etc/hadoop/hdfs-site.xml</h2><p>在<configuration></configuration>中加入   <property> <name>dfs.namenode.name.dir</name> <value>file:/root/hadoop/hdfs/name</value> </property> <property> <name>dfs.datanode.data.dir</name> <value>file:/root/hadoop/hdfs/data</value> </property> <property> <name>dfs.replication</name> <value>3</value> </property> <property> <name>dfs.namenode.secondary.http-address</name> <value>s204:9001</value> </property> <property> <name>dfs.webhdfs.enabled</name> <value>true</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-mapred-site-xml\"><a href=\"#vim-etc-hadoop-mapred-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/mapred-site.xml\"></a>vim etc/hadoop/mapred-site.xml</h2><p>在<configuration></configuration>中加入   <property> <name>mapreduce.framework.name</name> <value>yarn</value> </property> <property> <name>mapreduce.jobhistory.address</name> <value>s204:10020</value> </property> <property> <name>mapreduce.jobhistory.webapp.address</name> <value>s204:19888</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-yarn-site-xml\"><a href=\"#vim-etc-hadoop-yarn-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/yarn-site.xml\"></a>vim etc/hadoop/yarn-site.xml</h2><p>在<configuration></configuration>中加入 <property> <name>yarn.nodemanager.aux-services</name> <value>mapreduce_shuffle</value> </property> <property> <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name> <value>org.apache.hadoop.mapred.ShuffleHandler</value> </property> <property> <name>yarn.resourcemanager.address</name> <value>s204:8032</value> </property> <property> <name>yarn.resourcemanager.scheduler.address</name> <value>s204:8030</value> </property> <property> <name>yarn.resourcemanager.resource-tracker.address</name> <value>s204:8031</value> </property> <property> <name>yarn.resourcemanager.admin.address</name> <value>s204:8033</value> </property> <property> <name>yarn.resourcemanager.webapp.address</name> <value>s204:8088</value> </property> <property> <name>yarn.nodemanager.resource.memory-mb</name> <value>6078</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-yarn-env-sh\"><a href=\"#vim-etc-hadoop-yarn-env-sh\" class=\"headerlink\" title=\"vim etc/hadoop/yarn-env.sh\"></a>vim etc/hadoop/yarn-env.sh</h2><p>  中找到 export JAVA_HOME 去掉注释 编辑java地址 export JAVA_HOME=/usr/java/jdk1.8.0_121   找到JAVA_HEAP_MAX=-Xmx1000m 改为 JAVA_HEAP_MAX=-Xmx1024m  </p>\n<h2 id=\"vim-etc-hadoop-slaves\"><a href=\"#vim-etc-hadoop-slaves\" class=\"headerlink\" title=\"vim etc/hadoop/slaves\"></a>vim etc/hadoop/slaves</h2><p>  清空添加 s204    </p>\n<h1 id=\"网络配置\"><a href=\"#网络配置\" class=\"headerlink\" title=\"网络配置\"></a>网络配置</h1><p>我这ip是 192.168.5.9   编辑网络固定ip vim /etc/sysconfig/network-scripts/ifcfg-ens33   指定固定ip   TYPE=”Ethernet” #BOOTPROTO=”dhcp” DEFROUTE=”yes” PEERDNS=”yes” PEERROUTES=”yes” IPV4_FAILURE_FATAL=”no” IPV6INIT=”yes” IPV6_AUTOCONF=”yes” IPV6_DEFROUTE=”yes” IPV6_PEERDNS=”yes” IPV6_PEERROUTES=”yes” IPV6_FAILURE_FATAL=”no” IPV6_ADDR_GEN_MODE=”stable-privacy” NAME=”ens33” UUID=”b9fe1e5c-be20-47f1-a2d3-e12f5ddb6aa1” DEVICE=”ens33” ONBOOT=”yes” IPADDR0=192.168.5.9 PREFIX0=24 GATEWAY0=192.168.5.2 DNS1=114.114.114.114   然后重启网络 systemctl  restart  network   执行 ip add  查看网络ip是否和设定的一致  </p>\n<h1 id=\"Hadopp启动\"><a href=\"#Hadopp启动\" class=\"headerlink\" title=\"Hadopp启动\"></a>Hadopp启动</h1><p>  进入/root/hadoop目录   执行编译 ./bin/hdfs namenode –format   结果倒数第五行出现 Exiting with status 0 则为成功   然后启动 ./sbin/start-all.sh   启动完毕执行./bin/hdfs dfsadmin –report 查看是否有节点 如果返回 无法连接则为启动失败   执行systemctl stop firewalld.service关闭防火墙  在浏览器输入s204:8088则可以看到hadoop界面  </p>\n<h1 id=\"其他节点配置\"><a href=\"#其他节点配置\" class=\"headerlink\" title=\"其他节点配置\"></a>其他节点配置</h1><p>以上配置完毕后，关闭centos7 然后完全克隆，在新克隆的系统中，更改ip地址和主机名 其中hadoop配置文件 etc/hadoop/hdfs-site.xml  中 <property> <name>dfs.datanode.data.dir</name> <value>file:/root/hadoop/hdfs/data</value> </property>   的file地址不能一样。 我这边三个地址分别为 file:/root/hadoop/hdfs/data file:/root/hadoop/hdfs/data/205 file:/root/hadoop/hdfs/data/206   克隆完毕，配置文件和ip、主机名修改好后。在s204机器中编辑 vim etc/hadoop/slaves 加入 s205 s206   复制ssh令牌免密登录 例如复制到s205 scp ~/.ssh/authorized_keys root@s205:~/.ssh/   其他另个机器也一样操作   另外几个机器也要编译一下   然后在s204停止hadoop   ./sbin/stop-all.sh   再次启动./sbin/start-all.sh   在浏览器就可以看到三个节点。</p>\n",
            "tags": [
                "hadoop",
                "hadoop2.8.0",
                "hadoop安装教程",
                "hadoop安装详细教程",
                "hadoop教程",
                "hadoop部署"
            ]
        }
    ]
}