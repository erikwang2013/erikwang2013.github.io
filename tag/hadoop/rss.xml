<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>艾瑞可erik • Posts by &#34;hadoop&#34; tag • Posts by &#34;undefined&#34; categories</title>
        <link>https://erik.xyz</link>
        <description>一只PHP开发的程序猿，偶尔做做运维、Goland、Python、Java、摄影、画画、写作、顺便睡觉，反正整站都搞过。</description>
        <language>zh-CN</language>
        <pubDate>Fri, 25 Jul 2025 21:36:00 +0800</pubDate>
        <lastBuildDate>Fri, 25 Jul 2025 21:36:00 +0800</lastBuildDate>
        <category>php扩展</category>
        <category>php技巧</category>
        <category>php类库</category>
        <category>php资源</category>
        <category>日志</category>
        <category>工具</category>
        <category>jquery</category>
        <category>jquery插件</category>
        <category>js</category>
        <category>css</category>
        <category>php</category>
        <category>web</category>
        <category>代码</category>
        <category>压缩</category>
        <category>说说</category>
        <category>趣闻</category>
        <category>php服务器</category>
        <category>随笔</category>
        <category>php实例</category>
        <category>转载</category>
        <category>php库</category>
        <category>互联</category>
        <category>项目实战</category>
        <category>javascript</category>
        <category>漏洞</category>
        <category>nginx</category>
        <category>php应用</category>
        <category>浮点</category>
        <category>负载均衡</category>
        <category>kali</category>
        <category>kali安装</category>
        <category>http</category>
        <category>http服务器</category>
        <category>农业系统</category>
        <category>系统设计</category>
        <category>克莱姆法则</category>
        <category>行列式</category>
        <category>n阶行列式</category>
        <category>支付系统</category>
        <category>支付</category>
        <category>centos</category>
        <category>linux</category>
        <category>apache优化</category>
        <category>apache隐藏index</category>
        <category>nginx优化</category>
        <category>nginx隐藏index</category>
        <category>日常</category>
        <category>seo</category>
        <category>优化</category>
        <category>摘要</category>
        <category>文章</category>
        <category>游记</category>
        <category>ca证书</category>
        <category>证书生成</category>
        <category>二战</category>
        <category>二战熊</category>
        <category>西伯利亚熊</category>
        <category>centos软件</category>
        <category>yum仓库</category>
        <category>软件</category>
        <category>centos安装chromium报错</category>
        <category>chromium安装报错</category>
        <category>svn</category>
        <category>代码提交</category>
        <category>deb</category>
        <category>deb/rpm互转</category>
        <category>deb转rpm</category>
        <category>rpm互转</category>
        <category>centos7安装steam</category>
        <category>centos安装steam</category>
        <category>centos安装吃鸡steam</category>
        <category>linux安装steam</category>
        <category>steam安装</category>
        <category>centos软件安装</category>
        <category>centos6.5</category>
        <category>linux系统</category>
        <category>centos7安装Redis Desktop Manager</category>
        <category>centos7安装redis桌面</category>
        <category>centos安装redis桌面</category>
        <category>linux安装centos7安装Redis Desktop Manager</category>
        <category>Redis Desktop Manager</category>
        <category>redis桌面</category>
        <category>centos7</category>
        <category>centos7-wine</category>
        <category>wine</category>
        <category>wine安装</category>
        <category>root密码</category>
        <category>root密码重置</category>
        <category>忘记root密码</category>
        <category>memcache</category>
        <category>memcached</category>
        <category>生活手记</category>
        <category>艾瑞可erik</category>
        <category>程序员</category>
        <category>开源云</category>
        <category>容器</category>
        <category>cncf</category>
        <category>监控</category>
        <category>composer</category>
        <category>composer部署</category>
        <category>内网部署composer</category>
        <category>cphalcon</category>
        <category>cphalcon报错</category>
        <category>css中的em</category>
        <category>响应式字体</category>
        <category>响应式布局样式</category>
        <category>proxy代理搭建</category>
        <category>代理服务器搭建</category>
        <category>proxy服务器</category>
        <category>查找</category>
        <category>排序</category>
        <category>快速排序</category>
        <category>冒泡排序</category>
        <category>二分查找</category>
        <category>datahub</category>
        <category>datahub安装</category>
        <category>deepin</category>
        <category>emergency</category>
        <category>emergency mode</category>
        <category>deepin黑屏</category>
        <category>开发语言</category>
        <category>开发</category>
        <category>清理系统</category>
        <category>清理c盘</category>
        <category>dns</category>
        <category>域名监测</category>
        <category>网站监测</category>
        <category>docker</category>
        <category>php安装</category>
        <category>杂谈</category>
        <category>ecshop</category>
        <category>框架</category>
        <category>beego数据分页</category>
        <category>分页</category>
        <category>elasticsearch</category>
        <category>elasticsearch搭建</category>
        <category>elasticsearch集群</category>
        <category>系统</category>
        <category>emm</category>
        <category>mdm</category>
        <category>phone</category>
        <category>手机</category>
        <category>新闻</category>
        <category>免费</category>
        <category>jenkis</category>
        <category>jenkis教程</category>
        <category>算法</category>
        <category>随笔吐槽</category>
        <category>ping</category>
        <category>ping服务器</category>
        <category>各大网站ping</category>
        <category>搜引擎ping服务器</category>
        <category>go获取ip</category>
        <category>im</category>
        <category>go中pdf生成</category>
        <category>go中限流</category>
        <category>go对接快递签名</category>
        <category>go时间获取</category>
        <category>go类型转换</category>
        <category>微服务</category>
        <category>go-zero</category>
        <category>rpc</category>
        <category>go加密</category>
        <category>go解密</category>
        <category>归</category>
        <category>吐槽</category>
        <category>php大全</category>
        <category>php资料</category>
        <category>hadoop</category>
        <category>hadoop2.8.0</category>
        <category>hadoop安装教程</category>
        <category>hadoop安装详细教程</category>
        <category>hadoop教程</category>
        <category>hadoop部署</category>
        <category>hadoop3</category>
        <category>hadoop配置</category>
        <category>log4j2</category>
        <category>数据库</category>
        <category>hbase安装教程</category>
        <category>hbase</category>
        <category>http1.1</category>
        <category>http2.0</category>
        <category>会话</category>
        <category>会话原理</category>
        <category>hyperf</category>
        <category>杂录</category>
        <category>新冠肺炎</category>
        <category>springboot</category>
        <category>springboot内网部署</category>
        <category>linux恢复</category>
        <category>linux误删</category>
        <category>linux命令</category>
        <category>linux命令汇总</category>
        <category>jenkins</category>
        <category>jetbtrains</category>
        <category>phpstorm</category>
        <category>搜索引擎</category>
        <category>图片</category>
        <category>素材</category>
        <category>jq</category>
        <category>jq侧边导航</category>
        <category>侧边导航</category>
        <category>js判断浏览器</category>
        <category>js判断浏览器版本</category>
        <category>判断浏览器</category>
        <category>浏览器版本判断</category>
        <category>获取浏览器信息</category>
        <category>kali右键汉化</category>
        <category>kali桌面右键汉化</category>
        <category>kali右键创建文件</category>
        <category>区块链</category>
        <category>lanmp</category>
        <category>php环境独立配置</category>
        <category>服务器</category>
        <category>劳动纠纷</category>
        <category>追缴工资</category>
        <category>申请仲裁</category>
        <category>flash</category>
        <category>表单</category>
        <category>linux报错</category>
        <category>linux中update-command-not-found</category>
        <category>linux运行命令报错</category>
        <category>web前端</category>
        <category>web优化</category>
        <category>撮合算法</category>
        <category>撮合</category>
        <category>php撮合算法</category>
        <category>maven搭建库</category>
        <category>maven</category>
        <category>maven内网库</category>
        <category>高级缓存配置</category>
        <category>mongodb</category>
        <category>mongodb权限</category>
        <category>可穿戴设备</category>
        <category>mysql</category>
        <category>分库分表</category>
        <category>mysql应对千万级</category>
        <category>mysql瓶颈</category>
        <category>mysql瓶颈解决办法</category>
        <category>redis</category>
        <category>数据一致性</category>
        <category>mysql消息</category>
        <category>mysql队列</category>
        <category>mysql高并发</category>
        <category>mysql存储</category>
        <category>mysql引擎</category>
        <category>mysql数据表设计选择</category>
        <category>mysql监控</category>
        <category>mysql性能</category>
        <category>内网支付</category>
        <category>内网穿透</category>
        <category>支付接口本地化开发</category>
        <category>本地挂网</category>
        <category>穿透</category>
        <category>go</category>
        <category>new和make的区别</category>
        <category>红包算法</category>
        <category>深圳劳动法服务部门</category>
        <category>非关系型数据库</category>
        <category>onethink</category>
        <category>oop</category>
        <category>php管理系统</category>
        <category>开放接口开发</category>
        <category>开源工具</category>
        <category>桌面共享工具</category>
        <category>openresty</category>
        <category>openvas</category>
        <category>openvas安装</category>
        <category>php架构</category>
        <category>php服务</category>
        <category>php服务设计</category>
        <category>php项目</category>
        <category>php架构设计</category>
        <category>php变量</category>
        <category>php超级全局变量</category>
        <category>php超级变量</category>
        <category>php基本类型</category>
        <category>php数据类型</category>
        <category>php设计模式</category>
        <category>php对接微信支付</category>
        <category>微信支付</category>
        <category>微信支付回调</category>
        <category>游戏</category>
        <category>php函数</category>
        <category>php随机数</category>
        <category>php获取闰年</category>
        <category>闰年.php时间</category>
        <category>php环境</category>
        <category>php集成环境</category>
        <category>服务器集成环境</category>
        <category>数组函数</category>
        <category>数组排序函数</category>
        <category>php数学函数</category>
        <category>php面试题</category>
        <category>php面向对象</category>
        <category>面向对象</category>
        <category>php-zookeeper</category>
        <category>zookeeper3.5.5</category>
        <category>php-zookeeper扩展</category>
        <category>php串口开发</category>
        <category>php倒计时</category>
        <category>php时间</category>
        <category>倒计时</category>
        <category>计算时间</category>
        <category>PHP数组</category>
        <category>字符串函数</category>
        <category>排序函数</category>
        <category>php的SPL</category>
        <category>SPL手册</category>
        <category>PHP算法</category>
        <category>php递归</category>
        <category>递归</category>
        <category>phpunit</category>
        <category>phpunit安装</category>
        <category>php过滤</category>
        <category>过滤</category>
        <category>foreach</category>
        <category>foreach报错</category>
        <category>php中foreach报错</category>
        <category>php中if</category>
        <category>php中if判断</category>
        <category>php的if</category>
        <category>php字符串</category>
        <category>php7中sphinx</category>
        <category>php7中sphinx扩展</category>
        <category>sphinx扩展</category>
        <category>plc</category>
        <category>python</category>
        <category>python库</category>
        <category>a标签</category>
        <category>a标签虚线</category>
        <category>虚线框</category>
        <category>R语言</category>
        <category>数据随机化</category>
        <category>redis总结</category>
        <category>redis命令</category>
        <category>redis监控</category>
        <category>redis锁</category>
        <category>redis分布式锁</category>
        <category>任意金额输入</category>
        <category>10元、5元、2元</category>
        <category>队列</category>
        <category>栈</category>
        <category>顺序表</category>
        <category>链表</category>
        <category>数据结构</category>
        <category>线性结构</category>
        <category>浏览器禁止操作视频</category>
        <category>禁止视频</category>
        <category>响应慢</category>
        <category>页面优化</category>
        <category>js编辑</category>
        <category>runjs</category>
        <category>在线编辑</category>
        <category>rust</category>
        <category>rust配置</category>
        <category>seajs</category>
        <category>session</category>
        <category>路由器烧录</category>
        <category>烧录</category>
        <category>极路由2烧录</category>
        <category>砖头烧录</category>
        <category>免费服务器</category>
        <category>空间</category>
        <category>资源</category>
        <category>深圳政府电话</category>
        <category>深圳电话</category>
        <category>特区电话</category>
        <category>居住证</category>
        <category>居住证签注</category>
        <category>深圳新居住证</category>
        <category>国庆骑行</category>
        <category>深圳珠海骑行</category>
        <category>骑行</category>
        <category>世界那么大</category>
        <category>css3</category>
        <category>css在线生成工具</category>
        <category>css工具</category>
        <category>php正则</category>
        <category>正则</category>
        <category>shodan</category>
        <category>黑谷歌</category>
        <category>黒帽搜素</category>
        <category>shopex</category>
        <category>可视化数据</category>
        <category>数据</category>
        <category>数据表</category>
        <category>socket通信</category>
        <category>socket多进程</category>
        <category>socket</category>
        <category>json</category>
        <category>json数组</category>
        <category>json解析</category>
        <category>大数据</category>
        <category>spark</category>
        <category>hive</category>
        <category>数据分析</category>
        <category>sql</category>
        <category>sql优化</category>
        <category>css3兼容360浏览器兼容模式</category>
        <category>css圆角</category>
        <category>结构体转map</category>
        <category>config</category>
        <category>thinkphp</category>
        <category>配置文件</category>
        <category>树</category>
        <category>二叉树</category>
        <category>js插件</category>
        <category>virtualbox</category>
        <category>hyper-v</category>
        <category>鸿蒙开发</category>
        <category>web自适应</category>
        <category>响应式布局</category>
        <category>响应式所有分辨率</category>
        <category>自适应布局</category>
        <category>自适应所有分辨率</category>
        <category>webman</category>
        <category>mysql设置超时，超时</category>
        <category>markdown</category>
        <category>wget</category>
        <category>wget抓取</category>
        <category>网站抓取</category>
        <category>我在</category>
        <category>wordpress</category>
        <category>wordpress标签</category>
        <category>域名合并</category>
        <category>wpscan</category>
        <category>usbrip</category>
        <category>无限极分类</category>
        <category>php无限极</category>
        <category>分类tree</category>
        <category>无限极分类树型</category>
        <category>xhprof</category>
        <category>laravel</category>
        <category>composer插件</category>
        <category>html</category>
        <category>响应式分辨率</category>
        <category>响应式调试</category>
        <category>自适应屏幕</category>
        <category>携程</category>
        <category>携程攻击</category>
        <category>携程网站瘫痪</category>
        <category>物理删除</category>
        <category>3D</category>
        <category>动画</category>
        <category>平台</category>
        <category>虚幻4引擎编辑</category>
        <category>生成唯一id</category>
        <category>生成id</category>
        <category>发邮件</category>
        <category>邮件函数</category>
        <category>储蓄卡免年费</category>
        <category>银行卡</category>
        <category>银行卡免年费</category>
        <category>composer安装</category>
        <category>composer配置</category>
        <category>项目创建composer</category>
        <category>mysql优化</category>
        <category>mysql读写优化</category>
        <category>数据库优化，mysql语句优化</category>
        <category>php加密</category>
        <category>php技术</category>
        <category>夕阳</category>
        <category>mysql函数</category>
        <category>php中mysql函数</category>
        <category>互联网时代</category>
        <category>开源技术</category>
        <category>web框架</category>
        <category>php抓取图片</category>
        <category>php批量抓取页面图片</category>
        <category>邮箱服务器</category>
        <category>正则表达式</category>
        <category>翻墙</category>
        <category>谷歌</category>
        <category>谷歌搜索</category>
        <item>
            <guid isPermalink="true">https://erik.xyz/2025/07/25/spark-hive-hadoo-combination-guide/</guid>
            <title>Spark、Hive、Hadoop选择与组合使用指南</title>
            <link>https://erik.xyz/2025/07/25/spark-hive-hadoo-combination-guide/</link>
            <category>hadoop</category>
            <category>大数据</category>
            <category>spark</category>
            <category>hive</category>
            <category>数据分析</category>
            <pubDate>Fri, 25 Jul 2025 21:36:00 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;在构建大数据平台时，Spark、Hive 和 Hadoop 的关系是&lt;strong&gt;互补协作&lt;/strong&gt;而非互斥。选择哪种技术以及如何组合取决于你的具体需求（数据量、处理速度、查询复杂度、成本、团队技能）。以下是如何选择和结合使用的指南：&lt;/p&gt;
&lt;h2 id=&#34;核心定位与区别&#34;&gt;&lt;a href=&#34;#核心定位与区别&#34; class=&#34;headerlink&#34; title=&#34;核心定位与区别&#34;&gt;&lt;/a&gt;核心定位与区别&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Hadoop (主要指 HDFS + MapReduce/YARN):&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定位：&lt;/strong&gt; 分布式存储(HDFS) + 基础资源管理和批处理框架(MapReduce/YARN)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势：&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;高可靠、高容错的分布式存储 (HDFS):&lt;/strong&gt; 存储海量数据的基石。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;成熟的资源管理 (YARN):&lt;/strong&gt; 协调集群资源（CPU, 内存）供上层应用（Spark, MapReduce, Hive on MR/Tez）使用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;极高的可扩展性和成本效益：&lt;/strong&gt; 能在廉价硬件上构建大规模集群。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;劣势：&lt;/strong&gt; MapReduce 计算模型&lt;strong&gt;速度慢&lt;/strong&gt;（尤其迭代计算、交互式查询），编程相对复杂。&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Hive:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定位：&lt;/strong&gt; 构建在 Hadoop 之上的&lt;strong&gt;数据仓库框架&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势：&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;类 SQL 接口 (HiveQL):&lt;/strong&gt; 极大降低了使用门槛，让熟悉 SQL 的分析师和工程师能处理大数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;强大的元数据管理 (Metastore):&lt;/strong&gt; 管理表结构、分区、数据类型等，是数据治理的关键。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;批处理优化：&lt;/strong&gt; 将 SQL 查询转换为 MapReduce/Tez/Spark 作业执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;劣势：&lt;/strong&gt; 传统上基于 MapReduce/Tez，&lt;strong&gt;延迟较高&lt;/strong&gt;，不适合低延迟交互式查询或流处理（虽然有 LLAP 和 Hive on Spark 改进）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Spark:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定位：&lt;/strong&gt; 统一&lt;strong&gt;的、高性能的分布式计算引擎&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;优势：&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;极快的速度：&lt;/strong&gt; 基于内存计算、DAG 执行引擎、高度优化的执行计划，比 MapReduce 快几个数量级。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;统一引擎：&lt;/strong&gt; 支持批处理(Spark SQL)、流处理(Spark Streaming, Structured Streaming)、机器学习(MLlib)、图计算(GraphX)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;易用的 API：&lt;/strong&gt; 提供 Scala, Java, Python, R 等多种语言的 API，开发效率高。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活的部署：&lt;/strong&gt; 可以在 YARN (Hadoop), Mesos, Kubernetes 或 Standalone 模式上运行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;与 Hive 集成：&lt;/strong&gt; 可以直接读取 Hive Metastore 中的元数据，运行 HiveQL 查询（Spark SQL）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;劣势：&lt;/strong&gt; 对内存要求较高，纯内存计算成本可能高于基于磁盘的 MapReduce（但速度优势通常远超成本差异）；非常复杂的计算可能需要更精细的内存调优。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;如何选择？&#34;&gt;&lt;a href=&#34;#如何选择？&#34; class=&#34;headerlink&#34; title=&#34;如何选择？&#34;&gt;&lt;/a&gt;如何选择？&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;存储层：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HDFS 通常是默认和基石选择：&lt;/strong&gt; 如果你需要存储 PB 级甚至 EB 级数据，要求高容错、高可靠、成本效益，&lt;strong&gt;HDFS 几乎是必选项&lt;/strong&gt;。它是 Spark 和 Hive 最常见的数据来源和存储目的地。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;替代方案：&lt;/strong&gt; 云存储（S3, GCS, ADLS）越来越流行，它们提供无限扩展、按需付费、高可用性，并且 Spark/Hive 都支持直接读写。选择云存储通常能简化运维。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;计算引擎：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;需要极致的处理速度（批处理、流处理、迭代算法、机器学习）？&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;首选 Spark：&lt;/strong&gt; 它在绝大多数计算场景下都远快于 MapReduce/Tez。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;主要需求是使用熟悉的 SQL 进行批处理分析和报表，团队 SQL 技能强？&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hive 是很好的起点：&lt;/strong&gt; 利用其强大的元数据管理和 SQL 接口。但&lt;strong&gt;强烈建议将执行引擎配置为 Spark (Hive on Spark)&lt;/strong&gt;，而不是 MapReduce 或 Tez，以获得显著的性能提升。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spark SQL：&lt;/strong&gt; 也可以直接使用 Spark SQL 来执行 SQL 查询，它同样支持 HiveQL 语法（兼容 Hive Metastore），性能通常优于 Hive on Spark。如果你已经在用 Spark 做其他事情（如 ETL, ML），Spark SQL 是更统一的选择。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;需要亚秒级响应的交互式查询？&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hive LLAP：&lt;/strong&gt; Hive 的 Live Long and Process 模式提供内存缓存和守护进程，加速查询。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spark Thrift Server / JDBC/ODBC Server：&lt;/strong&gt; 允许 BI 工具通过标准接口连接 Spark SQL 进行交互式查询。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;专用交互式引擎：&lt;/strong&gt; 如 Presto, Impala, Druid 等（这些通常也依赖 HDFS/S3 存储和 Hive Metastore）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;需要实时/准实时流处理？&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Spark Structured Streaming：&lt;/strong&gt; 首选的统一引擎方案。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flink：&lt;/strong&gt; 另一个强大的流处理引擎（Spark 和 Flink 是当前流处理的主流）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;需要做机器学习或图计算？&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Spark MLlib / GraphX：&lt;/strong&gt; Spark 的内置库提供了丰富的功能。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;元数据管理：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hive Metastore (HMS) 是事实标准：&lt;/strong&gt; 无论你主要使用 Hive、Spark SQL 还是其他查询引擎（Presto, Impala），&lt;strong&gt;强烈建议使用 Hive Metastore&lt;/strong&gt; 来集中管理表结构、分区、数据类型、存储位置等元数据。这保证了不同引擎对数据有一致的视图，是数据治理的基础。Spark 原生支持读写 Hive Metastore。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;典型的组合使用模式&#34;&gt;&lt;a href=&#34;#典型的组合使用模式&#34; class=&#34;headerlink&#34; title=&#34;典型的组合使用模式&#34;&gt;&lt;/a&gt;典型的组合使用模式&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;经典批处理数据仓库 (Hive-Centric):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;存储:&lt;/strong&gt; HDFS 或 S3/GCS/ADLS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;元数据:&lt;/strong&gt; Hive Metastore&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ETL/计算：&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;传统/基础版：&lt;/em&gt; Hive on MapReduce/Tez (利用 HiveQL 编写 ETL 和查询逻辑)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;现代/高效版：* &lt;/strong&gt;Hive on Spark&lt;strong&gt; (HiveQL -&amp;gt; Spark Job) 或 &lt;/strong&gt;Spark SQL** (Spark API/SQL -&amp;gt; Spark Job)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;查询：&lt;/strong&gt; Hive CLI/Beeline (执行 HiveQL)，Spark SQL Thrift Server (支持 BI 工具连接)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;场景：&lt;/strong&gt; 传统的 T+1 数据报表，大规模历史数据分析。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;高性能统一分析平台 (Spark-Centric):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;存储:&lt;/strong&gt; HDFS 或 S3/GCS/ADLS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;元数据:&lt;/strong&gt; Hive Metastore (Spark SQL 直接读写 HMS)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算：&lt;/strong&gt; &lt;strong&gt;Spark&lt;/strong&gt; 作为核心引擎&lt;ul&gt;
&lt;li&gt;&lt;em&gt;批处理 ETL:&lt;/em&gt; 使用 Spark DataFrame/Dataset API 或 Spark SQL 清洗、转换、加载数据到 Hive 表。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;流处理:&lt;/em&gt; 使用 Spark Structured Streaming 处理 Kafka 等数据源，结果写入 Hive 表或直接供下游使用。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;交互式查询:&lt;/em&gt; 通过 Spark Thrift Server 支持 BI 工具连接 Spark SQL。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;机器学习:&lt;/em&gt; 使用 Spark MLlib 训练模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源管理:&lt;/strong&gt; YARN (Hadoop) 或 Kubernetes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;场景：&lt;/strong&gt; 需要融合批处理、流处理、机器学习、交互式查询等多种工作负载的现代数据平台。Hive Metastore 提供了统一的数据目录。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;云原生数据湖：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;存储:&lt;/strong&gt; S3, GCS, ADLS (对象存储)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;元数据:&lt;/strong&gt; Hive Metastore (托管服务如 AWS Glue Data Catalog 是 HMS 的兼容实现)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算：&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Serverless SQL 查询：&lt;/em&gt; AWS Athena, Google BigQuery (直接查询 S3/GCS 数据，利用 Glue Catalog 或类似元数据)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;自定义处理：&lt;/em&gt; &lt;strong&gt;Spark&lt;/strong&gt; on EMR/Dataproc/Databricks/Synapse (进行复杂的 ETL、ML、流处理，读写对象存储和元数据服务)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;场景：&lt;/strong&gt; 利用云服务的弹性、按需付费特性，减少基础设施运维负担。Spark 处理复杂任务，Serverless SQL 处理即席查询。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结与关键建议&#34;&gt;&lt;a href=&#34;#总结与关键建议&#34; class=&#34;headerlink&#34; title=&#34;总结与关键建议&#34;&gt;&lt;/a&gt;总结与关键建议&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;HDFS/对象存储是基石：&lt;/strong&gt; 选择适合你的分布式存储（HDFS 或云存储）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hive Metastore 是核心枢纽：&lt;/strong&gt; &lt;strong&gt;务必使用&lt;/strong&gt; Hive Metastore 或兼容服务（如 AWS Glue）来统一管理元数据，这是打通不同计算引擎的关键。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spark 是首选计算引擎：&lt;/strong&gt; 对于绝大多数&lt;strong&gt;需要速度&lt;/strong&gt;的计算任务（批处理、流处理、ML、交互式SQL），&lt;strong&gt;优先选择 Spark&lt;/strong&gt; 替代传统的 MapReduce/Tez。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hive 的价值在于 SQL 接口和 Metastore：&lt;/strong&gt; 即使主要用 Spark，Hive 的 Metastore 必不可少，HiveQL 接口对于重度 SQL 用户依然有价值（但底层执行应配置为 Spark）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hadoop YARN 是可选的资源管理器：&lt;/strong&gt; Spark 可以运行在 YARN、Kubernetes 或 Standalone 上。如果已有 Hadoop 集群，YARN 是自然选择；新建集群，Kubernetes 越来越流行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;组合是常态：&lt;/strong&gt; 几乎没有大型平台只使用其中一种技术。典型组合是：&lt;code&gt;(HDFS/S3) + (Hive Metastore) + (Spark for Processing) + (可选 Hive for SQL interface / LLAP for interactive)&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;简而言之：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;存储数据用什么？&lt;/strong&gt; HDFS 或 云存储 (S3/GCS/ADLS)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;管理表结构用什么？&lt;/strong&gt; Hive Metastore (或云服务如 Glue Catalog)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跑 ETL、流处理、机器学习、快速 SQL 用什么？&lt;/strong&gt; Spark (Spark Core, Spark SQL, Structured Streaming, MLlib)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;想用熟悉的 SQL 做批处理分析，或者需要加速交互查询？&lt;/strong&gt; 可以使用 Hive (但配置 Hive on Spark 或 Hive LLAP)，或者直接用 Spark SQL + Thrift Server。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据你的具体场景（数据规模、延迟要求、处理类型、团队技能、预算、云或本地）来调整这些组件的权重和配置。对于新项目，以 Spark 为核心计算引擎，结合 Hive Metastore 和 HDFS/云存储，是最常见且高效的起点。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://erik.xyz/2017/06/29/hadoop2-8-0-de-bu-shu-an-zhuang-jiao-cheng/</guid>
            <title>hadoop2.8.0的部署安装教程</title>
            <link>https://erik.xyz/2017/06/29/hadoop2-8-0-de-bu-shu-an-zhuang-jiao-cheng/</link>
            <category>hadoop</category>
            <category>hadoop2.8.0</category>
            <category>hadoop安装教程</category>
            <category>hadoop安装详细教程</category>
            <category>hadoop教程</category>
            <category>hadoop部署</category>
            <pubDate>Thu, 29 Jun 2017 08:27:00 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;Hadoop部署准备 本地vmware安装 Linux系统家族中 centos7 下载地址&lt;a href=&#34;http://101.110.118.58/isoredirect.centos.org/centos/7/isos/x86\_64/CentOS-7-x86\_64-Minimal-1611.iso&#34;&gt;http://101.110.118.58/isoredirect.centos.org/centos/7/isos/x86\_64/CentOS-7-x86\_64-Minimal-1611.iso&lt;/a&gt;   Java对应版本1.8.0_121   Hadoop版本2.8.0下载地址 &lt;a href=&#34;http://mirror.bit.edu.cn/apache/hadoop/common/&#34;&gt;http://mirror.bit.edu.cn/apache/hadoop/common/&lt;/a&gt; 可以根据自己喜好的版本下载&lt;/p&gt;
&lt;h1 id=&#34;1-基本配置&#34;&gt;&lt;a href=&#34;#1-基本配置&#34; class=&#34;headerlink&#34; title=&#34;1.基本配置&#34;&gt;&lt;/a&gt;1.基本配置&lt;/h1&gt;&lt;p&gt;首先安装一个centos7并配置好java Java环境配置 我的java安装地址 /usr/java/ jdk1.8.0_121   编辑java环境 vi ~/.bash_profile 添加或修改 export JAVA_HOME=/usr/java/jdk1.8.0_121 export PATH=$JAVA_HOME/bin:$PATH 执行 . ~/.bash_profile 使变量生效  &lt;span id=&#34;more&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;2-ssh配置&#34;&gt;&lt;a href=&#34;#2-ssh配置&#34; class=&#34;headerlink&#34; title=&#34;2.ssh配置&#34;&gt;&lt;/a&gt;2.ssh配置&lt;/h1&gt;&lt;p&gt;先 yum install ssh  安装   然后执行 ssh-keygen -t dsa -P ‘’ -f ~/.ssh/id_dsa 生成密匙&lt;/p&gt;
&lt;h1 id=&#34;3-hadoop配置&#34;&gt;&lt;a href=&#34;#3-hadoop配置&#34; class=&#34;headerlink&#34; title=&#34;3.hadoop配置&#34;&gt;&lt;/a&gt;3.hadoop配置&lt;/h1&gt;&lt;p&gt;把下载好的hadoop解压出来。（我的地址在/roo目录,即完整地址/root/hadoop）   配置环境变量 vi ~/.bash_profile export HADOOP_HOME=/root/hadoop export PATH=$JAVA_HOME/bin:$PATH:$HOME/bin:$HADOOP_HOME/bin 执行 . ~/.bash_profile 使变量生效  &lt;/p&gt;
&lt;h1 id=&#34;4-hadoop文件配置&#34;&gt;&lt;a href=&#34;#4-hadoop文件配置&#34; class=&#34;headerlink&#34; title=&#34;4.hadoop文件配置&#34;&gt;&lt;/a&gt;4.hadoop文件配置&lt;/h1&gt;&lt;p&gt;首先给本机命名个名字：例如我这边是s204   就执行 hostnamectl set-hostname s204 变更主机名字   然后在/root/hadoop目录下 依次执行编辑&lt;/p&gt;
&lt;h2 id=&#34;vim-etc-hadoop-core-site-xml&#34;&gt;&lt;a href=&#34;#vim-etc-hadoop-core-site-xml&#34; class=&#34;headerlink&#34; title=&#34;vim etc/hadoop/core-site.xml&#34;&gt;&lt;/a&gt;vim etc/hadoop/core-site.xml&lt;/h2&gt;&lt;p&gt;  在&lt;configuration&gt;&lt;/configuration&gt;中加入 &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://s204:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/root/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131702&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt;   &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt;  &lt;/p&gt;
&lt;h2 id=&#34;vim-etc-hadoop-hdfs-site-xml&#34;&gt;&lt;a href=&#34;#vim-etc-hadoop-hdfs-site-xml&#34; class=&#34;headerlink&#34; title=&#34;vim etc/hadoop/hdfs-site.xml&#34;&gt;&lt;/a&gt;vim etc/hadoop/hdfs-site.xml&lt;/h2&gt;&lt;p&gt;在&lt;configuration&gt;&lt;/configuration&gt;中加入   &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/root/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/root/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;s204:9001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;  &lt;/p&gt;
&lt;h2 id=&#34;vim-etc-hadoop-mapred-site-xml&#34;&gt;&lt;a href=&#34;#vim-etc-hadoop-mapred-site-xml&#34; class=&#34;headerlink&#34; title=&#34;vim etc/hadoop/mapred-site.xml&#34;&gt;&lt;/a&gt;vim etc/hadoop/mapred-site.xml&lt;/h2&gt;&lt;p&gt;在&lt;configuration&gt;&lt;/configuration&gt;中加入   &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;s204:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;s204:19888&lt;/value&gt; &lt;/property&gt;  &lt;/p&gt;
&lt;h2 id=&#34;vim-etc-hadoop-yarn-site-xml&#34;&gt;&lt;a href=&#34;#vim-etc-hadoop-yarn-site-xml&#34; class=&#34;headerlink&#34; title=&#34;vim etc/hadoop/yarn-site.xml&#34;&gt;&lt;/a&gt;vim etc/hadoop/yarn-site.xml&lt;/h2&gt;&lt;p&gt;在&lt;configuration&gt;&lt;/configuration&gt;中加入 &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;s204:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;s204:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;s204:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;s204:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;s204:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;6078&lt;/value&gt; &lt;/property&gt;  &lt;/p&gt;
&lt;h2 id=&#34;vim-etc-hadoop-yarn-env-sh&#34;&gt;&lt;a href=&#34;#vim-etc-hadoop-yarn-env-sh&#34; class=&#34;headerlink&#34; title=&#34;vim etc/hadoop/yarn-env.sh&#34;&gt;&lt;/a&gt;vim etc/hadoop/yarn-env.sh&lt;/h2&gt;&lt;p&gt;  中找到 export JAVA_HOME 去掉注释 编辑java地址 export JAVA_HOME=/usr/java/jdk1.8.0_121   找到JAVA_HEAP_MAX=-Xmx1000m 改为 JAVA_HEAP_MAX=-Xmx1024m  &lt;/p&gt;
&lt;h2 id=&#34;vim-etc-hadoop-slaves&#34;&gt;&lt;a href=&#34;#vim-etc-hadoop-slaves&#34; class=&#34;headerlink&#34; title=&#34;vim etc/hadoop/slaves&#34;&gt;&lt;/a&gt;vim etc/hadoop/slaves&lt;/h2&gt;&lt;p&gt;  清空添加 s204    &lt;/p&gt;
&lt;h1 id=&#34;网络配置&#34;&gt;&lt;a href=&#34;#网络配置&#34; class=&#34;headerlink&#34; title=&#34;网络配置&#34;&gt;&lt;/a&gt;网络配置&lt;/h1&gt;&lt;p&gt;我这ip是 192.168.5.9   编辑网络固定ip vim /etc/sysconfig/network-scripts/ifcfg-ens33   指定固定ip   TYPE=”Ethernet” #BOOTPROTO=”dhcp” DEFROUTE=”yes” PEERDNS=”yes” PEERROUTES=”yes” IPV4_FAILURE_FATAL=”no” IPV6INIT=”yes” IPV6_AUTOCONF=”yes” IPV6_DEFROUTE=”yes” IPV6_PEERDNS=”yes” IPV6_PEERROUTES=”yes” IPV6_FAILURE_FATAL=”no” IPV6_ADDR_GEN_MODE=”stable-privacy” NAME=”ens33” UUID=”b9fe1e5c-be20-47f1-a2d3-e12f5ddb6aa1” DEVICE=”ens33” ONBOOT=”yes” IPADDR0=192.168.5.9 PREFIX0=24 GATEWAY0=192.168.5.2 DNS1=114.114.114.114   然后重启网络 systemctl  restart  network   执行 ip add  查看网络ip是否和设定的一致  &lt;/p&gt;
&lt;h1 id=&#34;Hadopp启动&#34;&gt;&lt;a href=&#34;#Hadopp启动&#34; class=&#34;headerlink&#34; title=&#34;Hadopp启动&#34;&gt;&lt;/a&gt;Hadopp启动&lt;/h1&gt;&lt;p&gt;  进入/root/hadoop目录   执行编译 ./bin/hdfs namenode –format   结果倒数第五行出现 Exiting with status 0 则为成功   然后启动 ./sbin/start-all.sh   启动完毕执行./bin/hdfs dfsadmin –report 查看是否有节点 如果返回 无法连接则为启动失败   执行systemctl stop firewalld.service关闭防火墙  在浏览器输入s204:8088则可以看到hadoop界面  &lt;/p&gt;
&lt;h1 id=&#34;其他节点配置&#34;&gt;&lt;a href=&#34;#其他节点配置&#34; class=&#34;headerlink&#34; title=&#34;其他节点配置&#34;&gt;&lt;/a&gt;其他节点配置&lt;/h1&gt;&lt;p&gt;以上配置完毕后，关闭centos7 然后完全克隆，在新克隆的系统中，更改ip地址和主机名 其中hadoop配置文件 etc/hadoop/hdfs-site.xml  中 &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/root/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt;   的file地址不能一样。 我这边三个地址分别为 file:/root/hadoop/hdfs/data file:/root/hadoop/hdfs/data/205 file:/root/hadoop/hdfs/data/206   克隆完毕，配置文件和ip、主机名修改好后。在s204机器中编辑 vim etc/hadoop/slaves 加入 s205 s206   复制ssh令牌免密登录 例如复制到s205 scp ~/.ssh/authorized_keys root@s205:~/.ssh/   其他另个机器也一样操作   另外几个机器也要编译一下   然后在s204停止hadoop   ./sbin/stop-all.sh   再次启动./sbin/start-all.sh   在浏览器就可以看到三个节点。&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>