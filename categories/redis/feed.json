{
    "version": "https://jsonfeed.org/version/1",
    "title": "艾瑞可erik • All posts by \"redis\" categories",
    "description": "一只PHP开发的程序猿，偶尔做做运维、Goland、Python、Java、摄影、画画、写作、顺便睡觉，反正整站都搞过。",
    "home_page_url": "https://erik.xyz",
    "items": [
        {
            "id": "https://erik.xyz/2021/11/15/reids-info-lock/",
            "url": "https://erik.xyz/2021/11/15/reids-info-lock/",
            "title": "细说Redis分布式锁",
            "date_published": "2021-11-15T13:43:00.000Z",
            "content_html": "<p>谈起Redis锁，下面三个，算是出现最多的高频词汇：</p>\n<ul>\n<li>Setnx</li>\n<li>Redlock</li>\n<li>Redisson</li>\n</ul>\n<p>Setnx</p>\n<p>其实目前通常所说的Setnx命令，并非单指Redis的setnx key value这条命令。</p>\n<span id=\"more\"></span>\n<p>一般代指Redis中对set命令加上nx参数进行使用，set这个命令，目前已经支持这么多参数可选：</p>\n<pre><code>SET key value [EX seconds|PX milliseconds] [NX|XX] [KEEPTTL]\n</code></pre><p>当然了，就不在文章中默写API了，基础参数还有不清晰的，可以蹦到官网：<a href=\"https://redis.io/commands/set\">https://redis.io/commands/set</a></p>\n<p><img src=\"/2021/11/20211115214422.jpg\" alt=\"\"></p>\n<p>上图是笔者画的Setnx大致原理，主要依托了它的key不存在才能set成功的特性，进程A拿到锁，在没有删除锁的Key时，进程B自然获取锁就失败了。</p>\n<p>那么为什么要使用PX 30000去设置一个超时时间？</p>\n<p>是怕进程A不讲道理啊，锁没等释放呢，万一崩了，直接原地把锁带走了，导致系统中谁也拿不到锁。</p>\n<p>就算这样，还是不能保证万无一失。</p>\n<p>如果进程A又不讲道理，操作锁内资源超过笔者设置的超时时间，那么就会导致其他进程拿到锁，等进程A回来了，回手就是把其他进程的锁删了，如图：</p>\n<p><img src=\"/2021/11/20211115214716.jpg\" alt=\"\"></p>\n<p>还是刚才那张图，将T5时刻改成了锁超时，被Redis释放。</p>\n<p>进程B在T6开开心心拿到锁不到一会，进程A操作完成，回手一个del，就把锁释放了。</p>\n<p>当进程B操作完成，去释放锁的时候（图中T8时刻）：</p>\n<p>找不到锁其实还算好的，万一T7时刻有个进程C过来加锁成功，那么进程B就把进程C的锁释放了。</p>\n<p>以此类推，进程C可能释放进程D的锁，进程D……（禁止套娃），具体什么后果就不得而知了。</p>\n<p>所以在用Setnx的时候，key虽然是主要作用，但是value也不能闲着，可以设置一个唯一的客户端ID，或者用UUID这种随机数。</p>\n<p>当解锁的时候，先获取value判断是否是当前进程加的锁，再去删除。伪代码：</p>\n<pre><code>String uuid = xxxx;\n// 伪代码，具体实现看项目中用的连接工具\n// 有的提供的方法名为set，有的叫setIfAbsent\nset Test uuid NX PX 3000\ntry&#123;\n// biz handle....\n&#125; finally &#123;\n    // unlock\n    if(uuid.equals(redisTool.get(&#39;Test&#39;))&#123;\n        redisTool.del(&#39;Test&#39;);\n    &#125;\n&#125;\n</code></pre><p>这回看起来是不是稳了。</p>\n<p>相反，这回的问题更明显了，在finally代码块中，get和del并非原子操作，还是有进程安全问题。</p>\n<p>为什么有问题还说这么多呢？</p>\n<p>第一，搞清劣势所在，才能更好的完善。</p>\n<p>第二点，其实上文中最后这段代码，还是有很多公司在用的。</p>\n<p>大小项目悖论：大公司实现规范，但是小司小项目虽然存在不严谨，可并发倒也不高，出问题的概率和大公司一样低。——鲁迅</p>\n<p>那么删除锁的正确姿势之一，就是可以使用Lua脚本，通过Redis的eval/evalsha命令来运行：</p>\n<pre><code>-- Lua删除锁：\n-- KEYS和ARGV分别是以集合方式传入的参数，对应上文的Test和uuid。\n-- 如果对应的value等于传入的uuid。\nif redis.call(&#39;get&#39;, KEYS[1]) == ARGV[1] \n    then \n -- 执行删除操作\n        return redis.call(&#39;del&#39;, KEYS[1]) \n    else \n -- 不成功，返回0\n        return 0 \nend\n</code></pre><p>通过Lua脚本能保证原子性的原因说的通俗一点：</p>\n<p>就算你在Lua里写出花，执行也是一个命令（eval/evalsha）去执行的，一条命令没执行完，其他客户端是看不到的。</p>\n<p>那么既然这么麻烦，有没有比较好的工具呢？就要说到Redisson了。</p>\n<p>介绍Redisson之前，笔者简单解释一下为什么现在的Setnx默认是指set命令带上nx参数，而不是直接说是Setnx这个命令。</p>\n<p>因为Redis版本在2.6.12之前，set是不支持nx参数的，如果想要完成一个锁，那么需要两条命令：</p>\n<pre><code>1. setnx Test uuid\n2. expire Test 30\n</code></pre><p>即放入Key和设置有效期，是分开的两步，理论上会出现1刚执行完，程序挂掉，无法保证原子性。</p>\n<p>但是早在2013年，也就是7年前，Redis就发布了2.6.12版本，并且官网（set命令页[1]），也早早就说明了“SETNX，SETEX，PSETEX可能在未来的版本中，会弃用并永久删除”。</p>\n<p>笔者曾阅读过一位大佬的文章，其中就有一句指导入门者的面试小套路，具体文字忘记了，大概意思如下：</p>\n<pre><code>说到Redis锁的时候，可以先从Setnx讲起，最后慢慢引出set命令的可以加参数，可以体现出自己的知识面。\n</code></pre><p>如果有缘你也阅读过这篇文章，并且学到了这个套路，作为本文的笔者我要加一句提醒：</p>\n<p>请注意你的工作年限！首先回答官网表明即将废弃的命令，再引出set命令七年前的“新特性”，如果是刚毕业不久的人这么说，面试官会以为自己穿越了。</p>\n<p>你套路面试官，面试官也会套路你。——vt・沃兹基硕德</p>\n<p>Redisson</p>\n<p>Redisson是Java的Redis客户端之一，提供了一些API方便操作Redis。</p>\n<p>但是Redisson这个客户端可有点厉害，笔者在官网截了仅仅是一部分的图：</p>\n<p><img src=\"/2021/11/20211115214952.jpg\" alt=\"\"></p>\n<p>这个特性列表可以说是太多了，是不是还看到了一些JUC包下面的类名，Redisson帮我们搞了分布式的版本，比如AtomicLong，直接用RedissonAtomicLong就行了，连类名都不用去新记，很人性化了。</p>\n<p>锁只是它的冰山一角，并且从它的wiki[2]页面看到，对主从，哨兵，集群等模式都支持，当然了，单节点模式肯定是支持的。</p>\n<p>本文还是以锁为主，其他的不过多介绍。</p>\n<p>Redisson普通的锁实现源码主要是RedissonLock这个类，还没有看过它源码的盆友，不妨去瞧一瞧。</p>\n<p>源码中加锁/释放锁操作都是用Lua脚本完成的，封装的非常完善，开箱即用。</p>\n<p>这里有个小细节，加锁使用Setnx就能实现，也采用Lua脚本是不是多此一举？笔者也非常严谨的思考了一下：这么厉害的东西哪能写废代码？</p>\n<p>其实笔者仔细看了一下，加锁解锁的Lua脚本考虑的非常全面，其中就包括锁的重入性，这点可以说是考虑非常周全，我也随手写了代码测试一下：</p>\n<p><img src=\"/2021/11/20211115215028.jpg\" alt=\"\"></p>\n<p>的确用起来像JDK的ReentrantLock一样丝滑，那么Redisson实现的已经这么完善，RedLock又是什么？</p>\n<p>RedLock</p>\n<p>RedLock的中文是直译过来的，就叫红锁。</p>\n<p>红锁并非是一个工具，而是Redis官方提出的一种分布式锁的算法。</p>\n<p>就在刚刚介绍完的Redisson中，就实现了redLock版本的锁。也就是说除了getLock方法，还有getRedLock方法。</p>\n<p>笔者大概画了一下对红锁的理解：</p>\n<p><img src=\"/2021/11/20211115215116.jpg\" alt=\"\"></p>\n<p>如果你不熟悉Redis高可用部署，那么没关系。RedLock算法虽然是需要多个实例，但是这些实例都是独自部署的，没有主从关系。</p>\n<p>RedLock作者指出，之所以要用独立的，是避免了redis异步复制造成的锁丢失，比如：主节点没来的及把刚刚set进来这条数据给从节点，就挂了。</p>\n<p>有些人是不是觉得大佬们都是杠精啊，天天就想着极端情况。其实高可用嘛，拼的就是99.999……%中小数点后面的位数。</p>\n<p>回到上面那张简陋的图片，红锁算法认为，只要(N/2) + 1个节点加锁成功，那么就认为获取了锁， 解锁时将所有实例解锁。流程为：</p>\n<p>  1.顺序向五个节点请求加锁</p>\n<p>  2.根据一定的超时时间来推断是不是跳过该节点</p>\n<p>  3.三个节点加锁成功并且花费时间小于锁的有效期</p>\n<p>  4.认定加锁成功</p>\n<p>也就是说，假设锁30秒过期，三个节点加锁花了31秒，自然是加锁失败了。</p>\n<p>这只是举个例子，实际上并不应该等每个节点那么长时间，就像官网所说的那样，假设有效期是10秒，那么单个Redis实例操作超时时间，应该在5到50毫秒（注意时间单位）。</p>\n<p>还是假设我们设置有效期是30秒，图中超时了两个Redis节点。那么加锁成功的节点总共花费了3秒，所以锁的实际有效期是小于27秒的。</p>\n<p>即扣除加锁成功三个实例的3秒，还要扣除等待超时Redis实例的总共时间。</p>\n<p>看到这，你有可能对这个算法有一些疑问，那么你不是一个人。</p>\n<p>回头看看Redis官网关于红锁的描述[3]。</p>\n<p>就在这篇描述页面的最下面，你能看到著名的关于红锁的神仙打架事件。</p>\n<p>即Martin Kleppmann和Antirez的RedLock辩论。一个是很有资历的分布式架构师，一个是Redis之父。</p>\n<p>官方挂人，最为致命。</p>\n<p>开个玩笑，要是质疑能被官方挂到官网，说明肯定是有价值的。</p>\n<p>所以说如果项目里要使用红锁，除了红锁的介绍，不妨要多看两篇文章，即：</p>\n<ul>\n<li><p>Martin Kleppmann的质疑贴：<a href=\"http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\">http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</a></p>\n</li>\n<li><p>Antirez的反击贴：<a href=\"http://antirez.com/news/101\">http://antirez.com/news/101</a></p>\n</li>\n</ul>\n<p>总结</p>\n<p>看了这么多，是不是发现如何实现，都不能保证100%的稳定。</p>\n<p>程序就是这样，没有绝对的稳定，所以做好人工补偿环节也是重要的一环，毕竟：技术不够，人工来凑～</p>\n<p>相关链接：</p>\n<p><a href=\"https://redis.io/commands/set\">https://redis.io/commands/set</a></p>\n<p><a href=\"https://github.com/redisson/redisson/wiki/Table-of-Content\">https://github.com/redisson/redisson/wiki/Table-of-Content</a></p>\n<p><a href=\"https://redis.io/topics/distlock\">https://redis.io/topics/distlock</a></p>\n<p>原文链接：<a href=\"https://juejin.cn/post/6844904082860146695\">https://juejin.cn/post/6844904082860146695</a></p>\n",
            "tags": [
                "redis",
                "redis锁",
                "redis分布式锁"
            ]
        },
        {
            "id": "https://erik.xyz/2021/04/07/redis-about-all/",
            "url": "https://erik.xyz/2021/04/07/redis-about-all/",
            "title": "关于redis的总结",
            "date_published": "2021-04-07T08:09:00.000Z",
            "content_html": "<h2 id=\"基础数据结构\"><a href=\"#基础数据结构\" class=\"headerlink\" title=\"基础数据结构\"></a>基础数据结构</h2><ul>\n<li><h3 id=\"字符串（string）\"><a href=\"#字符串（string）\" class=\"headerlink\" title=\"字符串（string）\"></a>字符串（string）</h3><ul>\n<li>字符串、整数、浮点数</li>\n<li>对整个字符串或者字符串的其中一部分执行操作，对整数和浮点数执行自增或自减操作</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"哈希列表（hash）\"><a href=\"#哈希列表（hash）\" class=\"headerlink\" title=\"哈希列表（hash）\"></a>哈希列表（hash）</h3><ul>\n<li>包含键值对的无序散列表</li>\n<li>添加、获取、移除单个键值对，获取所有键值对，检查某个键是否存在</li>\n</ul>\n</li>\n</ul>\n<span id=\"more\"></span>\n<ul>\n<li><h3 id=\"列表（list）\"><a href=\"#列表（list）\" class=\"headerlink\" title=\"列表（list）\"></a>列表（list）</h3><ul>\n<li>链表</li>\n<li>从两端压入或者弹出元素，读取单个或者多个元素进行修剪，只保留一个范围内的元素</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"集合（set）\"><a href=\"#集合（set）\" class=\"headerlink\" title=\"集合（set）\"></a>集合（set）</h3><ul>\n<li>无序集合</li>\n<li>添加、获取、移除单个元素，检查一个元素是否存在与集合中，计算交集、并集、差集，从集合里面随机获取元素</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"有序集合（sort-set）\"><a href=\"#有序集合（sort-set）\" class=\"headerlink\" title=\"有序集合（sort set）\"></a>有序集合（sort set）</h3><ul>\n<li>有序集合</li>\n<li>添加、获取、删除元素，根据分值范围或者成员来获取元素，计算一个键的排名</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"复杂的数据结构\"><a href=\"#复杂的数据结构\" class=\"headerlink\" title=\"复杂的数据结构\"></a>复杂的数据结构</h2><ul>\n<li><h3 id=\"位图（bitmaps）\"><a href=\"#位图（bitmaps）\" class=\"headerlink\" title=\"位图（bitmaps）\"></a>位图（bitmaps）</h3><ul>\n<li>Bitmap 在 Redis 中不是一种实际的数据类型，而是一种将 String 作为 Bitmap 使用的方法。可以理解为将 String 转换为 bit 数组。使用 Bitmap 来存储 true/false 类型的简单数据极为节省空间。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"算法数据结构（hyperloglogs）\"><a href=\"#算法数据结构（hyperloglogs）\" class=\"headerlink\" title=\"算法数据结构（hyperloglogs）\"></a>算法数据结构（hyperloglogs）</h3><ul>\n<li>HyperLogLogs 是一种主要用于数量统计的数据结构，它和 Set 类似，维护一个不可重复的 String 集合，但是 HyperLogLogs 并不维护具体的 member 内容，只维护 member 的个数。也就是说，HyperLogLogs 只能用于计算一个集合中不重复的元素数量，所以它比 Set 要节省很多内存空间</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"地理空间（geo）\"><a href=\"#地理空间（geo）\" class=\"headerlink\" title=\"地理空间（geo）\"></a>地理空间（geo）</h3><ul>\n<li>地理空间索引半径查询</li>\n</ul>\n</li>\n<li><h3 id=\"布隆过滤（bloomfilter）\"><a href=\"#布隆过滤（bloomfilter）\" class=\"headerlink\" title=\"布隆过滤（bloomfilter）\"></a>布隆过滤（bloomfilter）</h3></li>\n</ul>\n<h2 id=\"非分布式场景下Redis应用的备份与容灾\"><a href=\"#非分布式场景下Redis应用的备份与容灾\" class=\"headerlink\" title=\"非分布式场景下Redis应用的备份与容灾\"></a>非分布式场景下Redis应用的备份与容灾</h2><ul>\n<li><h3 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h3><ul>\n<li>一个Master节点，两个Slave节点。客户端写数据的时候是写Master节点，读的时候，是读取两个Slave，这样实现读的扩展，减轻了Master节点读负载。</li>\n</ul>\n</li>\n<li><h3 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h3><ul>\n<li>Master和Slave1使用keepalived进行VIP转移。Client连接Master的时候是通过VIP进行连接的。避免了方案一IP更改的情况。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"Redis-Sentinel架构\"><a href=\"#Redis-Sentinel架构\" class=\"headerlink\" title=\"Redis Sentinel架构\"></a>Redis Sentinel架构</h3><ul>\n<li>Sentinel集群对自身和Redis主从复制进行监控。当发现Master节点出现故障时，会经过如下步骤：<ul>\n<li>Sentinel之间进行选举，选举出一个leader，由选举出的leader进行failover</li>\n<li>Sentinel leader选取slave节点中的一个slave作为新的Master节点。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"客户端工具\"><a href=\"#客户端工具\" class=\"headerlink\" title=\"客户端工具\"></a>客户端工具</h2><ul>\n<li><h3 id=\"使用socket连接redis服务器\"><a href=\"#使用socket连接redis服务器\" class=\"headerlink\" title=\"使用socket连接redis服务器\"></a>使用socket连接redis服务器</h3><pre><code> redis-cli -s /tmp/redis.sock\n</code></pre></li>\n</ul>\n<ul>\n<li><h3 id=\"不使用socket连接redis服务器\"><a href=\"#不使用socket连接redis服务器\" class=\"headerlink\" title=\"不使用socket连接redis服务器\"></a>不使用socket连接redis服务器</h3><pre><code>redis-cli\n</code></pre></li>\n</ul>\n<h2 id=\"性能测试工具\"><a href=\"#性能测试工具\" class=\"headerlink\" title=\"性能测试工具\"></a>性能测试工具</h2><ul>\n<li><h3 id=\"使用默认参数测试\"><a href=\"#使用默认参数测试\" class=\"headerlink\" title=\"使用默认参数测试\"></a>使用默认参数测试</h3><pre><code>redis-benchmark\n</code></pre></li>\n<li><h3 id=\"自定义参数测试\"><a href=\"#自定义参数测试\" class=\"headerlink\" title=\"自定义参数测试\"></a>自定义参数测试</h3><pre><code>redis-benchmark -n 1000000 --csv\n</code></pre></li>\n<li><h3 id=\"雪球-rdr：\"><a href=\"#雪球-rdr：\" class=\"headerlink\" title=\"雪球 rdr：\"></a>雪球 rdr：</h3><pre><code>  https://github.com/xueqiu/rdr\n</code></pre></li>\n<li><h3 id=\"redis-rdb-tools：\"><a href=\"#redis-rdb-tools：\" class=\"headerlink\" title=\"redis-rdb-tools：\"></a>redis-rdb-tools：</h3><pre><code>https://github.com/sripathikrishnan/redis-rdb-tools\n</code></pre></li>\n</ul>\n<h2 id=\"工具命令\"><a href=\"#工具命令\" class=\"headerlink\" title=\"工具命令\"></a>工具命令</h2><ul>\n<li><h3 id=\"指定配置文件启动服务\"><a href=\"#指定配置文件启动服务\" class=\"headerlink\" title=\"指定配置文件启动服务\"></a>指定配置文件启动服务</h3><pre><code>redis-server redis.conf\n</code></pre></li>\n<li><h3 id=\"指定端口启动服务\"><a href=\"#指定端口启动服务\" class=\"headerlink\" title=\"指定端口启动服务\"></a>指定端口启动服务</h3><pre><code>redis-server --port 6379\n</code></pre></li>\n</ul>\n<h2 id=\"检查修复本地数据文件工具\"><a href=\"#检查修复本地数据文件工具\" class=\"headerlink\" title=\"检查修复本地数据文件工具\"></a>检查修复本地数据文件工具</h2><pre><code>redis-check-dump dump.rdb\n</code></pre><h2 id=\"检查修复AOF日志文件工具\"><a href=\"#检查修复AOF日志文件工具\" class=\"headerlink\" title=\"检查修复AOF日志文件工具\"></a>检查修复AOF日志文件工具</h2><pre><code>redis-check-aof appendonly.aof\n</code></pre><h2 id=\"基础命令\"><a href=\"#基础命令\" class=\"headerlink\" title=\"基础命令\"></a>基础命令</h2><ul>\n<li><p>keys</p>\n<ul>\n<li>列出Redis所有的key</li>\n</ul>\n</li>\n<li><p>del</p>\n<ul>\n<li>删除一个或多个key，多个key之间用空格分隔，其返回值为整数，表示成功删除了多少个存在的key，因此，如果只删除一个key，则可以从返回值中判断是否成功，如果删除多个key，则只能得到删除成功的数量</li>\n</ul>\n</li>\n<li><p>exists</p>\n<ul>\n<li>exists命令用于判断一个或多个key是否存在，判断多个key时，key之间用空格分隔,exists的返回值为整数，表示当前判断有多少个key是存在的。</li>\n</ul>\n</li>\n<li><p>expire/pexpire</p>\n<ul>\n<li>expire设置key在多少秒之后过期，pexpire设置key在多少毫秒之后过期,成功返回1，失败返回0。</li>\n</ul>\n</li>\n<li><p>ttl/pttl</p>\n<ul>\n<li><p>ttl和pttl命令用于获取key的过期时间，其返回值为整型</p>\n<ul>\n<li><p>当key不存在或过期时间，返回-2。</p>\n</li>\n<li><p>当key存在且永久有效时，返回-1。</p>\n</li>\n<li><p>当key有设置过期时间时，返回为剩下的秒数(pttl为毫秒数)</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>expireat/pexpireat</p>\n<ul>\n<li>设置key在某个时间戳过期,expreat参数时间戳用秒表示，而pexpireat则用毫秒表示，与expire和pexpire功能类似，返回1表示成功，0表示失败。</li>\n</ul>\n</li>\n<li><p>persist</p>\n<ul>\n<li>移除key的过期时间，将key设置为永久有效，当key设置了过期时间，使用persist命令移除后返回1，如果key不存在或本身就是永久有效的，则返回0</li>\n</ul>\n</li>\n<li><p>type</p>\n<ul>\n<li>判断key是什么类型的数据结构,返回值为string,list,set,hash,zset,分别表示我们前面介绍的Redis的5种基础数据结构。</li>\n</ul>\n</li>\n</ul>\n<p>geo,hyperloglog,bitmaps等复杂的数据结构，都是在这五种基础数据结构上实现，比如geo是zset类型，hyperloglog和bitmaps都为string。</p>\n<ul>\n<li><p>auth </p>\n<ul>\n<li>Redis认证命令，执行其他命令前，必须先进行认证</li>\n</ul>\n</li>\n<li><p>ping</p>\n<ul>\n<li>测试客户端和服务器之间的联通，返回值为PONG,表示联通</li>\n</ul>\n</li>\n<li><p>config get * </p>\n<ul>\n<li>获取所有配置参数</li>\n</ul>\n</li>\n<li><p>config set config_name config_value</p>\n<ul>\n<li>设置配置参数值</li>\n</ul>\n</li>\n<li><p>info</p>\n<ul>\n<li>返回服务器信息</li>\n</ul>\n</li>\n<li><p>select </p>\n<ul>\n<li>切换数据库，redis默认的数据库是0-15，共16个数据库</li>\n</ul>\n</li>\n<li><p>move</p>\n<ul>\n<li>将当前库的键移动到其他数据库</li>\n</ul>\n</li>\n<li><p>dbsize</p>\n<ul>\n<li>获取当前库中所有键的数量</li>\n</ul>\n</li>\n<li><p>flushdb</p>\n<ul>\n<li>删除当前库中的所有key</li>\n</ul>\n</li>\n<li><p>flushall</p>\n<ul>\n<li>删除所有库中的所有key</li>\n</ul>\n</li>\n<li><p>save</p>\n<ul>\n<li>创建当前库的备份</li>\n</ul>\n</li>\n<li><p>bgsave</p>\n<ul>\n<li>同save,但是是后台备份，不阻塞主进程</li>\n</ul>\n</li>\n<li><p>eval</p>\n<ul>\n<li>执行lua脚本</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"string\"><a href=\"#string\" class=\"headerlink\" title=\"string\"></a>string</h3><ul>\n<li><p>set</p>\n<ul>\n<li>为一个 key 设置 value，可以配合 EX/PX 参数指定 key 的有效期</li>\n</ul>\n</li>\n<li><p>get</p>\n<ul>\n<li>获取某个 key 对应的 value</li>\n</ul>\n</li>\n<li><p>getset</p>\n<ul>\n<li>为一个 key 设置 value，并返回该 key 的原 value</li>\n</ul>\n</li>\n<li><p>incr/decr </p>\n<ul>\n<li>自增/自减(前提是键值是整型)</li>\n</ul>\n</li>\n<li><p>incrby/decrby </p>\n<ul>\n<li>指定步长增加减少(q前提是键值是整型)</li>\n</ul>\n</li>\n<li><p>mset</p>\n<ul>\n<li>为多个 key 设置 value</li>\n</ul>\n</li>\n<li><p>msetnx</p>\n<ul>\n<li>同 MSET，如果指定的 key 中有任意一个已存在，则不进行任何操作</li>\n</ul>\n</li>\n<li><p>mget</p>\n<ul>\n<li>获取多个 key 对应的 value</li>\n</ul>\n</li>\n<li><p>strlen </p>\n<ul>\n<li>获取键的长度</li>\n</ul>\n</li>\n<li><p>append </p>\n<ul>\n<li>向指定键追加值，返回字符串长度</li>\n</ul>\n</li>\n<li><p>setnx </p>\n<ul>\n<li>判断键是否存在，存在返回0，否则返回1，不会覆盖原来值</li>\n</ul>\n</li>\n<li><p>getrange </p>\n<ul>\n<li>根据指定下标获取键的值</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"list\"><a href=\"#list\" class=\"headerlink\" title=\"list\"></a>list</h3><ul>\n<li><p>lpush</p>\n<ul>\n<li>向指定 List 的左侧（即头部）插入 1 个或多个元素，返回插入后的 List 长度</li>\n</ul>\n</li>\n<li><p>rpush</p>\n<ul>\n<li>同 lpush，向指定 List 的右侧（即尾部）插入 1 或多个元素</li>\n</ul>\n</li>\n<li><p>lpushx/rpushx</p>\n<ul>\n<li>与 lpush/rpush类似，区别在于，lpushx/rpushx操作的 key 如果不存在，则不会进行任何操作</li>\n</ul>\n</li>\n<li><p>lrange</p>\n<ul>\n<li>返回指定 List 中指定范围的元素（双端包含，即 lrange key 0 10 会返回 11 个元素），时间复杂度 O(N)。应尽可能控制一次获取的元素数量，一次获取过大范围的 List 元素会导致延迟，同时对长度不可预知的 List，避免使用 lrange key 0 -1 这样的完整遍历操作</li>\n</ul>\n</li>\n<li><p>lindex</p>\n<ul>\n<li>返回指定 List 指定 index 上的元素，如果 index 越界，返回 nil。index 数值是回环的，即 - 1 代表 List 最后一个位置，-2 代表 List 倒数第二个位置。</li>\n</ul>\n</li>\n<li><p>linsert</p>\n<ul>\n<li>向指定 List 中指定元素之前 / 之后插入一个新元素，并返回操作后的 List 长度。如果指定的元素不存在，返回 - 1。如果指定 key 不存在，不会进行任何操作</li>\n</ul>\n</li>\n<li><p>lset</p>\n<ul>\n<li><p>将指定 List 指定 index 上的元素设置为 value</p>\n<ul>\n<li>如果 index 越界则返回错误，时间复杂度 O(N)，</li>\n<li>如果操作的是头 / 尾部的元素，则时间复杂度为 O(1)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>lpop</p>\n<ul>\n<li>从指定 List 的左侧（即头部）移除一个元素并返回</li>\n</ul>\n</li>\n<li><p>rpop</p>\n<ul>\n<li>同 lpop，从指定 List 的右侧（即尾部）移除 1 个元素并返回</li>\n</ul>\n</li>\n<li><p>llen</p>\n<ul>\n<li>返回指定 List 的长度</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"hash\"><a href=\"#hash\" class=\"headerlink\" title=\"hash\"></a>hash</h3><ul>\n<li><p>hset</p>\n<ul>\n<li>将 key 对应的 Hash 中的 field 设置为 value。如果该 Hash 不存在，会自动创建一个。</li>\n</ul>\n</li>\n<li><p>hget</p>\n<ul>\n<li>返回指定 Hash 中 field 字段的值</li>\n</ul>\n</li>\n<li><p>hsetnx</p>\n<ul>\n<li>同 HSET，但如 field 已经存在，HSETNX 不会进行任何操作</li>\n</ul>\n</li>\n<li><p>hexists</p>\n<ul>\n<li>判断指定 Hash 中 field 是否存在，存在返回 1，不存在返回 0</li>\n</ul>\n</li>\n<li><p>hincrby</p>\n<ul>\n<li>同 incrby命令，对指定 Hash 中的一个 field 进行 incrby</li>\n</ul>\n</li>\n<li><p>hmset/hmget</p>\n<ul>\n<li>同 HSET 和 HGET，可以批量操作同一个 key 下的多个 field</li>\n</ul>\n</li>\n<li><p>hdel</p>\n<ul>\n<li>删除指定 Hash 中的 field（1 个或多个）</li>\n</ul>\n</li>\n<li><p>hgetall</p>\n<ul>\n<li>返回指定 Hash 中所有的 field-value 对。返回结果为数组，数组中 field 和 value 交替出现</li>\n</ul>\n</li>\n<li><p>hkeys/hvals</p>\n<ul>\n<li>返回指定 Hash 中所有的 field/value</li>\n</ul>\n</li>\n<li><p>hlen </p>\n<ul>\n<li>返回指定hash 表中field中的数量</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"set\"><a href=\"#set\" class=\"headerlink\" title=\"set\"></a>set</h3><ul>\n<li><p>scard</p>\n<ul>\n<li>返回指定 Set 中的 member 个数</li>\n</ul>\n</li>\n<li><p>sismember</p>\n<ul>\n<li>判断指定的 value 是否存在于指定 Set 中</li>\n</ul>\n</li>\n<li><p>smove</p>\n<ul>\n<li>将指定 member 从一个 Set 移至另一个 Set</li>\n</ul>\n</li>\n<li><p>sadd</p>\n<ul>\n<li>向指定 Set 中添加 1 个或多个 member，如果指定 Set 不存在，会自动创建一个。</li>\n</ul>\n</li>\n<li><p>srem</p>\n<ul>\n<li>从指定 Set 中移除 1 个或多个 member</li>\n</ul>\n</li>\n<li><p>srandmember</p>\n<ul>\n<li>从指定 Set 中随机返回 1 个或多个 member</li>\n</ul>\n</li>\n<li><p>spop</p>\n<ul>\n<li>从指定 Set 中随机移除并返回 count 个 member</li>\n</ul>\n</li>\n<li><p>smembers</p>\n<ul>\n<li>返回指定 Hash 中所有的 member</li>\n</ul>\n</li>\n<li><p>sunion/sunionstore</p>\n<ul>\n<li>计算多个 Set 的并集并返回 / 存储至另一个 Set 中</li>\n</ul>\n</li>\n<li><p>sinter/sinterstore</p>\n<ul>\n<li>计算多个 Set 的交集并返回 / 存储至另一个 Set 中</li>\n</ul>\n</li>\n<li><p>sdiff/sinterstore</p>\n<ul>\n<li>计算 1 个 Set 与 1 或多个 Set 的差集并返回 / 存储至另一个 Set 中</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"zset\"><a href=\"#zset\" class=\"headerlink\" title=\"zset\"></a>zset</h3><ul>\n<li>zadd</li>\n<li>zrem</li>\n<li>zcard</li>\n<li>zcount</li>\n<li>zscore</li>\n<li>zrank/zrevrank</li>\n<li>zincrby</li>\n<li>zrange/zrevrange</li>\n<li>zrangebyscore/zrevragebyscore</li>\n<li>zremrangebyrank/zremrangebyscore</li>\n</ul>\n<h3 id=\"事物\"><a href=\"#事物\" class=\"headerlink\" title=\"事物\"></a>事物</h3><ul>\n<li><p>multi </p>\n<ul>\n<li>开启一个事务</li>\n</ul>\n</li>\n<li><p>exec </p>\n<ul>\n<li>执行事务</li>\n</ul>\n</li>\n<li><p>discard </p>\n<ul>\n<li>撤销事务</li>\n</ul>\n</li>\n<li><p>watch </p>\n<ul>\n<li>监视数据库键，若发生改变，返回空</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"复制\"><a href=\"#复制\" class=\"headerlink\" title=\"复制\"></a>复制</h3><ul>\n<li><p>info replication</p>\n<ul>\n<li>获取复制信息</li>\n</ul>\n</li>\n<li><p>slaveof</p>\n<ul>\n<li>建立复制关系</li>\n</ul>\n</li>\n<li><p>sync </p>\n<ul>\n<li>同步</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"订阅发布\"><a href=\"#订阅发布\" class=\"headerlink\" title=\"订阅发布\"></a>订阅发布</h3><ul>\n<li><p>subscribe</p>\n<ul>\n<li>订阅一个或多个频道</li>\n</ul>\n</li>\n<li><p>publish </p>\n<ul>\n<li>向某一频道发送信息</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"性能调优\"><a href=\"#性能调优\" class=\"headerlink\" title=\"性能调优\"></a>性能调优</h2><ul>\n<li><h3 id=\"避免存储-bigkey\"><a href=\"#避免存储-bigkey\" class=\"headerlink\" title=\"避免存储 bigkey\"></a>避免存储 bigkey</h3></li>\n<li><h3 id=\"使用-pipelining-将连续执行的命令组合执行\"><a href=\"#使用-pipelining-将连续执行的命令组合执行\" class=\"headerlink\" title=\"使用 pipelining 将连续执行的命令组合执行\"></a>使用 pipelining 将连续执行的命令组合执行</h3></li>\n<li><h3 id=\"操作系统的-Transparent-huge-pages-功能必须关闭\"><a href=\"#操作系统的-Transparent-huge-pages-功能必须关闭\" class=\"headerlink\" title=\"操作系统的 Transparent huge pages 功能必须关闭\"></a>操作系统的 Transparent huge pages 功能必须关闭</h3><pre><code>  echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\n</code></pre></li>\n<li><h3 id=\"使用物理机部署-Redis\"><a href=\"#使用物理机部署-Redis\" class=\"headerlink\" title=\"使用物理机部署 Redis\"></a>使用物理机部署 Redis</h3><ul>\n<li>Redis 在做数据持久化时，采用创建子进程的方式进行。<br>而创建子进程会调用操作系统的 fork 系统调用，这个系统调用的执行耗时，与系统环境有关。<br>虚拟机环境执行 fork 的耗时，要比物理机慢得多，所以你的 Redis 应该尽可能部署在物理机上</li>\n</ul>\n</li>\n<li><h3 id=\"检查数据持久化策略\"><a href=\"#检查数据持久化策略\" class=\"headerlink\" title=\"检查数据持久化策略\"></a>检查数据持久化策略</h3></li>\n<li><h3 id=\"考虑引入读写分离机制\"><a href=\"#考虑引入读写分离机制\" class=\"headerlink\" title=\"考虑引入读写分离机制\"></a>考虑引入读写分离机制</h3></li>\n<li><h3 id=\"开启-lazy-free-机制\"><a href=\"#开启-lazy-free-机制\" class=\"headerlink\" title=\"开启 lazy-free 机制\"></a>开启 lazy-free 机制</h3><ul>\n<li>如果你无法避免存储 bigkey，那么我建议你开启 Redis 的 lazy-free 机制。（4.0+版本支持）<br>当开启这个机制后，Redis 在删除一个 bigkey 时，释放内存的耗时操作，将会放到后台线程中去执行，这样可以在最大程度上，避免对主线程的影响</li>\n</ul>\n</li>\n<li><h3 id=\"不使用复杂度过高的命令\"><a href=\"#不使用复杂度过高的命令\" class=\"headerlink\" title=\"不使用复杂度过高的命令\"></a>不使用复杂度过高的命令</h3><ul>\n<li>避免执行例如 SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE 等聚合类命令。<br>对于这种聚合类操作，我建议你把它放到客户端来执行，不要让 Redis 承担太多的计算工作</li>\n</ul>\n</li>\n<li><h3 id=\"执行-O-N-命令时，关注-N-的大\"><a href=\"#执行-O-N-命令时，关注-N-的大\" class=\"headerlink\" title=\"执行 O(N) 命令时，关注 N 的大\"></a>执行 O(N) 命令时，关注 N 的大</h3><ul>\n<li><p>查询数据时，遵循原则</p>\n<ul>\n<li>先查询数据元素的数量（LLEN/HLEN/SCARD/ZCARD）</li>\n<li>元素数量较少，可一次性查询全量数据</li>\n<li>元素数量非常多，分批查询数据（LRANGE/HASCAN/SSCAN/ZSCAN）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"关注-DEL-时间复杂度\"><a href=\"#关注-DEL-时间复杂度\" class=\"headerlink\" title=\"关注 DEL 时间复杂度\"></a>关注 DEL 时间复杂度</h3><ul>\n<li><p>删除一个 key，其元素数量越多，执行 DEL 也就越慢</p>\n<ul>\n<li>List类型：执行多次 LPOP/RPOP，直到所有元素都删除完成</li>\n<li>Hash/Set/ZSet类型：先执行 HSCAN/SSCAN/SCAN 查询元素，再执行 HDEL/SREM/ZREM 依次删除每个元素</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"批量命令代替单个命令\"><a href=\"#批量命令代替单个命令\" class=\"headerlink\" title=\"批量命令代替单个命令\"></a>批量命令代替单个命令</h3><ul>\n<li><p>批量操作相比于多次单个操作的优势在于，可以显著减少客户端、服务端的来回网络 IO 次数</p>\n</li>\n<li><p>String / Hash 使用 MGET/MSET 替代 GET/SET，HMGET/HMSET 替代 HGET/HSET</p>\n</li>\n<li>其它数据类型使用 Pipeline，打包一次性发送多个命令到服务端执行</li>\n</ul>\n</li>\n<li><h3 id=\"避免集中过期-key\"><a href=\"#避免集中过期-key\" class=\"headerlink\" title=\"避免集中过期 key\"></a>避免集中过期 key</h3><ul>\n<li><p>如果你的业务存在大量 key 集中过期的情况，那么 Redis 在清理过期 key 时，也会有阻塞主线程的风险</p>\n</li>\n<li><p>在设置过期时间时，增加一个随机时间，把这些 key 的过期时间打散，从而降低集中过期对主线程的影响</p>\n</li>\n</ul>\n</li>\n<li><h3 id=\"使用长连接操作-Redis，合理配置连接池\"><a href=\"#使用长连接操作-Redis，合理配置连接池\" class=\"headerlink\" title=\"使用长连接操作 Redis，合理配置连接池\"></a>使用长连接操作 Redis，合理配置连接池</h3><ul>\n<li>你的业务应该使用长连接操作 Redis，避免短连接</li>\n<li>当使用短连接操作 Redis 时，每次都需要经过 TCP 三次握手、四次挥手，这个过程也会增加操作耗时</li>\n<li>同时，你的客户端应该使用连接池的方式访问 Redis，并设置合理的参数，长时间不操作 Redis 时，需及时释放连接资源</li>\n</ul>\n</li>\n<li><h3 id=\"只使用-db0\"><a href=\"#只使用-db0\" class=\"headerlink\" title=\"只使用 db0\"></a>只使用 db0</h3><ul>\n<li>在一个连接上操作多个 db 数据时，每次都需要先执行 SELECT，这会给 Redis 带来额外的压力</li>\n<li>使用多个 db 的目的是，按不同业务线存储数据，那为何不拆分多个实例存储呢？拆分多个实例部署，多个业务线不会互相影响，还能提高 Redis 的访问性能</li>\n<li>Redis Cluster 只支持 db0，如果后期你想要迁移到 Redis Cluster，迁移成本高</li>\n</ul>\n</li>\n<li><h3 id=\"使用读写分离-分片集群\"><a href=\"#使用读写分离-分片集群\" class=\"headerlink\" title=\"使用读写分离 + 分片集群\"></a>使用读写分离 + 分片集群</h3><ul>\n<li>如果你的业务读请求量很大，那么可以采用部署多个从库的方式，实现读写分离，让 Redis 的从库分担读压力，进而提升性能</li>\n<li>如果你的业务写请求量很大，单个 Redis 实例已无法支撑这么大的写流量，那么此时你需要使用分片集群，分担写压力</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"不开启-AOF-或-AOF-配置为每秒刷盘\"><a href=\"#不开启-AOF-或-AOF-配置为每秒刷盘\" class=\"headerlink\" title=\"不开启 AOF 或 AOF 配置为每秒刷盘\"></a>不开启 AOF 或 AOF 配置为每秒刷盘</h3><ul>\n<li>如果对于丢失数据不敏感的业务，我建议你不开启 AOF，避免 AOF 写磁盘拖慢 Redis 的性能</li>\n<li>如果确实需要开启 AOF，那么我建议你配置为 appendfsync everysec，把数据持久化的刷盘操作，放到后台线程中去执行，尽量降低 Redis 写磁盘对性能的影响</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"长耗时命令\"><a href=\"#长耗时命令\" class=\"headerlink\" title=\"长耗时命令\"></a>长耗时命令</h2><ul>\n<li><h3 id=\"避免在使用这些-O-N-命令\"><a href=\"#避免在使用这些-O-N-命令\" class=\"headerlink\" title=\"避免在使用这些 O(N) 命令\"></a>避免在使用这些 O(N) 命令</h3><ul>\n<li>不要把 List 当做列表使用，仅当做队列来使用</li>\n<li>通过机制严格控制 Hash、Set、Sorted Set 的大小</li>\n<li>可能的话，将排序、并集、交集等操作放在客户端执行</li>\n<li>绝对禁止使用 keys 命令</li>\n<li>避免一次性遍历集合类型的所有成员，而应使用 scan 类的命令进行分批的，游标式的遍历</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"Slow-Log-功能，自动记录耗时较长的命令\"><a href=\"#Slow-Log-功能，自动记录耗时较长的命令\" class=\"headerlink\" title=\"Slow Log 功能，自动记录耗时较长的命令\"></a>Slow Log 功能，自动记录耗时较长的命令</h3><ul>\n<li>slowlog-log-slower-than xxxms  #执行时间慢于xxx毫秒的命令计入  。                              Slow Logslowlog-max-len xxx  #Slow Log的长度，即最大纪录多少条Slow Log</li>\n<li>使用 slowlog get [number] 命令，可以输出最近进入 Slow Log 的 number 条命令。<br>使用 slowlog reset 命令，可以重置 Slow Log</li>\n</ul>\n</li>\n<li><h3 id=\"网络引发的延迟\"><a href=\"#网络引发的延迟\" class=\"headerlink\" title=\"网络引发的延迟\"></a>网络引发的延迟</h3><ul>\n<li>尽可能使用长连接或连接池，避免频繁创建销毁连接</li>\n<li>客户端进行的批量数据操作，应使用 Pipeline 特性在一次交互中完成。</li>\n</ul>\n</li>\n<li><h3 id=\"数据持久化引发的延迟\"><a href=\"#数据持久化引发的延迟\" class=\"headerlink\" title=\"数据持久化引发的延迟\"></a>数据持久化引发的延迟</h3><ul>\n<li><p>要根据数据的安全级别和性能要求制定合理的持久化策略</p>\n<ul>\n<li>AOF + fsync always 的设置虽然能够绝对确保数据安全，但每个操作都会触发一次 fsync，会对 Redis 的性能有比较明显的影响</li>\n<li>AOF + fsync every second 是比较好的折中方案，每秒 fsync 一次</li>\n<li>AOF + fsync never 会提供 AOF 持久化方案下的最优性能<br>使用 RDB 持久化通常会提供比使用 AOF 更高的性能，但需要注意 RDB 的策略配置</li>\n<li>每一次 RDB 快照和 AOF Rewrite 都需要 Redis 主进程进行 fork 操作。fork 操作本身可能会产生较高的耗时，与 CPU 和 Redis 占用的内存大小有关。根据具体的情况合理配置 RDB 快照和 AOF Rewrite 时机，避免过于频繁的 fork 带来的延迟</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"Swap-引发的延迟\"><a href=\"#Swap-引发的延迟\" class=\"headerlink\" title=\"Swap 引发的延迟\"></a>Swap 引发的延迟</h3><ul>\n<li><p>当 Linux 将 Redis 所用的内存分页移至 swap 空间时，将会阻塞 Redis 进程，导致 Redis 出现不正常的延迟。Swap 通常在物理内存不足或一些进程在进行大量 I/O 操作时发生，应尽可能避免上述两种情况的出现。<br>/proc//smaps 文件中会保存进程的 swap 记录，通过查看这个文件，能够判断 Redis 的延迟是否由 Swap 产生。如果这个文件中记录了较大的 Swap size，则说明延迟很有可能是 Swap 造成的。</p>\n</li>\n<li><p>数据淘汰引发的延迟<br>当同一秒内有大量 key 过期时，也会引发 Redis 的延迟。在使用时应尽量将 key 的失效时间错开。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"主从复制与集群分片\"><a href=\"#主从复制与集群分片\" class=\"headerlink\" title=\"主从复制与集群分片\"></a>主从复制与集群分片</h2><ul>\n<li><h3 id=\"主从复制\"><a href=\"#主从复制\" class=\"headerlink\" title=\"主从复制\"></a>主从复制</h3><ul>\n<li><p>Redis 支持一主多从的主从复制架构。一个 Master 实例负责处理所有的写请求，Master 将写操作同步至所有 Slave。</p>\n<ul>\n<li><p>借助 Redis 的主从复制，可以实现读写分离和高可用</p>\n<ul>\n<li>实时性要求不是特别高的读请求，可以在 Slave 上完成，提升效率。特别是一些周期性执行的统计任务，这些任务可能需要执行一些长耗时的 Redis 命令，可以专门规划出 1 个或几个 Slave 用于服务这些统计任务</li>\n<li>借助 Redis Sentinel 可以实现高可用，当 Master crash 后，Redis Sentinel 能够自动将一个 Slave 晋升为 Master，继续提供服务</li>\n</ul>\n</li>\n<li><p>Sentinel 做自动 failover</p>\n<ul>\n<li><p>Redis 的主从复制功能本身只是做数据同步，并不提供监控和自动 failover 能力，要通过主从复制功能来实现 Redis 的高可用，还需要引入一个组件：Redis Sentinel<br>Redis Sentinel 是 Redis 官方开发的监控组件，可以监控 Redis 实例的状态，通过 Master 节点自动发现 Slave 节点，并在监测到 Master 节点失效时选举出一个新的 Master，并向所有 Redis 实例推送新的主从配置</p>\n<ul>\n<li>sentinel monitor mymaster 127.0.0.1 6379 2  #Master实例的IP、端口，以及选举需要的赞成票数</li>\n<li>sentinel down-after-milliseconds mymaster 60000  #多长时间没有响应视为Master失效</li>\n<li>sentinel failover-timeout mymaster 180000  #两次failover尝试间的间隔时长</li>\n<li>sentinel parallel-syncs mymaster 1  #如果有多个Slave，可以通过此配置指定同时从新Master进行数据同步的Slave数，避免所有Slave同时进行数据同步导致查询服务也不可用</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"集群分片\"><a href=\"#集群分片\" class=\"headerlink\" title=\"集群分片\"></a>集群分片</h3><ul>\n<li>Redis 中存储的数据量大，一台主机的物理内存已经无法容纳</li>\n<li>Redis 的写请求并发量大，一个 Redis 实例以无法承载</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><ul>\n<li><h3 id=\"缓存和数据库双写一致性问题\"><a href=\"#缓存和数据库双写一致性问题\" class=\"headerlink\" title=\"缓存和数据库双写一致性问题\"></a>缓存和数据库双写一致性问题</h3><ul>\n<li>降低不一致发生的概率，无法完全避免</li>\n<li>只能保证最终一致性</li>\n</ul>\n<p>首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。</p>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"缓存雪崩问题\"><a href=\"#缓存雪崩问题\" class=\"headerlink\" title=\"缓存雪崩问题\"></a>缓存雪崩问题</h3><ul>\n<li>缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"缓存穿透\"><a href=\"#缓存穿透\" class=\"headerlink\" title=\"缓存穿透\"></a>缓存穿透</h3><ul>\n<li>缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常</li>\n</ul>\n</li>\n<li><h3 id=\"缓存击穿问题\"><a href=\"#缓存击穿问题\" class=\"headerlink\" title=\"缓存击穿问题\"></a>缓存击穿问题</h3><ul>\n<li>在第一个查询数据的请求上使用一个互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h2><ul>\n<li><h3 id=\"纯内存操作\"><a href=\"#纯内存操作\" class=\"headerlink\" title=\"纯内存操作\"></a>纯内存操作</h3><ul>\n<li>Redis将所有数据放在内存中，非数据同步正常工作中，是不需要从磁盘读取数据的，0次IO。内存响应时间大约为100纳秒</li>\n</ul>\n</li>\n<li><h3 id=\"单线程操作，避免了频繁的上下文切换\"><a href=\"#单线程操作，避免了频繁的上下文切换\" class=\"headerlink\" title=\"单线程操作，避免了频繁的上下文切换\"></a>单线程操作，避免了频繁的上下文切换</h3><ul>\n<li>第一，单线程简化算法的实现，并发的数据结构实现不但困难且测试也麻烦。第二，单线程避免了线程切换以及加锁释放锁带来的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。当然了，单线程也会有它的缺点，也是Redis的噩梦：阻塞。如果执行一个命令过长，那么会造成其他命令的阻塞，对于Redis是十分致命的，所以Redis是面向快速执行场景的数据库。</li>\n</ul>\n</li>\n<li><h3 id=\"采用了非阻塞I-O多路复用机制\"><a href=\"#采用了非阻塞I-O多路复用机制\" class=\"headerlink\" title=\"采用了非阻塞I/O多路复用机制\"></a>采用了非阻塞I/O多路复用机制</h3><ul>\n<li>当使用read或者write对某一文件描述符（File Descriptor FD）进行读写的时候，如果数据没有收到，那么该线程会被挂起，直到收到数据</li>\n<li><p>I/O多路复用实际上是指多个连接的管理可以在同一进程。多路是指网络连接，复用只是同一个线程</p>\n<ul>\n<li>Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll的read、write、close等都转换成事件，不在网络I/O上浪费过多的时间。实现对多个FD读写的监控，提高性能。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"策略以及内存淘汰机制\"><a href=\"#策略以及内存淘汰机制\" class=\"headerlink\" title=\"策略以及内存淘汰机制\"></a>策略以及内存淘汰机制</h2><ul>\n<li><h3 id=\"删除机制\"><a href=\"#删除机制\" class=\"headerlink\" title=\"删除机制\"></a>删除机制</h3><ul>\n<li><p>定期删除</p>\n<ul>\n<li>用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key</li>\n</ul>\n</li>\n<li><p>惰性删除策略</p>\n<ul>\n<li>所谓惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期了就立即删除，不会给你返回任何东西。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"内存淘汰策略\"><a href=\"#内存淘汰策略\" class=\"headerlink\" title=\"内存淘汰策略\"></a>内存淘汰策略</h3><ul>\n<li><p>noeviction</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，新写入操作会报错</li>\n</ul>\n</li>\n<li><p>allkeys-lru</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key</li>\n</ul>\n</li>\n<li><p>allkeys-random</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在键空间中，随机移除某个key</li>\n</ul>\n</li>\n<li><p>volatile-lru</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。不推荐</li>\n</ul>\n</li>\n<li><p>volatile-random</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。不推荐</li>\n</ul>\n</li>\n<li><p>volatile-ttl</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。不推荐</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"持久化策略\"><a href=\"#持久化策略\" class=\"headerlink\" title=\"持久化策略\"></a>持久化策略</h3><ul>\n<li><p>快照（RDB）</p>\n<ul>\n<li>快照是内存数据的二进制序列化形式，在存储上非常紧凑</li>\n<li>RDB是通过Redis主进程fork子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化。RDB记录的是数据</li>\n</ul>\n</li>\n<li><p>日志追加（AOF）</p>\n<ul>\n<li>AOF 日志是连续的增量备份，在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长</li>\n<li>AOF 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的指令记录。AOF记录的是指令</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"节省内存\"><a href=\"#节省内存\" class=\"headerlink\" title=\"节省内存\"></a>节省内存</h2><ul>\n<li><h3 id=\"控制-key-的长度\"><a href=\"#控制-key-的长度\" class=\"headerlink\" title=\"控制 key 的长度\"></a>控制 key 的长度</h3></li>\n<li><h3 id=\"避免存储-bigkey-1\"><a href=\"#避免存储-bigkey-1\" class=\"headerlink\" title=\"避免存储 bigkey\"></a>避免存储 bigkey</h3><ul>\n<li>String：大小控制在 10KB 以下</li>\n<li>List/Hash/Set/ZSet：元素数量控制在 1 万以下</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"选择合适的数据类型\"><a href=\"#选择合适的数据类型\" class=\"headerlink\" title=\"选择合适的数据类型\"></a>选择合适的数据类型</h3><ul>\n<li>String、Set：尽可能存储 int 类型数据</li>\n<li>Hash、ZSet：存储的元素数量控制在转换阈值之下，以压缩列表存储，节约内存</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"把-Redis-当作缓存使用\"><a href=\"#把-Redis-当作缓存使用\" class=\"headerlink\" title=\"把 Redis 当作缓存使用\"></a>把 Redis 当作缓存使用</h3></li>\n<li><h3 id=\"实例设置-maxmemory-淘汰策略\"><a href=\"#实例设置-maxmemory-淘汰策略\" class=\"headerlink\" title=\"实例设置 maxmemory + 淘汰策略\"></a>实例设置 maxmemory + 淘汰策略</h3><ul>\n<li>volatile-lru / allkeys-lru：优先保留最近访问过的数据</li>\n<li>volatile-lfu / allkeys-lfu：优先保留访问次数最频繁的数据（4.0+版本支持）</li>\n<li>volatile-ttl ：优先淘汰即将过期的数据</li>\n<li>volatile-random / allkeys-random：随机淘汰数据</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"数据压缩后写入-Redis\"><a href=\"#数据压缩后写入-Redis\" class=\"headerlink\" title=\"数据压缩后写入 Redis\"></a>数据压缩后写入 Redis</h3></li>\n</ul>\n<h2 id=\"可靠性\"><a href=\"#可靠性\" class=\"headerlink\" title=\"可靠性\"></a>可靠性</h2><ul>\n<li><h3 id=\"按业务线部署实例\"><a href=\"#按业务线部署实例\" class=\"headerlink\" title=\"按业务线部署实例\"></a>按业务线部署实例</h3><ul>\n<li>提升可靠性的第一步，就是「资源隔离」。<br>你最好按不同的业务线来部署 Redis 实例，这样当其中一个实例发生故障时，不会影响到其它业务。<br>这种资源隔离的方案，实施成本是最低的，但成效却是非常大的</li>\n</ul>\n</li>\n<li><h3 id=\"部署主从集群\"><a href=\"#部署主从集群\" class=\"headerlink\" title=\"部署主从集群\"></a>部署主从集群</h3><ul>\n<li>如果你只使用单机版 Redis，那么就会存在机器宕机服务不可用的风险。<br>所以，你需要部署「多副本」实例，即主从集群，这样当主库宕机后，依旧有从库可以使用，避免了数据丢失的风险，也降低了服务不可用的时间。<br>在部署主从集群时，你还需要注意，主从库需要分布在不同机器上，避免交叉部署。<br>这么做的原因在于，通常情况下，Redis 的主库会承担所有的读写流量，所以我们一定要优先保证主库的稳定性，即使从库机器异常，也不要对主库造成影响。<br>而且，有时我们需要对 Redis 做日常维护，例如数据定时备份等操作，这时你就可以只在从库上进行，这只会消耗从库机器的资源，也避免了对主库的影响</li>\n</ul>\n</li>\n<li><h3 id=\"合理配置主从复制参数\"><a href=\"#合理配置主从复制参数\" class=\"headerlink\" title=\"合理配置主从复制参数\"></a>合理配置主从复制参数</h3><ul>\n<li><p>不合理</p>\n<ul>\n<li>主从复制中断</li>\n<li>从库发起全量复制，主库性能受到影响</li>\n</ul>\n</li>\n<li><p>合理</p>\n<ul>\n<li>设置合理的 repl-backlog 参数：过小的 repl-backlog 在写流量比较大的场景下，主从复制中断会引发全量复制数据的风险</li>\n<li>设置合理的 slave client-output-buffer-limit：当从库复制发生问题时，过小的 buffer 会导致从库缓冲区溢出，从而导致复制中断</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"部署哨兵集群，实现故障自动切换\"><a href=\"#部署哨兵集群，实现故障自动切换\" class=\"headerlink\" title=\"部署哨兵集群，实现故障自动切换\"></a>部署哨兵集群，实现故障自动切换</h3><ul>\n<li>只部署了主从节点，但故障发生时是无法自动切换的，所以，你还需要部署哨兵集群，实现故障的「自动切换」。<br>而且，多个哨兵节点需要分布在不同机器上，实例为奇数个，防止哨兵选举失败，影响切换时间</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"日常运维\"><a href=\"#日常运维\" class=\"headerlink\" title=\"日常运维\"></a>日常运维</h2><ul>\n<li><h3 id=\"禁止使用-KEYS-FLUSHALL-FLUSHDB-命令\"><a href=\"#禁止使用-KEYS-FLUSHALL-FLUSHDB-命令\" class=\"headerlink\" title=\"禁止使用 KEYS/FLUSHALL/FLUSHDB 命令\"></a>禁止使用 KEYS/FLUSHALL/FLUSHDB 命令</h3><ul>\n<li><p>执行这些命令，会长时间阻塞 Redis 主线程，危害极大</p>\n<ul>\n<li>SCAN 替换 KEYS</li>\n<li>4.0+版本可使用 FLUSHALL/FLUSHDB ASYNC，清空数据的操作放在后台线程执行</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"扫描线上实例时，设置休眠时间\"><a href=\"#扫描线上实例时，设置休眠时间\" class=\"headerlink\" title=\"扫描线上实例时，设置休眠时间\"></a>扫描线上实例时，设置休眠时间</h3><ul>\n<li>不管你是使用 SCAN 扫描线上实例，还是对实例做 bigkey 统计分析，我建议你在扫描时一定记得设置休眠时间。<br>防止在扫描过程中，实例 OPS 过高对 Redis 产生性能抖动</li>\n</ul>\n</li>\n<li><h3 id=\"慎用-MONITOR-命令\"><a href=\"#慎用-MONITOR-命令\" class=\"headerlink\" title=\"慎用 MONITOR 命令\"></a>慎用 MONITOR 命令</h3><ul>\n<li>有时在排查 Redis 问题时，你会使用 MONITOR 查看 Redis 正在执行的命令。<br>但如果你的 Redis OPS 比较高，那么在执行 MONITOR 会导致 Redis 输出缓冲区的内存持续增长，这会严重消耗 Redis 的内存资源，甚至会导致实例内存超过 maxmemory，引发数据淘汰，这种情况你需要格外注意</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"从库必须设置为-slave-read-only\"><a href=\"#从库必须设置为-slave-read-only\" class=\"headerlink\" title=\"从库必须设置为 slave-read-only\"></a>从库必须设置为 slave-read-only</h3><ul>\n<li>你的从库必须设置为 slave-read-only 状态，避免从库写入数据，导致主从数据不一致。<br>除此之外，从库如果是非 read-only 状态，如果你使用的是 4.0 以下的 Redis，它存在这样的 Bug：<br>从库写入了有过期时间的数据，不会做定时清理和释放内存。<br>这会造成从库的内存泄露！这个问题直到 4.0 版本才修复，你在配置从库时需要格外注意</li>\n</ul>\n</li>\n<li><h3 id=\"合理配置-timeout-和-tcp-keepalive-参数\"><a href=\"#合理配置-timeout-和-tcp-keepalive-参数\" class=\"headerlink\" title=\"合理配置 timeout 和 tcp-keepalive 参数\"></a>合理配置 timeout 和 tcp-keepalive 参数</h3><ul>\n<li>如果因为网络原因，导致你的大量客户端连接与 Redis 意外中断，恰好你的 Redis 配置的 maxclients 参数比较小，此时有可能导致客户端无法与服务端建立新的连接（服务端认为超过了 maxclients）。<br>造成这个问题原因在于，客户端与服务端每建立一个连接，Redis 都会给这个客户端分配了一个 client fd。</li>\n</ul>\n<p>当客户端与服务端网络发生问题时，服务端并不会立即释放这个 client fd。</p>\n<p>什么时候释放呢？</p>\n<p>Redis 内部有一个定时任务，会定时检测所有 client 的空闲时间是否超过配置的 timeout 值。<br>如果 Redis 没有开启 tcp-keepalive 的话，服务端直到配置的 timeout 时间后，才会清理释放这个 client fd。</p>\n<p>在没有清理之前，如果还有大量新连接进来，就有可能导致 Redis 服务端内部持有的 client fd 超过了 maxclients，这时新连接就会被拒绝。</p>\n<p>针对这种情况，我给你的优化建议是：<br>不要配置过高的 timeout：让服务端尽快把无效的 client fd 清理掉<br>Redis 开启 tcp-keepalive：这样服务端会定时给客户端发送 TCP 心跳包，检测连接连通性，当网络异常时，可以尽快清理僵尸 client fd</p>\n</li>\n<li><h3 id=\"调整-maxmemory-时，注意主从库的调整顺序\"><a href=\"#调整-maxmemory-时，注意主从库的调整顺序\" class=\"headerlink\" title=\"调整 maxmemory 时，注意主从库的调整顺序\"></a>调整 maxmemory 时，注意主从库的调整顺序</h3><ul>\n<li>从库内存如果超过了 maxmemory，也会触发数据淘汰。<br>在某些场景下，从库是可能优先主库达到 maxmemory 的（例如在从库执行 MONITOR 命令，输出缓冲区占用大量内存），那么此时从库开始淘汰数据，主从库就会产生不一致。</li>\n</ul>\n<p>要想避免此问题，在调整 maxmemory 时，一定要注意主从库的修改顺序：</p>\n<p>调大 maxmemory：先修改从库，再修改主库</p>\n<p>调小 maxmemory：先修改主库，再修改从库</p>\n<p>直到 Redis 5.0，Redis 才增加了一个配置 replica-ignore-maxmemory，默认从库超过 maxmemory 不会淘汰数据，才解决了此问题</p>\n</li>\n</ul>\n<h2 id=\"预防-Redis-问题\"><a href=\"#预防-Redis-问题\" class=\"headerlink\" title=\"预防 Redis 问题\"></a>预防 Redis 问题</h2><ul>\n<li><h3 id=\"合理的资源规划\"><a href=\"#合理的资源规划\" class=\"headerlink\" title=\"合理的资源规划\"></a>合理的资源规划</h3><ul>\n<li>保证机器有足够的 CPU、内存、带宽、磁盘资源</li>\n<li>提前做好容量规划，主库机器预留一半内存资源，防止主从机器网络故障，引发大面积全量同步，导致主库机器内存不足的问题</li>\n<li>单个实例内存建议控制在 10G 以下，大实例在主从全量同步、RDB 备份时有阻塞风险</li>\n</ul>\n</li>\n<li><h3 id=\"完善的监控预警\"><a href=\"#完善的监控预警\" class=\"headerlink\" title=\"完善的监控预警\"></a>完善的监控预警</h3><ul>\n<li>做好机器 CPU、内存、带宽、磁盘监控，资源不足时及时报警，任意资源不足都会影响 Redis 性能</li>\n<li>设置合理的 slowlog 阈值，并对其进行监控，slowlog 过多及时报警</li>\n<li>监控组件采集 Redis INFO 信息时，采用长连接，避免频繁的短连接</li>\n<li>做好实例运行时监控，重点关注 expired_keys、evicted_keys、latest_fork_usec 指标，这些指标短时突增可能会有阻塞风险</li>\n</ul>\n<p>以上命令，应尽量避免传递 [0 -1] 或 [-inf +inf] 这样的参数，来对 Sorted Set 做一次性的完整遍历，特别是在 Sorted Set 的尺寸不可预知的情况下。可以通过 ZSCAN 命令来进行游标式的遍历，或通过 LIMIT 参数来限制返回 member 的数量（适用于 ZRANGEBYSCORE 和 ZREVRANGEBYSCORE 命令），以实现游标式的遍历</p>\n</li>\n</ul>\n<p> 时间复杂度为O(N)，N随着redis中key的数量增加而增加，因此redis有大量的key,keys命令会执行很长时间，而由于Redis是单线程，某个命令耗费过长时间，则会导致后面的的所有请求无法得到响应</p>\n<p> <img src=\"/img/202104/redis.svg\" alt=\"reids总结图\"></p>\n",
            "tags": [
                "redis",
                "redis总结",
                "redis命令"
            ]
        }
    ]
}