{
    "version": "https://jsonfeed.org/version/1",
    "title": "艾瑞可erik • All posts by \"linux\" categories",
    "description": "一只PHP开发的程序猿，偶尔做做运维、Goland、Python、Java、摄影、画画、写作、顺便睡觉，反正整站都搞过。",
    "home_page_url": "https://erik.xyz",
    "items": [
        {
            "id": "https://erik.xyz/2025/02/13/open-source-esktop-sharing-tool/",
            "url": "https://erik.xyz/2025/02/13/open-source-esktop-sharing-tool/",
            "title": "开源桌面共享工具",
            "date_published": "2025-02-13T13:35:00.000Z",
            "content_html": "<h2 id=\"1-xrdp\"><a href=\"#1-xrdp\" class=\"headerlink\" title=\"1. xrdp\"></a>1. <a href=\"https://github.com/neutrinolabs/xrdp\">xrdp</a></h2><ul>\n<li><strong>功能</strong>：xrdp 是一个开源的远程桌面协议 (RDP) 服务器，允许 Linux 系统通过 Windows 的 RDP 客户端远程访问。它与 Microsoft RDP 协议兼容，能够让你从 Windows 客户端连接到 Linux 系统。</li>\n<li><strong>安装</strong>：通常可以通过 Linux 的包管理器安装，例如在 Ubuntu 上使用命令：<span id=\"more\"></span>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install xrdp</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"2-VNC-Virtual-Network-Computing\"><a href=\"#2-VNC-Virtual-Network-Computing\" class=\"headerlink\" title=\"2. VNC (Virtual Network Computing)\"></a>2. VNC (Virtual Network Computing)</h2><ul>\n<li><strong>功能</strong>：VNC 是一种图形桌面共享系统，支持跨平台远程访问。常见的开源 VNC 实现有：<ul>\n<li><strong>TightVNC</strong>：轻量级且性能优化。</li>\n<li><strong>TigerVNC</strong>：增强了性能和安全性。</li>\n<li><strong>RealVNC</strong>：提供商业和开源版本。</li>\n</ul>\n</li>\n<li><strong>安装</strong>：可以通过包管理器（如 <code>apt</code>）安装，或通过下载其源代码来安装。</li>\n</ul>\n<h2 id=\"3-NoMachine\"><a href=\"#3-NoMachine\" class=\"headerlink\" title=\"3. NoMachine\"></a>3. <a href=\"https://www.nomachine.com/\">NoMachine</a></h2><ul>\n<li><strong>功能</strong>：NoMachine 是一款开源远程桌面解决方案，支持跨平台远程访问。它具有高性能和较低延迟，支持音视频流和文件传输等功能。</li>\n<li><strong>安装</strong>：可以直接从官网下载安装包，也可以通过官方的开源版本进行安装。</li>\n</ul>\n<h2 id=\"4-Remmina\"><a href=\"#4-Remmina\" class=\"headerlink\" title=\"4. Remmina\"></a>4. <a href=\"https://github.com/FreeRDP/Remmina\">Remmina</a></h2><ul>\n<li><strong>功能</strong>：Remmina 是一个支持多种远程桌面协议的客户端，支持 RDP、VNC、SSH 等多种协议。它的设计非常适合 Linux 用户，但也支持其他操作系统。</li>\n<li><strong>安装</strong>：大多数 Linux 发行版都可以通过包管理器安装，例如：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> apt install remmina</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"5-FreeRDP\"><a href=\"#5-FreeRDP\" class=\"headerlink\" title=\"5. FreeRDP\"></a>5. <a href=\"https://github.com/FreeRDP/FreeRDP\">FreeRDP</a></h2><ul>\n<li><strong>功能</strong>：FreeRDP 是一个开源的远程桌面协议实现，可以用作 RDP 客户端和服务器。它支持 Windows 和 Linux 系统之间的远程访问，并且非常轻量级。</li>\n<li><strong>安装</strong>：可以通过包管理器进行安装，例如：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> apt install freerdp2-x11</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"6-WayVNC\"><a href=\"#6-WayVNC\" class=\"headerlink\" title=\"6. WayVNC\"></a>6. WayVNC</h2><ul>\n<li><strong>功能</strong>：WayVNC 是专门为 Wayland 兼容的 Linux 系统设计的 VNC 服务器，适用于那些使用 Wayland 显示服务器的系统。</li>\n<li><strong>安装</strong>：可以通过源码编译安装，或查找相关的 Linux 包。</li>\n</ul>\n<h2 id=\"7-Guacamole\"><a href=\"#7-Guacamole\" class=\"headerlink\" title=\"7. Guacamole\"></a>7. <a href=\"http://guacamole.apache.org/\">Guacamole</a></h2><ul>\n<li><strong>功能</strong>：Guacamole 是一个基于 Web 的远程桌面客户端，支持 RDP、VNC 和 SSH。你可以通过浏览器访问并远程控制计算机，安装较为复杂，通常需要配置 Web 服务器。</li>\n<li><strong>安装</strong>：需要在服务器端安装 Guacamole，并配置相应的 Web 服务器。它支持各种操作系统。</li>\n</ul>\n",
            "tags": [
                "工具",
                "开源工具",
                "桌面共享工具"
            ]
        },
        {
            "id": "https://erik.xyz/2025/01/03/php-serial-port-development/",
            "url": "https://erik.xyz/2025/01/03/php-serial-port-development/",
            "title": "php串口开发",
            "date_published": "2025-01-03T07:30:00.000Z",
            "content_html": "<p>使用外置设备，通过串口发送和接收数据。那么，就要在php端有个串口的操作代码。<br>PHP 的 dio 扩展（Direct I/O）提供了对底层 I/O 操作的访问，包括串口通信。通过 dio 扩展，你可以直接操作串口设备文件（如 /dev/ttyUSB0 或 COM1）来实现串口通信。<br> <span id=\"more\"></span></p>\n<h3 id=\"1-安装-dio-扩展\"><a href=\"#1-安装-dio-扩展\" class=\"headerlink\" title=\"1. 安装 dio 扩展\"></a>1. 安装 dio 扩展</h3><p>dio 扩展是 PHP 的一个 PECL 扩展。你可以通过以下步骤安装：</p>\n<p>在 Linux 上安装：<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install php-dev  # 安装 PHP 开发工具</span><br><span class=\"line\">sudo pecl install dio         # 安装 dio 扩展</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></p>\n<p>安装完成后，在 php.ini 文件中启用扩展：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">extension=dio.so</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"2-使用-dio-实现串口通信\"><a href=\"#2-使用-dio-实现串口通信\" class=\"headerlink\" title=\"2. 使用 dio 实现串口通信\"></a>2. 使用 dio 实现串口通信</h3><p>以下是一个使用 dio 扩展实现串口通信的示例代码：<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;?php</span><br><span class=\"line\">// 串口设备路径</span><br><span class=\"line\">$device = &#x27;/dev/pts/4&#x27;; // Linux</span><br><span class=\"line\">// $device = &#x27;COM1&#x27;;      // Windows</span><br><span class=\"line\"></span><br><span class=\"line\">// 打开串口设备</span><br><span class=\"line\">$fd = dio_open($device, O_RDWR | O_NOCTTY | O_NONBLOCK);</span><br><span class=\"line\"></span><br><span class=\"line\">if (!$fd) &#123;</span><br><span class=\"line\">    die(&quot;无法打开串口设备: $device\\n&quot;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// 配置串口参数</span><br><span class=\"line\">dio_tcsetattr($fd, [</span><br><span class=\"line\">    &#x27;baud&#x27; =&gt; 9600,          // 波特率</span><br><span class=\"line\">    &#x27;bits&#x27; =&gt; 8,             // 数据位</span><br><span class=\"line\">    &#x27;stop&#x27; =&gt; 1,             // 停止位</span><br><span class=\"line\">    &#x27;parity&#x27; =&gt; 0,           // 校验位 (0: none, 1: odd, 2: even)</span><br><span class=\"line\">    &#x27;flow_control&#x27; =&gt; 0,     // 流控制 (0: none, 1: hardware)</span><br><span class=\"line\">]);</span><br><span class=\"line\"></span><br><span class=\"line\">// 发送数据到串口</span><br><span class=\"line\">$message = &quot;你好我在https://erik.xyz上出生了！&quot;;</span><br><span class=\"line\">dio_write($fd, $message);</span><br><span class=\"line\">echo &quot;已发送: $message&quot;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 从串口读取数据</span><br><span class=\"line\">$data = dio_read($fd, 1024); // 读取最多 1024 字节</span><br><span class=\"line\">echo &quot;已接收: $data\\n&quot;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 关闭串口</span><br><span class=\"line\">dio_close($fd);</span><br><span class=\"line\">?&gt;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"3-代码说明\"><a href=\"#3-代码说明\" class=\"headerlink\" title=\"3. 代码说明\"></a>3. 代码说明</h3><ul>\n<li><p>dio_open: 打开串口设备文件。O_RDWR 表示以读写模式打开，O_NOCTTY 表示不将设备作为控制终端，O_NONBLOCK 表示非阻塞模式。</p>\n</li>\n<li><p>dio_tcsetattr: 配置串口参数，包括波特率、数据位、停止位、校验位和流控制。</p>\n</li>\n<li><p>dio_write: 向串口写入数据。</p>\n</li>\n<li><p>dio_read: 从串口读取数据。</p>\n</li>\n<li><p>dio_close: 关闭串口设备。</p>\n</li>\n</ul>\n<h3 id=\"4-串口参数配置\"><a href=\"#4-串口参数配置\" class=\"headerlink\" title=\"4. 串口参数配置\"></a>4. 串口参数配置</h3><ul>\n<li><p>dio_tcsetattr 的配置选项：</p>\n</li>\n<li><p>baud: 波特率（如 9600、19200、38400、57600、115200）。</p>\n</li>\n<li><p>bits: 数据位（通常为 8）。</p>\n</li>\n<li><p>stop: 停止位（1 或 2）。</p>\n</li>\n<li><p>parity: 校验位（0: 无校验，1: 奇校验，2: 偶校验）。</p>\n</li>\n<li><p>flow_control: 流控制（0: 无流控制，1: 硬件流控制）。</p>\n</li>\n</ul>\n<h2 id=\"那么这时候需要测试一下代码。那总不能真的找个串口设备吧，然而虚拟串口真香。\"><a href=\"#那么这时候需要测试一下代码。那总不能真的找个串口设备吧，然而虚拟串口真香。\" class=\"headerlink\" title=\"那么这时候需要测试一下代码。那总不能真的找个串口设备吧，然而虚拟串口真香。\"></a>那么这时候需要测试一下代码。那总不能真的找个串口设备吧，然而虚拟串口真香。</h2><h3 id=\"5-在Linux中使用-socat-模拟虚拟串口\"><a href=\"#5-在Linux中使用-socat-模拟虚拟串口\" class=\"headerlink\" title=\"5.在Linux中使用 socat 模拟虚拟串口\"></a>5.在Linux中使用 socat 模拟虚拟串口</h3><p>socat 是一个强大的工具，可以创建虚拟串口对。</p>\n<p>安装 socat：<br>在Debian/Ubuntu系统上：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt update</span><br><span class=\"line\">sudo apt install socat</span><br></pre></td></tr></table></figure>\n<p>创建虚拟串口对：<br>运行以下命令创建一对虚拟串口：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">socat -d -d pty,raw,echo=0 pty,raw,echo=0</span><br></pre></td></tr></table></figure>\n<p>运行后如图：<br><img src=\"/img/2024/20250103151316.png\" alt=\"https://erik.xyz\"><br>这样可以看到出现两个虚拟串口。<br>把上面的php代码放到文件中运行一下:<br><img src=\"/img/2024/20250103151620.png\" alt=\"https://erik.xyz\"></p>\n<p>同时新开个窗口执行：<code>cat /dev/pts/5</code>来读取串口数据。<br>如下图：<br><img src=\"/img/2024/20250103151927.png\" alt=\"https://erik.xyz\"></p>\n<p>这里是发送数据，那接收数据怎么看呢。<br>那就在代码上改造一下加个for：<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 从串口读取数据</span><br><span class=\"line\">$data = dio_read($fd, 1024); // 读取最多 1024 字节</span><br><span class=\"line\">echo &quot;已接收: $data\\n&quot;;</span><br></pre></td></tr></table></figure><br>这里改造主要是测试用，实际上不需要。<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//测试接收</span><br><span class=\"line\">for($i=0;$i&lt;20;$i++)&#123;</span><br><span class=\"line\">    sleep(3);</span><br><span class=\"line\">// 从串口读取数据</span><br><span class=\"line\">$data = dio_read($fd, 1024); // 读取最多 1024 字节</span><br><span class=\"line\">echo &quot;已接收: $data\\n&quot;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>那么，再次运行php代码,然后在新窗口运行<code>echo &quot;欢迎你出生在https://erik.xyz&quot; &gt; /dev/pts/5</code>来发送信息，你会看到如图的接收：<br><img src=\"/img/2024/20250103152421.png\" alt=\"https://erik.xyz\"></p>\n<p>到这里，发送和接收串口已经好了。</p>\n",
            "tags": [
                "php",
                "php串口开发"
            ]
        },
        {
            "id": "https://erik.xyz/2024/12/18/maven-intranet-library/",
            "url": "https://erik.xyz/2024/12/18/maven-intranet-library/",
            "title": "maven内网库",
            "date_published": "2024-12-18T12:55:00.000Z",
            "content_html": "<h4 id=\"1-搭建-Maven-私有仓库\"><a href=\"#1-搭建-Maven-私有仓库\" class=\"headerlink\" title=\"1. 搭建 Maven 私有仓库\"></a>1. 搭建 Maven 私有仓库</h4><p>首先，需要在内网环境中搭建一个 Maven 仓库，常用的私有 Maven 仓库工具有：</p>\n<ul>\n<li>Nexus Repository：Sonatype Nexus 是最流行的私有 Maven 仓库管理工具。</li>\n<li>Artifactory：JFrog Artifactory 是另一种流行的构建管理工具，提供了私有仓库的支持。</li>\n<li>Apache Archiva：Apache Archiva 也是一个支持 Maven 的仓库管理工具。</li>\n</ul>\n<p>以下是搭建 Nexus Repository 的简单步骤：<br><span id=\"more\"></span></p>\n<p>1.1 安装 Nexus Repository</p>\n<ul>\n<li><p>下载 Nexus： 访问 Nexus Repository 下载页面 下载 Nexus OSS 版本。</p>\n</li>\n<li><p>解压并启动： 解压下载的压缩包并启动 Nexus。</p>\n</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">cd /opt/nexus/bin</span><br><span class=\"line\">./nexus start</span><br></pre></td></tr></table></figure>\n<ul>\n<li>访问 Nexus UI： 打开浏览器，访问 Nexus 的默认地址：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://localhost:8081</span><br></pre></td></tr></table></figure>\n<p>默认用户名为 admin，密码为 admin123，可以在首次登录后修改密码。</p>\n<p>1.2 配置 Maven 仓库</p>\n<p>在 Nexus UI 中，你可以创建一个新的 Maven 仓库。创建仓库后，你可以上传公司的内部依赖、插件和构建工件。</p>\n<h4 id=\"2-配置-Maven-使用内网仓库\"><a href=\"#2-配置-Maven-使用内网仓库\" class=\"headerlink\" title=\"2. 配置 Maven 使用内网仓库\"></a>2. 配置 Maven 使用内网仓库</h4><p>配置 Maven 使用内网仓库需要修改 settings.xml 文件。</p>\n<p>2.1 修改 settings.xml</p>\n<p>在 Maven 的 settings.xml 文件中，配置私有仓库的地址和认证信息。settings.xml 文件通常位于 ~/.m2/ 目录下（用户级别配置）或者 ${MAVEN_HOME}/conf/ 目录下（全局配置）。</p>\n<p>以下是配置内网 Maven 仓库的示例：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;</span><br><span class=\"line\">          xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class=\"line\">          xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;mirrors&gt;</span><br><span class=\"line\">        &lt;!-- 配置私有仓库镜像 --&gt;</span><br><span class=\"line\">        &lt;mirror&gt;</span><br><span class=\"line\">            &lt;id&gt;nexus&lt;/id&gt;</span><br><span class=\"line\">            &lt;mirrorOf&gt;external:http://central&lt;/mirrorOf&gt;</span><br><span class=\"line\">            &lt;url&gt;http://your-nexus-server:8081/repository/maven-public/&lt;/url&gt;</span><br><span class=\"line\">            &lt;blocked&gt;false&lt;/blocked&gt;</span><br><span class=\"line\">        &lt;/mirror&gt;</span><br><span class=\"line\">    &lt;/mirrors&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;repositories&gt;</span><br><span class=\"line\">        &lt;repository&gt;</span><br><span class=\"line\">            &lt;id&gt;internal-repo&lt;/id&gt;</span><br><span class=\"line\">            &lt;url&gt;http://your-nexus-server:8081/repository/maven-releases/&lt;/url&gt;</span><br><span class=\"line\">            &lt;snapshots&gt;</span><br><span class=\"line\">                &lt;enabled&gt;false&lt;/enabled&gt;</span><br><span class=\"line\">            &lt;/snapshots&gt;</span><br><span class=\"line\">        &lt;/repository&gt;</span><br><span class=\"line\">    &lt;/repositories&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;pluginRepositories&gt;</span><br><span class=\"line\">        &lt;pluginRepository&gt;</span><br><span class=\"line\">            &lt;id&gt;internal-plugins&lt;/id&gt;</span><br><span class=\"line\">            &lt;url&gt;http://your-nexus-server:8081/repository/maven-plugins/&lt;/url&gt;</span><br><span class=\"line\">        &lt;/pluginRepository&gt;</span><br><span class=\"line\">    &lt;/pluginRepositories&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;servers&gt;</span><br><span class=\"line\">        &lt;!-- 配置 Maven 仓库认证 --&gt;</span><br><span class=\"line\">        &lt;server&gt;</span><br><span class=\"line\">            &lt;id&gt;nexus&lt;/id&gt;</span><br><span class=\"line\">            &lt;username&gt;your-nexus-username&lt;/username&gt;</span><br><span class=\"line\">            &lt;password&gt;your-nexus-password&lt;/password&gt;</span><br><span class=\"line\">        &lt;/server&gt;</span><br><span class=\"line\">    &lt;/servers&gt;</span><br><span class=\"line\">&lt;/settings&gt;</span><br></pre></td></tr></table></figure>\n<p>2.2 配置镜像和仓库</p>\n<ul>\n<li><p>镜像（Mirror）：在 <mirrors> 标签中配置私有仓库的 URL，将 Maven 的中央仓库或其他公共仓库的请求代理到私有仓库中。通过 mirrorOf 配置来选择代理哪些仓库（external:<a href=\"http://central\">http://central</a> 表示代理所有外部仓库）。</p>\n</li>\n<li><p>仓库（Repository）：在 <repositories> 和 <pluginRepositories> 标签中配置你的内网仓库的 URL。</p>\n</li>\n<li><p>认证（Server Authentication）：在 <servers> 标签中配置内网仓库的认证信息（如果仓库需要认证）。</p>\n</li>\n</ul>\n<h4 id=\"3-配置项目使用内网仓库\"><a href=\"#3-配置项目使用内网仓库\" class=\"headerlink\" title=\"3. 配置项目使用内网仓库\"></a>3. 配置项目使用内网仓库</h4><p>在项目的 pom.xml 文件中，通常不需要额外配置仓库，因为 Maven 会使用 settings.xml 中配置的内网仓库。但是如果需要强制指定某个仓库，可以在 pom.xml 中配置 <repositories> 标签：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;repositories&gt;</span><br><span class=\"line\">    &lt;repository&gt;</span><br><span class=\"line\">        &lt;id&gt;nexus-repo&lt;/id&gt;</span><br><span class=\"line\">        &lt;url&gt;http://your-nexus-server:8081/repository/maven-releases/&lt;/url&gt;</span><br><span class=\"line\">    &lt;/repository&gt;</span><br><span class=\"line\">&lt;/repositories&gt;</span><br></pre></td></tr></table></figure>\n<h4 id=\"4-上传和下载依赖\"><a href=\"#4-上传和下载依赖\" class=\"headerlink\" title=\"4. 上传和下载依赖\"></a>4. 上传和下载依赖</h4><p>4.1 上传依赖到内网仓库<br>你可以通过 Maven 命令将本地构建的 JAR 文件上传到内网仓库。例如，将某个 JAR 上传到 Nexus：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn deploy:deploy-file \\</span><br><span class=\"line\">    -DgroupId=com.example \\</span><br><span class=\"line\">    -DartifactId=my-artifact \\</span><br><span class=\"line\">    -Dversion=1.0.0 \\</span><br><span class=\"line\">    -Dpackaging=jar \\</span><br><span class=\"line\">    -Dfile=path/to/your-artifact.jar \\</span><br><span class=\"line\">    -DrepositoryId=nexus \\</span><br><span class=\"line\">    -Durl=http://your-nexus-server:8081/repository/maven-releases/</span><br></pre></td></tr></table></figure>\n<p>4.2 从内网仓库下载依赖</p>\n<p>配置好内网仓库后，Maven 会自动从内网仓库下载依赖。如果仓库中没有该依赖，Maven 会尝试从其他配置的仓库下载。</p>\n<h4 id=\"5-使用私有仓库中的依赖\"><a href=\"#5-使用私有仓库中的依赖\" class=\"headerlink\" title=\"5. 使用私有仓库中的依赖\"></a>5. 使用私有仓库中的依赖</h4><p>一旦仓库配置好，Maven 将会从配置的内网仓库下载依赖。你可以在项目的 pom.xml 中正常引用依赖，Maven 会自动从私有仓库中拉取。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;dependencies&gt;</span><br><span class=\"line\">    &lt;dependency&gt;</span><br><span class=\"line\">        &lt;groupId&gt;com.example&lt;/groupId&gt;</span><br><span class=\"line\">        &lt;artifactId&gt;my-artifact&lt;/artifactId&gt;</span><br><span class=\"line\">        &lt;version&gt;1.0.0&lt;/version&gt;</span><br><span class=\"line\">    &lt;/dependency&gt;</span><br><span class=\"line\">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure>\n<h4 id=\"6-配置镜像以提高构建速度（可选）\"><a href=\"#6-配置镜像以提高构建速度（可选）\" class=\"headerlink\" title=\"6. 配置镜像以提高构建速度（可选）\"></a>6. 配置镜像以提高构建速度（可选）</h4><p>为了提高构建速度，你可以配置 settings.xml 来使用私有仓库作为 Maven 的默认镜像，确保所有的构建依赖都从私有仓库中拉取，避免每次访问外部仓库，降低构建时间。</p>\n",
            "tags": [
                "maven搭建库",
                "maven",
                "maven内网库"
            ]
        },
        {
            "id": "https://erik.xyz/2024/12/12/intranet-spring-boot-install/",
            "url": "https://erik.xyz/2024/12/12/intranet-spring-boot-install/",
            "title": "spring boot内网部署",
            "date_published": "2024-12-12T10:22:18.000Z",
            "content_html": "<h4 id=\"1-准备环境\"><a href=\"#1-准备环境\" class=\"headerlink\" title=\"1. 准备环境\"></a>1. 准备环境</h4><p>确保内网中的服务器或机器具备运行 Spring Boot 应用的基本环境：</p>\n<ul>\n<li>JDK：确保服务器安装了合适版本的 JDK（通常建议使用 Java 8 及以上版本）。</li>\n<li>Maven/Gradle：根据项目使用的构建工具安装 Maven 或 Gradle。</li>\n<li>数据库：如果应用需要连接数据库，确保数据库在内网中可访问，且连接配置正确。</li>\n</ul>\n<span id=\"more\"></span>\n<h4 id=\"2-编译-Spring-Boot-应用\"><a href=\"#2-编译-Spring-Boot-应用\" class=\"headerlink\" title=\"2. 编译 Spring Boot 应用\"></a>2. 编译 Spring Boot 应用</h4><p>首先，你需要编译你的 Spring Boot 应用，生成可执行的 JAR 文件。可以通过以下命令在项目目录下执行：</p>\n<ul>\n<li>Maven 构建命令：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn clean package</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<ul>\n<li>Gradle 构建命令：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./gradlew build</span><br></pre></td></tr></table></figure>\n<p>这会在 target/ 或 build/libs/ 目录下生成一个可执行的 JAR 文件，通常名为 your-application-name.jar。</p>\n<h4 id=\"3-传输-JAR-到内网服务器\"><a href=\"#3-传输-JAR-到内网服务器\" class=\"headerlink\" title=\"3. 传输 JAR 到内网服务器\"></a>3. 传输 JAR 到内网服务器</h4><p>将生成的 JAR 文件上传到内网的目标服务器。可以使用各种文件传输工具，比如：</p>\n<ul>\n<li>SCP（如果服务器支持 SSH）：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp your-application-name.jar user@server-ip:/path/to/deploy/</span><br></pre></td></tr></table></figure>\n<ul>\n<li>FTP 或 SFTP（如果有配置 FTP 服务）。</li>\n</ul>\n<h4 id=\"4-配置-Spring-Boot-应用\"><a href=\"#4-配置-Spring-Boot-应用\" class=\"headerlink\" title=\"4. 配置 Spring Boot 应用\"></a>4. 配置 Spring Boot 应用</h4><p>在内网部署时，你可能需要根据环境修改配置文件，比如 application.properties 或 application.yml。常见的配置项包括：</p>\n<ul>\n<li>数据库连接信息（spring.datasource.url、spring.datasource.username 等）。</li>\n<li>日志配置。</li>\n<li>服务端口（server.port）。</li>\n<li>安全设置（如禁用外部访问，或者设置访问白名单等）。</li>\n</ul>\n<p>例如，修改 application.properties 中的数据库配置：<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spring.datasource.url=jdbc:mysql://localhost:3306/your_db</span><br><span class=\"line\">spring.datasource.username=db_user</span><br><span class=\"line\">spring.datasource.password=db_password</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"5-启动-Spring-Boot-应用\"><a href=\"#5-启动-Spring-Boot-应用\" class=\"headerlink\" title=\"5. 启动 Spring Boot 应用\"></a>5. 启动 Spring Boot 应用</h4><p>在内网服务器上，使用以下命令启动 Spring Boot 应用：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">java -jar your-application-name.jar</span><br></pre></td></tr></table></figure>\n<p>如果你希望应用在后台运行，可以使用 nohup 或者类似的工具：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nohup java -jar your-application-name.jar &gt; output.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n<p>这会将输出重定向到 output.log 文件，并让应用在后台运行。</p>\n<h4 id=\"6-配置防火墙和网络\"><a href=\"#6-配置防火墙和网络\" class=\"headerlink\" title=\"6. 配置防火墙和网络\"></a>6. 配置防火墙和网络</h4><ul>\n<li>确保服务器的防火墙允许访问应用所绑定的端口（默认是 8080）。如果使用其他端口，可以在防火墙中配置允许访问该端口。</li>\n<li>如果 Spring Boot 应用需要通过内网的特定 IP 地址或域名访问，确保 DNS 或 hosts 配置正确。</li>\n</ul>\n<h4 id=\"7-监控和日志\"><a href=\"#7-监控和日志\" class=\"headerlink\" title=\"7. 监控和日志\"></a>7. 监控和日志</h4><ul>\n<li>日志：Spring Boot 应用会将日志输出到控制台，你可以将日志配置为输出到文件中进行持久化存储。常见做法是在 application.properties 或 application.yml 中设置日志路径：</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">logging.file.name=/path/to/logs/application.log</span><br></pre></td></tr></table></figure>\n<ul>\n<li>监控：可以使用 Spring Boot 的 Actuator 或其他监控工具（如 Prometheus 和 Grafana）来监控应用的运行状态。</li>\n</ul>\n<h4 id=\"8-设置开机启动（可选）\"><a href=\"#8-设置开机启动（可选）\" class=\"headerlink\" title=\"8. 设置开机启动（可选）\"></a>8. 设置开机启动（可选）</h4><p>如果希望应用在服务器重启时自动启动，可以使用 systemd（Linux 系统）或配置为 Windows 服务。</p>\n<p>Linux 系统 (Systemd)</p>\n<p>创建一个 systemd 服务文件，如 /etc/systemd/system/yourapp.service：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=Spring Boot Application</span><br><span class=\"line\">After=network.target</span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\">User=your_user</span><br><span class=\"line\">ExecStart=/usr/bin/java -jar /path/to/your-application-name.jar</span><br><span class=\"line\">SuccessExitStatus=143</span><br><span class=\"line\">Restart=always</span><br><span class=\"line\"></span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>\n<p>然后启用并启动服务：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl enable yourapp</span><br><span class=\"line\">sudo systemctl start yourapp</span><br></pre></td></tr></table></figure>",
            "tags": [
                "springboot",
                "springboot内网部署"
            ]
        },
        {
            "id": "https://erik.xyz/2024/11/15/deepin-not-login/",
            "url": "https://erik.xyz/2024/11/15/deepin-not-login/",
            "title": "deepin无法登录报错emergency mode",
            "date_published": "2024-11-15T02:56:00.000Z",
            "content_html": "<p>由于系统重启后，新安装的微信一直弹出框，卡在那难受。立马强制重启，开机后就一直显示You are in emergency mode……一堆东西，意思是说让进入root用户，查看报错并修复。</p>\n<p>  有点头大了。</p>\n<p>  系统命令可以显示，图形界面不显示。<br>  <span id=\"more\"></span><br>  果断拿出安装系统的u盘，使用u盘启动进入安装界面，按ctrl+alt+f4进入u盘命令界面。输入startx进入u盘图形界面。这下可以看到电脑的挂着盘。根据挂着的盘一个个找根目录盘。找到后使用u盘系统的命令窗口:<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo vi /etc/fstab</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></p>\n<p> 注释掉home目录，重启系统。</p>\n<p> 重启后会显示个登录图形界面。这个是假的，没用。按ctrl+alt+f2进入命令界面。<br> 使用账号密码登录命令界面。</p>\n<p> 打开/etc/fstab文件取消home注释。（这里要看一下home挂载路径，比如我的/dev/sda6）</p>\n<p> 使用以下命令修复：<br> <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo e2fsck /dev/sda6</span><br></pre></td></tr></table></figure></p>\n<p> 你会看到一堆修复，一个个确认后，等待修复完成就重启系统。</p>\n",
            "tags": [
                "deepin",
                "emergency",
                "emergency mode",
                "deepin黑屏"
            ]
        },
        {
            "id": "https://erik.xyz/2021/12/29/about-centos-load-balacnig/",
            "url": "https://erik.xyz/2021/12/29/about-centos-load-balacnig/",
            "title": "负载均衡-初谈",
            "date_published": "2021-12-29T04:41:00.000Z",
            "content_html": "<p>当一个项目沉淀一段时间后，随着用户量的提升，用户群体庞大起来。这时候就会出现过多的用户访问导致服务器（单机）供应不足。那么，负载均衡就出现了。<br><span id=\"more\"></span></p>\n<ul>\n<li>假设我有60w的用户量，那么负载如下图：</li>\n</ul>\n<pre class=\"mermaid\">graph TD;\n    A[\"nginx入口服务器\"]-->B1[\"nginx负载1(20w)\"];\n    A-->B2[\"nginx负载2(20w)\"];\n    A-->B3[\"nginx负载3(20w)\"];</pre>\n\n<p>此时分配负载是正确的。但是，某个时间段突然用户量飙升，超过了60w的访问量。这个时候增加服务器就来不及。这就又回到初始问题，服务器宕机。因此，要对负载服务器做限流，超过访问量就禁止访问。</p>\n<ul>\n<li>假设我有160w的用户量，那么负载如下图：</li>\n</ul>\n<pre class=\"mermaid\">graph TD;\n    A[\"nginx主服务器\"]-->A1;\n    A-->A2;\n    A-->A3;\n    A1[\"nginx入口服务器（55w）\"]-->B11[\"nginx负载1(20w)\"];\n    A1-->B12[\"nginx负载2(20w)\"];\n    A1-->B13[\"nginx负载3(20w)\"];\n    A2[\"nginx入口服务器（55w）\"]-->B21[\"nginx负载1(20w)\"];\n    A2-->B22[\"nginx负载2(20w)\"];\n    A2-->B23[\"nginx负载3(20w)\"];\n    A3[\"nginx入口服务器（55w）\"]-->B31[\"nginx负载1(20w)\"];\n    A3-->B32[\"nginx负载2(20w)\"];\n    A3-->B33[\"nginx负载3(20w)\"];</pre>\n\n<ul>\n<li>假设我有500w用户，要做个抽奖活动。</li>\n</ul>\n<p>这个就需要考虑一下，假如活动真有500w或者500w以上，超过服务器负载了。那么就会导致一部分负载服务器拦截，而被拦截的用户转而调到另外的负载服务器。很显然，这样持续下去会导致整个服务全部崩溃。这个时候就要考虑把抽奖活动单独部署出来，而活动服务器只是短期的伸缩服务器。那么，负载如图：</p>\n<pre class=\"mermaid\">graph TD;\n    A[\"nginx主服务器\"]-->A1;\n    A-->A2;\n    A-->A3;\n    A[\"nginx主服务器\"]-->H1[\"活动服务器(30w)\"];\n    A-->H2[\"活动服务器(30w)\"];\n    A-->H3[\"活动服务器(30w)\"];\n    A-->H4[\"活动服务器(30w)\"];\n    A-->H5[\"活动服务器(30w)\"];\n    A-->H6[\"活动服务器(30w)\"];\n    A-->H7[\"活动服务器(30w)\"];\n    A1[\"nginx入口服务器（55w）\"]-->B11[\"nginx负载1(20w)\"];\n    A1-->B12[\"nginx负载2(20w)\"];\n    A1-->B13[\"nginx负载3(20w)\"];\n    A2[\"nginx入口服务器（55w）\"]-->B21[\"nginx负载1(20w)\"];\n    A2-->B22[\"nginx负载2(20w)\"];\n    A2-->B23[\"nginx负载3(20w)\"];\n    A3[\"nginx入口服务器（55w）\"]-->B31[\"nginx负载1(20w)\"];\n    A3-->B32[\"nginx负载2(20w)\"];\n    A3-->B33[\"nginx负载3(20w)\"];</pre>\n\n<ul>\n<li><p>假设不因一个异常而导致其他服务不可用</p>\n<p> 那就考虑服务分化部署，即微服务</p>\n</li>\n</ul>\n<pre class=\"mermaid\">graph TD;\n    A(入口)-->B1(用户层);\n    A-->B2(订单);\n    A-->B3(活动);\n    A-->B4(商品);\n    A-->B5(物流);\n    A-->B6(日志);\n    A-->B7(客服);\n    A-->B8(支付);\n    B1-->C1(用户信息);\n    B1-->C2(用户任务);\n    B2-->D1(订单生成);\n    B2-->D2(订单支付);\n    B2-->D3(购物车);\n    B3-->E1(秒杀);\n    B3-->E2(团购);\n    B3-->E3(竞拍);\n    B4-->F1(商品搜索);\n    B4-->F2(商品详情);\n    B4-->F3(商品推荐);\n    B5-->G1(信息更新);\n    B5-->G2(服务商对接);\n    B6-->H1(请求日志);\n    B6-->H2(交易日志);\n    B6-->H3(浏览日志);\n    B7-->I1(纠纷处理);\n    B7-->I2(订单处理);\n    B7-->I3(投诉处理);\n    B8-->J1(支付宝);\n    B8-->J2(微信);\n    B8-->J3(银联);\n    B8-->J4(paypal);\n    B8-->J5(第三方支付);</pre>",
            "tags": [
                "负载均衡"
            ]
        },
        {
            "id": "https://erik.xyz/2021/11/15/reids-info-lock/",
            "url": "https://erik.xyz/2021/11/15/reids-info-lock/",
            "title": "细说Redis分布式锁",
            "date_published": "2021-11-15T13:43:00.000Z",
            "content_html": "<p>谈起Redis锁，下面三个，算是出现最多的高频词汇：</p>\n<ul>\n<li>Setnx</li>\n<li>Redlock</li>\n<li>Redisson</li>\n</ul>\n<p>Setnx</p>\n<p>其实目前通常所说的Setnx命令，并非单指Redis的setnx key value这条命令。</p>\n<span id=\"more\"></span>\n<p>一般代指Redis中对set命令加上nx参数进行使用，set这个命令，目前已经支持这么多参数可选：</p>\n<pre><code>SET key value [EX seconds|PX milliseconds] [NX|XX] [KEEPTTL]\n</code></pre><p>当然了，就不在文章中默写API了，基础参数还有不清晰的，可以蹦到官网：<a href=\"https://redis.io/commands/set\">https://redis.io/commands/set</a></p>\n<p><img src=\"/2021/11/20211115214422.jpg\" alt=\"\"></p>\n<p>上图是笔者画的Setnx大致原理，主要依托了它的key不存在才能set成功的特性，进程A拿到锁，在没有删除锁的Key时，进程B自然获取锁就失败了。</p>\n<p>那么为什么要使用PX 30000去设置一个超时时间？</p>\n<p>是怕进程A不讲道理啊，锁没等释放呢，万一崩了，直接原地把锁带走了，导致系统中谁也拿不到锁。</p>\n<p>就算这样，还是不能保证万无一失。</p>\n<p>如果进程A又不讲道理，操作锁内资源超过笔者设置的超时时间，那么就会导致其他进程拿到锁，等进程A回来了，回手就是把其他进程的锁删了，如图：</p>\n<p><img src=\"/2021/11/20211115214716.jpg\" alt=\"\"></p>\n<p>还是刚才那张图，将T5时刻改成了锁超时，被Redis释放。</p>\n<p>进程B在T6开开心心拿到锁不到一会，进程A操作完成，回手一个del，就把锁释放了。</p>\n<p>当进程B操作完成，去释放锁的时候（图中T8时刻）：</p>\n<p>找不到锁其实还算好的，万一T7时刻有个进程C过来加锁成功，那么进程B就把进程C的锁释放了。</p>\n<p>以此类推，进程C可能释放进程D的锁，进程D……（禁止套娃），具体什么后果就不得而知了。</p>\n<p>所以在用Setnx的时候，key虽然是主要作用，但是value也不能闲着，可以设置一个唯一的客户端ID，或者用UUID这种随机数。</p>\n<p>当解锁的时候，先获取value判断是否是当前进程加的锁，再去删除。伪代码：</p>\n<pre><code>String uuid = xxxx;\n// 伪代码，具体实现看项目中用的连接工具\n// 有的提供的方法名为set，有的叫setIfAbsent\nset Test uuid NX PX 3000\ntry&#123;\n// biz handle....\n&#125; finally &#123;\n    // unlock\n    if(uuid.equals(redisTool.get(&#39;Test&#39;))&#123;\n        redisTool.del(&#39;Test&#39;);\n    &#125;\n&#125;\n</code></pre><p>这回看起来是不是稳了。</p>\n<p>相反，这回的问题更明显了，在finally代码块中，get和del并非原子操作，还是有进程安全问题。</p>\n<p>为什么有问题还说这么多呢？</p>\n<p>第一，搞清劣势所在，才能更好的完善。</p>\n<p>第二点，其实上文中最后这段代码，还是有很多公司在用的。</p>\n<p>大小项目悖论：大公司实现规范，但是小司小项目虽然存在不严谨，可并发倒也不高，出问题的概率和大公司一样低。——鲁迅</p>\n<p>那么删除锁的正确姿势之一，就是可以使用Lua脚本，通过Redis的eval/evalsha命令来运行：</p>\n<pre><code>-- Lua删除锁：\n-- KEYS和ARGV分别是以集合方式传入的参数，对应上文的Test和uuid。\n-- 如果对应的value等于传入的uuid。\nif redis.call(&#39;get&#39;, KEYS[1]) == ARGV[1] \n    then \n -- 执行删除操作\n        return redis.call(&#39;del&#39;, KEYS[1]) \n    else \n -- 不成功，返回0\n        return 0 \nend\n</code></pre><p>通过Lua脚本能保证原子性的原因说的通俗一点：</p>\n<p>就算你在Lua里写出花，执行也是一个命令（eval/evalsha）去执行的，一条命令没执行完，其他客户端是看不到的。</p>\n<p>那么既然这么麻烦，有没有比较好的工具呢？就要说到Redisson了。</p>\n<p>介绍Redisson之前，笔者简单解释一下为什么现在的Setnx默认是指set命令带上nx参数，而不是直接说是Setnx这个命令。</p>\n<p>因为Redis版本在2.6.12之前，set是不支持nx参数的，如果想要完成一个锁，那么需要两条命令：</p>\n<pre><code>1. setnx Test uuid\n2. expire Test 30\n</code></pre><p>即放入Key和设置有效期，是分开的两步，理论上会出现1刚执行完，程序挂掉，无法保证原子性。</p>\n<p>但是早在2013年，也就是7年前，Redis就发布了2.6.12版本，并且官网（set命令页[1]），也早早就说明了“SETNX，SETEX，PSETEX可能在未来的版本中，会弃用并永久删除”。</p>\n<p>笔者曾阅读过一位大佬的文章，其中就有一句指导入门者的面试小套路，具体文字忘记了，大概意思如下：</p>\n<pre><code>说到Redis锁的时候，可以先从Setnx讲起，最后慢慢引出set命令的可以加参数，可以体现出自己的知识面。\n</code></pre><p>如果有缘你也阅读过这篇文章，并且学到了这个套路，作为本文的笔者我要加一句提醒：</p>\n<p>请注意你的工作年限！首先回答官网表明即将废弃的命令，再引出set命令七年前的“新特性”，如果是刚毕业不久的人这么说，面试官会以为自己穿越了。</p>\n<p>你套路面试官，面试官也会套路你。——vt・沃兹基硕德</p>\n<p>Redisson</p>\n<p>Redisson是Java的Redis客户端之一，提供了一些API方便操作Redis。</p>\n<p>但是Redisson这个客户端可有点厉害，笔者在官网截了仅仅是一部分的图：</p>\n<p><img src=\"/2021/11/20211115214952.jpg\" alt=\"\"></p>\n<p>这个特性列表可以说是太多了，是不是还看到了一些JUC包下面的类名，Redisson帮我们搞了分布式的版本，比如AtomicLong，直接用RedissonAtomicLong就行了，连类名都不用去新记，很人性化了。</p>\n<p>锁只是它的冰山一角，并且从它的wiki[2]页面看到，对主从，哨兵，集群等模式都支持，当然了，单节点模式肯定是支持的。</p>\n<p>本文还是以锁为主，其他的不过多介绍。</p>\n<p>Redisson普通的锁实现源码主要是RedissonLock这个类，还没有看过它源码的盆友，不妨去瞧一瞧。</p>\n<p>源码中加锁/释放锁操作都是用Lua脚本完成的，封装的非常完善，开箱即用。</p>\n<p>这里有个小细节，加锁使用Setnx就能实现，也采用Lua脚本是不是多此一举？笔者也非常严谨的思考了一下：这么厉害的东西哪能写废代码？</p>\n<p>其实笔者仔细看了一下，加锁解锁的Lua脚本考虑的非常全面，其中就包括锁的重入性，这点可以说是考虑非常周全，我也随手写了代码测试一下：</p>\n<p><img src=\"/2021/11/20211115215028.jpg\" alt=\"\"></p>\n<p>的确用起来像JDK的ReentrantLock一样丝滑，那么Redisson实现的已经这么完善，RedLock又是什么？</p>\n<p>RedLock</p>\n<p>RedLock的中文是直译过来的，就叫红锁。</p>\n<p>红锁并非是一个工具，而是Redis官方提出的一种分布式锁的算法。</p>\n<p>就在刚刚介绍完的Redisson中，就实现了redLock版本的锁。也就是说除了getLock方法，还有getRedLock方法。</p>\n<p>笔者大概画了一下对红锁的理解：</p>\n<p><img src=\"/2021/11/20211115215116.jpg\" alt=\"\"></p>\n<p>如果你不熟悉Redis高可用部署，那么没关系。RedLock算法虽然是需要多个实例，但是这些实例都是独自部署的，没有主从关系。</p>\n<p>RedLock作者指出，之所以要用独立的，是避免了redis异步复制造成的锁丢失，比如：主节点没来的及把刚刚set进来这条数据给从节点，就挂了。</p>\n<p>有些人是不是觉得大佬们都是杠精啊，天天就想着极端情况。其实高可用嘛，拼的就是99.999……%中小数点后面的位数。</p>\n<p>回到上面那张简陋的图片，红锁算法认为，只要(N/2) + 1个节点加锁成功，那么就认为获取了锁， 解锁时将所有实例解锁。流程为：</p>\n<p>  1.顺序向五个节点请求加锁</p>\n<p>  2.根据一定的超时时间来推断是不是跳过该节点</p>\n<p>  3.三个节点加锁成功并且花费时间小于锁的有效期</p>\n<p>  4.认定加锁成功</p>\n<p>也就是说，假设锁30秒过期，三个节点加锁花了31秒，自然是加锁失败了。</p>\n<p>这只是举个例子，实际上并不应该等每个节点那么长时间，就像官网所说的那样，假设有效期是10秒，那么单个Redis实例操作超时时间，应该在5到50毫秒（注意时间单位）。</p>\n<p>还是假设我们设置有效期是30秒，图中超时了两个Redis节点。那么加锁成功的节点总共花费了3秒，所以锁的实际有效期是小于27秒的。</p>\n<p>即扣除加锁成功三个实例的3秒，还要扣除等待超时Redis实例的总共时间。</p>\n<p>看到这，你有可能对这个算法有一些疑问，那么你不是一个人。</p>\n<p>回头看看Redis官网关于红锁的描述[3]。</p>\n<p>就在这篇描述页面的最下面，你能看到著名的关于红锁的神仙打架事件。</p>\n<p>即Martin Kleppmann和Antirez的RedLock辩论。一个是很有资历的分布式架构师，一个是Redis之父。</p>\n<p>官方挂人，最为致命。</p>\n<p>开个玩笑，要是质疑能被官方挂到官网，说明肯定是有价值的。</p>\n<p>所以说如果项目里要使用红锁，除了红锁的介绍，不妨要多看两篇文章，即：</p>\n<ul>\n<li><p>Martin Kleppmann的质疑贴：<a href=\"http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\">http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</a></p>\n</li>\n<li><p>Antirez的反击贴：<a href=\"http://antirez.com/news/101\">http://antirez.com/news/101</a></p>\n</li>\n</ul>\n<p>总结</p>\n<p>看了这么多，是不是发现如何实现，都不能保证100%的稳定。</p>\n<p>程序就是这样，没有绝对的稳定，所以做好人工补偿环节也是重要的一环，毕竟：技术不够，人工来凑～</p>\n<p>相关链接：</p>\n<p><a href=\"https://redis.io/commands/set\">https://redis.io/commands/set</a></p>\n<p><a href=\"https://github.com/redisson/redisson/wiki/Table-of-Content\">https://github.com/redisson/redisson/wiki/Table-of-Content</a></p>\n<p><a href=\"https://redis.io/topics/distlock\">https://redis.io/topics/distlock</a></p>\n<p>原文链接：<a href=\"https://juejin.cn/post/6844904082860146695\">https://juejin.cn/post/6844904082860146695</a></p>\n",
            "tags": [
                "redis",
                "redis锁",
                "redis分布式锁"
            ]
        },
        {
            "id": "https://erik.xyz/2021/04/07/redis-about-all/",
            "url": "https://erik.xyz/2021/04/07/redis-about-all/",
            "title": "关于redis的总结",
            "date_published": "2021-04-07T08:09:00.000Z",
            "content_html": "<h2 id=\"基础数据结构\"><a href=\"#基础数据结构\" class=\"headerlink\" title=\"基础数据结构\"></a>基础数据结构</h2><ul>\n<li><h3 id=\"字符串（string）\"><a href=\"#字符串（string）\" class=\"headerlink\" title=\"字符串（string）\"></a>字符串（string）</h3><ul>\n<li>字符串、整数、浮点数</li>\n<li>对整个字符串或者字符串的其中一部分执行操作，对整数和浮点数执行自增或自减操作</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"哈希列表（hash）\"><a href=\"#哈希列表（hash）\" class=\"headerlink\" title=\"哈希列表（hash）\"></a>哈希列表（hash）</h3><ul>\n<li>包含键值对的无序散列表</li>\n<li>添加、获取、移除单个键值对，获取所有键值对，检查某个键是否存在</li>\n</ul>\n</li>\n</ul>\n<span id=\"more\"></span>\n<ul>\n<li><h3 id=\"列表（list）\"><a href=\"#列表（list）\" class=\"headerlink\" title=\"列表（list）\"></a>列表（list）</h3><ul>\n<li>链表</li>\n<li>从两端压入或者弹出元素，读取单个或者多个元素进行修剪，只保留一个范围内的元素</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"集合（set）\"><a href=\"#集合（set）\" class=\"headerlink\" title=\"集合（set）\"></a>集合（set）</h3><ul>\n<li>无序集合</li>\n<li>添加、获取、移除单个元素，检查一个元素是否存在与集合中，计算交集、并集、差集，从集合里面随机获取元素</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"有序集合（sort-set）\"><a href=\"#有序集合（sort-set）\" class=\"headerlink\" title=\"有序集合（sort set）\"></a>有序集合（sort set）</h3><ul>\n<li>有序集合</li>\n<li>添加、获取、删除元素，根据分值范围或者成员来获取元素，计算一个键的排名</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"复杂的数据结构\"><a href=\"#复杂的数据结构\" class=\"headerlink\" title=\"复杂的数据结构\"></a>复杂的数据结构</h2><ul>\n<li><h3 id=\"位图（bitmaps）\"><a href=\"#位图（bitmaps）\" class=\"headerlink\" title=\"位图（bitmaps）\"></a>位图（bitmaps）</h3><ul>\n<li>Bitmap 在 Redis 中不是一种实际的数据类型，而是一种将 String 作为 Bitmap 使用的方法。可以理解为将 String 转换为 bit 数组。使用 Bitmap 来存储 true/false 类型的简单数据极为节省空间。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"算法数据结构（hyperloglogs）\"><a href=\"#算法数据结构（hyperloglogs）\" class=\"headerlink\" title=\"算法数据结构（hyperloglogs）\"></a>算法数据结构（hyperloglogs）</h3><ul>\n<li>HyperLogLogs 是一种主要用于数量统计的数据结构，它和 Set 类似，维护一个不可重复的 String 集合，但是 HyperLogLogs 并不维护具体的 member 内容，只维护 member 的个数。也就是说，HyperLogLogs 只能用于计算一个集合中不重复的元素数量，所以它比 Set 要节省很多内存空间</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"地理空间（geo）\"><a href=\"#地理空间（geo）\" class=\"headerlink\" title=\"地理空间（geo）\"></a>地理空间（geo）</h3><ul>\n<li>地理空间索引半径查询</li>\n</ul>\n</li>\n<li><h3 id=\"布隆过滤（bloomfilter）\"><a href=\"#布隆过滤（bloomfilter）\" class=\"headerlink\" title=\"布隆过滤（bloomfilter）\"></a>布隆过滤（bloomfilter）</h3></li>\n</ul>\n<h2 id=\"非分布式场景下Redis应用的备份与容灾\"><a href=\"#非分布式场景下Redis应用的备份与容灾\" class=\"headerlink\" title=\"非分布式场景下Redis应用的备份与容灾\"></a>非分布式场景下Redis应用的备份与容灾</h2><ul>\n<li><h3 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h3><ul>\n<li>一个Master节点，两个Slave节点。客户端写数据的时候是写Master节点，读的时候，是读取两个Slave，这样实现读的扩展，减轻了Master节点读负载。</li>\n</ul>\n</li>\n<li><h3 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h3><ul>\n<li>Master和Slave1使用keepalived进行VIP转移。Client连接Master的时候是通过VIP进行连接的。避免了方案一IP更改的情况。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"Redis-Sentinel架构\"><a href=\"#Redis-Sentinel架构\" class=\"headerlink\" title=\"Redis Sentinel架构\"></a>Redis Sentinel架构</h3><ul>\n<li>Sentinel集群对自身和Redis主从复制进行监控。当发现Master节点出现故障时，会经过如下步骤：<ul>\n<li>Sentinel之间进行选举，选举出一个leader，由选举出的leader进行failover</li>\n<li>Sentinel leader选取slave节点中的一个slave作为新的Master节点。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"客户端工具\"><a href=\"#客户端工具\" class=\"headerlink\" title=\"客户端工具\"></a>客户端工具</h2><ul>\n<li><h3 id=\"使用socket连接redis服务器\"><a href=\"#使用socket连接redis服务器\" class=\"headerlink\" title=\"使用socket连接redis服务器\"></a>使用socket连接redis服务器</h3><pre><code> redis-cli -s /tmp/redis.sock\n</code></pre></li>\n</ul>\n<ul>\n<li><h3 id=\"不使用socket连接redis服务器\"><a href=\"#不使用socket连接redis服务器\" class=\"headerlink\" title=\"不使用socket连接redis服务器\"></a>不使用socket连接redis服务器</h3><pre><code>redis-cli\n</code></pre></li>\n</ul>\n<h2 id=\"性能测试工具\"><a href=\"#性能测试工具\" class=\"headerlink\" title=\"性能测试工具\"></a>性能测试工具</h2><ul>\n<li><h3 id=\"使用默认参数测试\"><a href=\"#使用默认参数测试\" class=\"headerlink\" title=\"使用默认参数测试\"></a>使用默认参数测试</h3><pre><code>redis-benchmark\n</code></pre></li>\n<li><h3 id=\"自定义参数测试\"><a href=\"#自定义参数测试\" class=\"headerlink\" title=\"自定义参数测试\"></a>自定义参数测试</h3><pre><code>redis-benchmark -n 1000000 --csv\n</code></pre></li>\n<li><h3 id=\"雪球-rdr：\"><a href=\"#雪球-rdr：\" class=\"headerlink\" title=\"雪球 rdr：\"></a>雪球 rdr：</h3><pre><code>  https://github.com/xueqiu/rdr\n</code></pre></li>\n<li><h3 id=\"redis-rdb-tools：\"><a href=\"#redis-rdb-tools：\" class=\"headerlink\" title=\"redis-rdb-tools：\"></a>redis-rdb-tools：</h3><pre><code>https://github.com/sripathikrishnan/redis-rdb-tools\n</code></pre></li>\n</ul>\n<h2 id=\"工具命令\"><a href=\"#工具命令\" class=\"headerlink\" title=\"工具命令\"></a>工具命令</h2><ul>\n<li><h3 id=\"指定配置文件启动服务\"><a href=\"#指定配置文件启动服务\" class=\"headerlink\" title=\"指定配置文件启动服务\"></a>指定配置文件启动服务</h3><pre><code>redis-server redis.conf\n</code></pre></li>\n<li><h3 id=\"指定端口启动服务\"><a href=\"#指定端口启动服务\" class=\"headerlink\" title=\"指定端口启动服务\"></a>指定端口启动服务</h3><pre><code>redis-server --port 6379\n</code></pre></li>\n</ul>\n<h2 id=\"检查修复本地数据文件工具\"><a href=\"#检查修复本地数据文件工具\" class=\"headerlink\" title=\"检查修复本地数据文件工具\"></a>检查修复本地数据文件工具</h2><pre><code>redis-check-dump dump.rdb\n</code></pre><h2 id=\"检查修复AOF日志文件工具\"><a href=\"#检查修复AOF日志文件工具\" class=\"headerlink\" title=\"检查修复AOF日志文件工具\"></a>检查修复AOF日志文件工具</h2><pre><code>redis-check-aof appendonly.aof\n</code></pre><h2 id=\"基础命令\"><a href=\"#基础命令\" class=\"headerlink\" title=\"基础命令\"></a>基础命令</h2><ul>\n<li><p>keys</p>\n<ul>\n<li>列出Redis所有的key</li>\n</ul>\n</li>\n<li><p>del</p>\n<ul>\n<li>删除一个或多个key，多个key之间用空格分隔，其返回值为整数，表示成功删除了多少个存在的key，因此，如果只删除一个key，则可以从返回值中判断是否成功，如果删除多个key，则只能得到删除成功的数量</li>\n</ul>\n</li>\n<li><p>exists</p>\n<ul>\n<li>exists命令用于判断一个或多个key是否存在，判断多个key时，key之间用空格分隔,exists的返回值为整数，表示当前判断有多少个key是存在的。</li>\n</ul>\n</li>\n<li><p>expire/pexpire</p>\n<ul>\n<li>expire设置key在多少秒之后过期，pexpire设置key在多少毫秒之后过期,成功返回1，失败返回0。</li>\n</ul>\n</li>\n<li><p>ttl/pttl</p>\n<ul>\n<li><p>ttl和pttl命令用于获取key的过期时间，其返回值为整型</p>\n<ul>\n<li><p>当key不存在或过期时间，返回-2。</p>\n</li>\n<li><p>当key存在且永久有效时，返回-1。</p>\n</li>\n<li><p>当key有设置过期时间时，返回为剩下的秒数(pttl为毫秒数)</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>expireat/pexpireat</p>\n<ul>\n<li>设置key在某个时间戳过期,expreat参数时间戳用秒表示，而pexpireat则用毫秒表示，与expire和pexpire功能类似，返回1表示成功，0表示失败。</li>\n</ul>\n</li>\n<li><p>persist</p>\n<ul>\n<li>移除key的过期时间，将key设置为永久有效，当key设置了过期时间，使用persist命令移除后返回1，如果key不存在或本身就是永久有效的，则返回0</li>\n</ul>\n</li>\n<li><p>type</p>\n<ul>\n<li>判断key是什么类型的数据结构,返回值为string,list,set,hash,zset,分别表示我们前面介绍的Redis的5种基础数据结构。</li>\n</ul>\n</li>\n</ul>\n<p>geo,hyperloglog,bitmaps等复杂的数据结构，都是在这五种基础数据结构上实现，比如geo是zset类型，hyperloglog和bitmaps都为string。</p>\n<ul>\n<li><p>auth </p>\n<ul>\n<li>Redis认证命令，执行其他命令前，必须先进行认证</li>\n</ul>\n</li>\n<li><p>ping</p>\n<ul>\n<li>测试客户端和服务器之间的联通，返回值为PONG,表示联通</li>\n</ul>\n</li>\n<li><p>config get * </p>\n<ul>\n<li>获取所有配置参数</li>\n</ul>\n</li>\n<li><p>config set config_name config_value</p>\n<ul>\n<li>设置配置参数值</li>\n</ul>\n</li>\n<li><p>info</p>\n<ul>\n<li>返回服务器信息</li>\n</ul>\n</li>\n<li><p>select </p>\n<ul>\n<li>切换数据库，redis默认的数据库是0-15，共16个数据库</li>\n</ul>\n</li>\n<li><p>move</p>\n<ul>\n<li>将当前库的键移动到其他数据库</li>\n</ul>\n</li>\n<li><p>dbsize</p>\n<ul>\n<li>获取当前库中所有键的数量</li>\n</ul>\n</li>\n<li><p>flushdb</p>\n<ul>\n<li>删除当前库中的所有key</li>\n</ul>\n</li>\n<li><p>flushall</p>\n<ul>\n<li>删除所有库中的所有key</li>\n</ul>\n</li>\n<li><p>save</p>\n<ul>\n<li>创建当前库的备份</li>\n</ul>\n</li>\n<li><p>bgsave</p>\n<ul>\n<li>同save,但是是后台备份，不阻塞主进程</li>\n</ul>\n</li>\n<li><p>eval</p>\n<ul>\n<li>执行lua脚本</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"string\"><a href=\"#string\" class=\"headerlink\" title=\"string\"></a>string</h3><ul>\n<li><p>set</p>\n<ul>\n<li>为一个 key 设置 value，可以配合 EX/PX 参数指定 key 的有效期</li>\n</ul>\n</li>\n<li><p>get</p>\n<ul>\n<li>获取某个 key 对应的 value</li>\n</ul>\n</li>\n<li><p>getset</p>\n<ul>\n<li>为一个 key 设置 value，并返回该 key 的原 value</li>\n</ul>\n</li>\n<li><p>incr/decr </p>\n<ul>\n<li>自增/自减(前提是键值是整型)</li>\n</ul>\n</li>\n<li><p>incrby/decrby </p>\n<ul>\n<li>指定步长增加减少(q前提是键值是整型)</li>\n</ul>\n</li>\n<li><p>mset</p>\n<ul>\n<li>为多个 key 设置 value</li>\n</ul>\n</li>\n<li><p>msetnx</p>\n<ul>\n<li>同 MSET，如果指定的 key 中有任意一个已存在，则不进行任何操作</li>\n</ul>\n</li>\n<li><p>mget</p>\n<ul>\n<li>获取多个 key 对应的 value</li>\n</ul>\n</li>\n<li><p>strlen </p>\n<ul>\n<li>获取键的长度</li>\n</ul>\n</li>\n<li><p>append </p>\n<ul>\n<li>向指定键追加值，返回字符串长度</li>\n</ul>\n</li>\n<li><p>setnx </p>\n<ul>\n<li>判断键是否存在，存在返回0，否则返回1，不会覆盖原来值</li>\n</ul>\n</li>\n<li><p>getrange </p>\n<ul>\n<li>根据指定下标获取键的值</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"list\"><a href=\"#list\" class=\"headerlink\" title=\"list\"></a>list</h3><ul>\n<li><p>lpush</p>\n<ul>\n<li>向指定 List 的左侧（即头部）插入 1 个或多个元素，返回插入后的 List 长度</li>\n</ul>\n</li>\n<li><p>rpush</p>\n<ul>\n<li>同 lpush，向指定 List 的右侧（即尾部）插入 1 或多个元素</li>\n</ul>\n</li>\n<li><p>lpushx/rpushx</p>\n<ul>\n<li>与 lpush/rpush类似，区别在于，lpushx/rpushx操作的 key 如果不存在，则不会进行任何操作</li>\n</ul>\n</li>\n<li><p>lrange</p>\n<ul>\n<li>返回指定 List 中指定范围的元素（双端包含，即 lrange key 0 10 会返回 11 个元素），时间复杂度 O(N)。应尽可能控制一次获取的元素数量，一次获取过大范围的 List 元素会导致延迟，同时对长度不可预知的 List，避免使用 lrange key 0 -1 这样的完整遍历操作</li>\n</ul>\n</li>\n<li><p>lindex</p>\n<ul>\n<li>返回指定 List 指定 index 上的元素，如果 index 越界，返回 nil。index 数值是回环的，即 - 1 代表 List 最后一个位置，-2 代表 List 倒数第二个位置。</li>\n</ul>\n</li>\n<li><p>linsert</p>\n<ul>\n<li>向指定 List 中指定元素之前 / 之后插入一个新元素，并返回操作后的 List 长度。如果指定的元素不存在，返回 - 1。如果指定 key 不存在，不会进行任何操作</li>\n</ul>\n</li>\n<li><p>lset</p>\n<ul>\n<li><p>将指定 List 指定 index 上的元素设置为 value</p>\n<ul>\n<li>如果 index 越界则返回错误，时间复杂度 O(N)，</li>\n<li>如果操作的是头 / 尾部的元素，则时间复杂度为 O(1)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>lpop</p>\n<ul>\n<li>从指定 List 的左侧（即头部）移除一个元素并返回</li>\n</ul>\n</li>\n<li><p>rpop</p>\n<ul>\n<li>同 lpop，从指定 List 的右侧（即尾部）移除 1 个元素并返回</li>\n</ul>\n</li>\n<li><p>llen</p>\n<ul>\n<li>返回指定 List 的长度</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"hash\"><a href=\"#hash\" class=\"headerlink\" title=\"hash\"></a>hash</h3><ul>\n<li><p>hset</p>\n<ul>\n<li>将 key 对应的 Hash 中的 field 设置为 value。如果该 Hash 不存在，会自动创建一个。</li>\n</ul>\n</li>\n<li><p>hget</p>\n<ul>\n<li>返回指定 Hash 中 field 字段的值</li>\n</ul>\n</li>\n<li><p>hsetnx</p>\n<ul>\n<li>同 HSET，但如 field 已经存在，HSETNX 不会进行任何操作</li>\n</ul>\n</li>\n<li><p>hexists</p>\n<ul>\n<li>判断指定 Hash 中 field 是否存在，存在返回 1，不存在返回 0</li>\n</ul>\n</li>\n<li><p>hincrby</p>\n<ul>\n<li>同 incrby命令，对指定 Hash 中的一个 field 进行 incrby</li>\n</ul>\n</li>\n<li><p>hmset/hmget</p>\n<ul>\n<li>同 HSET 和 HGET，可以批量操作同一个 key 下的多个 field</li>\n</ul>\n</li>\n<li><p>hdel</p>\n<ul>\n<li>删除指定 Hash 中的 field（1 个或多个）</li>\n</ul>\n</li>\n<li><p>hgetall</p>\n<ul>\n<li>返回指定 Hash 中所有的 field-value 对。返回结果为数组，数组中 field 和 value 交替出现</li>\n</ul>\n</li>\n<li><p>hkeys/hvals</p>\n<ul>\n<li>返回指定 Hash 中所有的 field/value</li>\n</ul>\n</li>\n<li><p>hlen </p>\n<ul>\n<li>返回指定hash 表中field中的数量</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"set\"><a href=\"#set\" class=\"headerlink\" title=\"set\"></a>set</h3><ul>\n<li><p>scard</p>\n<ul>\n<li>返回指定 Set 中的 member 个数</li>\n</ul>\n</li>\n<li><p>sismember</p>\n<ul>\n<li>判断指定的 value 是否存在于指定 Set 中</li>\n</ul>\n</li>\n<li><p>smove</p>\n<ul>\n<li>将指定 member 从一个 Set 移至另一个 Set</li>\n</ul>\n</li>\n<li><p>sadd</p>\n<ul>\n<li>向指定 Set 中添加 1 个或多个 member，如果指定 Set 不存在，会自动创建一个。</li>\n</ul>\n</li>\n<li><p>srem</p>\n<ul>\n<li>从指定 Set 中移除 1 个或多个 member</li>\n</ul>\n</li>\n<li><p>srandmember</p>\n<ul>\n<li>从指定 Set 中随机返回 1 个或多个 member</li>\n</ul>\n</li>\n<li><p>spop</p>\n<ul>\n<li>从指定 Set 中随机移除并返回 count 个 member</li>\n</ul>\n</li>\n<li><p>smembers</p>\n<ul>\n<li>返回指定 Hash 中所有的 member</li>\n</ul>\n</li>\n<li><p>sunion/sunionstore</p>\n<ul>\n<li>计算多个 Set 的并集并返回 / 存储至另一个 Set 中</li>\n</ul>\n</li>\n<li><p>sinter/sinterstore</p>\n<ul>\n<li>计算多个 Set 的交集并返回 / 存储至另一个 Set 中</li>\n</ul>\n</li>\n<li><p>sdiff/sinterstore</p>\n<ul>\n<li>计算 1 个 Set 与 1 或多个 Set 的差集并返回 / 存储至另一个 Set 中</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"zset\"><a href=\"#zset\" class=\"headerlink\" title=\"zset\"></a>zset</h3><ul>\n<li>zadd</li>\n<li>zrem</li>\n<li>zcard</li>\n<li>zcount</li>\n<li>zscore</li>\n<li>zrank/zrevrank</li>\n<li>zincrby</li>\n<li>zrange/zrevrange</li>\n<li>zrangebyscore/zrevragebyscore</li>\n<li>zremrangebyrank/zremrangebyscore</li>\n</ul>\n<h3 id=\"事物\"><a href=\"#事物\" class=\"headerlink\" title=\"事物\"></a>事物</h3><ul>\n<li><p>multi </p>\n<ul>\n<li>开启一个事务</li>\n</ul>\n</li>\n<li><p>exec </p>\n<ul>\n<li>执行事务</li>\n</ul>\n</li>\n<li><p>discard </p>\n<ul>\n<li>撤销事务</li>\n</ul>\n</li>\n<li><p>watch </p>\n<ul>\n<li>监视数据库键，若发生改变，返回空</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"复制\"><a href=\"#复制\" class=\"headerlink\" title=\"复制\"></a>复制</h3><ul>\n<li><p>info replication</p>\n<ul>\n<li>获取复制信息</li>\n</ul>\n</li>\n<li><p>slaveof</p>\n<ul>\n<li>建立复制关系</li>\n</ul>\n</li>\n<li><p>sync </p>\n<ul>\n<li>同步</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"订阅发布\"><a href=\"#订阅发布\" class=\"headerlink\" title=\"订阅发布\"></a>订阅发布</h3><ul>\n<li><p>subscribe</p>\n<ul>\n<li>订阅一个或多个频道</li>\n</ul>\n</li>\n<li><p>publish </p>\n<ul>\n<li>向某一频道发送信息</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"性能调优\"><a href=\"#性能调优\" class=\"headerlink\" title=\"性能调优\"></a>性能调优</h2><ul>\n<li><h3 id=\"避免存储-bigkey\"><a href=\"#避免存储-bigkey\" class=\"headerlink\" title=\"避免存储 bigkey\"></a>避免存储 bigkey</h3></li>\n<li><h3 id=\"使用-pipelining-将连续执行的命令组合执行\"><a href=\"#使用-pipelining-将连续执行的命令组合执行\" class=\"headerlink\" title=\"使用 pipelining 将连续执行的命令组合执行\"></a>使用 pipelining 将连续执行的命令组合执行</h3></li>\n<li><h3 id=\"操作系统的-Transparent-huge-pages-功能必须关闭\"><a href=\"#操作系统的-Transparent-huge-pages-功能必须关闭\" class=\"headerlink\" title=\"操作系统的 Transparent huge pages 功能必须关闭\"></a>操作系统的 Transparent huge pages 功能必须关闭</h3><pre><code>  echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\n</code></pre></li>\n<li><h3 id=\"使用物理机部署-Redis\"><a href=\"#使用物理机部署-Redis\" class=\"headerlink\" title=\"使用物理机部署 Redis\"></a>使用物理机部署 Redis</h3><ul>\n<li>Redis 在做数据持久化时，采用创建子进程的方式进行。<br>而创建子进程会调用操作系统的 fork 系统调用，这个系统调用的执行耗时，与系统环境有关。<br>虚拟机环境执行 fork 的耗时，要比物理机慢得多，所以你的 Redis 应该尽可能部署在物理机上</li>\n</ul>\n</li>\n<li><h3 id=\"检查数据持久化策略\"><a href=\"#检查数据持久化策略\" class=\"headerlink\" title=\"检查数据持久化策略\"></a>检查数据持久化策略</h3></li>\n<li><h3 id=\"考虑引入读写分离机制\"><a href=\"#考虑引入读写分离机制\" class=\"headerlink\" title=\"考虑引入读写分离机制\"></a>考虑引入读写分离机制</h3></li>\n<li><h3 id=\"开启-lazy-free-机制\"><a href=\"#开启-lazy-free-机制\" class=\"headerlink\" title=\"开启 lazy-free 机制\"></a>开启 lazy-free 机制</h3><ul>\n<li>如果你无法避免存储 bigkey，那么我建议你开启 Redis 的 lazy-free 机制。（4.0+版本支持）<br>当开启这个机制后，Redis 在删除一个 bigkey 时，释放内存的耗时操作，将会放到后台线程中去执行，这样可以在最大程度上，避免对主线程的影响</li>\n</ul>\n</li>\n<li><h3 id=\"不使用复杂度过高的命令\"><a href=\"#不使用复杂度过高的命令\" class=\"headerlink\" title=\"不使用复杂度过高的命令\"></a>不使用复杂度过高的命令</h3><ul>\n<li>避免执行例如 SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE 等聚合类命令。<br>对于这种聚合类操作，我建议你把它放到客户端来执行，不要让 Redis 承担太多的计算工作</li>\n</ul>\n</li>\n<li><h3 id=\"执行-O-N-命令时，关注-N-的大\"><a href=\"#执行-O-N-命令时，关注-N-的大\" class=\"headerlink\" title=\"执行 O(N) 命令时，关注 N 的大\"></a>执行 O(N) 命令时，关注 N 的大</h3><ul>\n<li><p>查询数据时，遵循原则</p>\n<ul>\n<li>先查询数据元素的数量（LLEN/HLEN/SCARD/ZCARD）</li>\n<li>元素数量较少，可一次性查询全量数据</li>\n<li>元素数量非常多，分批查询数据（LRANGE/HASCAN/SSCAN/ZSCAN）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"关注-DEL-时间复杂度\"><a href=\"#关注-DEL-时间复杂度\" class=\"headerlink\" title=\"关注 DEL 时间复杂度\"></a>关注 DEL 时间复杂度</h3><ul>\n<li><p>删除一个 key，其元素数量越多，执行 DEL 也就越慢</p>\n<ul>\n<li>List类型：执行多次 LPOP/RPOP，直到所有元素都删除完成</li>\n<li>Hash/Set/ZSet类型：先执行 HSCAN/SSCAN/SCAN 查询元素，再执行 HDEL/SREM/ZREM 依次删除每个元素</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"批量命令代替单个命令\"><a href=\"#批量命令代替单个命令\" class=\"headerlink\" title=\"批量命令代替单个命令\"></a>批量命令代替单个命令</h3><ul>\n<li><p>批量操作相比于多次单个操作的优势在于，可以显著减少客户端、服务端的来回网络 IO 次数</p>\n</li>\n<li><p>String / Hash 使用 MGET/MSET 替代 GET/SET，HMGET/HMSET 替代 HGET/HSET</p>\n</li>\n<li>其它数据类型使用 Pipeline，打包一次性发送多个命令到服务端执行</li>\n</ul>\n</li>\n<li><h3 id=\"避免集中过期-key\"><a href=\"#避免集中过期-key\" class=\"headerlink\" title=\"避免集中过期 key\"></a>避免集中过期 key</h3><ul>\n<li><p>如果你的业务存在大量 key 集中过期的情况，那么 Redis 在清理过期 key 时，也会有阻塞主线程的风险</p>\n</li>\n<li><p>在设置过期时间时，增加一个随机时间，把这些 key 的过期时间打散，从而降低集中过期对主线程的影响</p>\n</li>\n</ul>\n</li>\n<li><h3 id=\"使用长连接操作-Redis，合理配置连接池\"><a href=\"#使用长连接操作-Redis，合理配置连接池\" class=\"headerlink\" title=\"使用长连接操作 Redis，合理配置连接池\"></a>使用长连接操作 Redis，合理配置连接池</h3><ul>\n<li>你的业务应该使用长连接操作 Redis，避免短连接</li>\n<li>当使用短连接操作 Redis 时，每次都需要经过 TCP 三次握手、四次挥手，这个过程也会增加操作耗时</li>\n<li>同时，你的客户端应该使用连接池的方式访问 Redis，并设置合理的参数，长时间不操作 Redis 时，需及时释放连接资源</li>\n</ul>\n</li>\n<li><h3 id=\"只使用-db0\"><a href=\"#只使用-db0\" class=\"headerlink\" title=\"只使用 db0\"></a>只使用 db0</h3><ul>\n<li>在一个连接上操作多个 db 数据时，每次都需要先执行 SELECT，这会给 Redis 带来额外的压力</li>\n<li>使用多个 db 的目的是，按不同业务线存储数据，那为何不拆分多个实例存储呢？拆分多个实例部署，多个业务线不会互相影响，还能提高 Redis 的访问性能</li>\n<li>Redis Cluster 只支持 db0，如果后期你想要迁移到 Redis Cluster，迁移成本高</li>\n</ul>\n</li>\n<li><h3 id=\"使用读写分离-分片集群\"><a href=\"#使用读写分离-分片集群\" class=\"headerlink\" title=\"使用读写分离 + 分片集群\"></a>使用读写分离 + 分片集群</h3><ul>\n<li>如果你的业务读请求量很大，那么可以采用部署多个从库的方式，实现读写分离，让 Redis 的从库分担读压力，进而提升性能</li>\n<li>如果你的业务写请求量很大，单个 Redis 实例已无法支撑这么大的写流量，那么此时你需要使用分片集群，分担写压力</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"不开启-AOF-或-AOF-配置为每秒刷盘\"><a href=\"#不开启-AOF-或-AOF-配置为每秒刷盘\" class=\"headerlink\" title=\"不开启 AOF 或 AOF 配置为每秒刷盘\"></a>不开启 AOF 或 AOF 配置为每秒刷盘</h3><ul>\n<li>如果对于丢失数据不敏感的业务，我建议你不开启 AOF，避免 AOF 写磁盘拖慢 Redis 的性能</li>\n<li>如果确实需要开启 AOF，那么我建议你配置为 appendfsync everysec，把数据持久化的刷盘操作，放到后台线程中去执行，尽量降低 Redis 写磁盘对性能的影响</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"长耗时命令\"><a href=\"#长耗时命令\" class=\"headerlink\" title=\"长耗时命令\"></a>长耗时命令</h2><ul>\n<li><h3 id=\"避免在使用这些-O-N-命令\"><a href=\"#避免在使用这些-O-N-命令\" class=\"headerlink\" title=\"避免在使用这些 O(N) 命令\"></a>避免在使用这些 O(N) 命令</h3><ul>\n<li>不要把 List 当做列表使用，仅当做队列来使用</li>\n<li>通过机制严格控制 Hash、Set、Sorted Set 的大小</li>\n<li>可能的话，将排序、并集、交集等操作放在客户端执行</li>\n<li>绝对禁止使用 keys 命令</li>\n<li>避免一次性遍历集合类型的所有成员，而应使用 scan 类的命令进行分批的，游标式的遍历</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"Slow-Log-功能，自动记录耗时较长的命令\"><a href=\"#Slow-Log-功能，自动记录耗时较长的命令\" class=\"headerlink\" title=\"Slow Log 功能，自动记录耗时较长的命令\"></a>Slow Log 功能，自动记录耗时较长的命令</h3><ul>\n<li>slowlog-log-slower-than xxxms  #执行时间慢于xxx毫秒的命令计入  。                              Slow Logslowlog-max-len xxx  #Slow Log的长度，即最大纪录多少条Slow Log</li>\n<li>使用 slowlog get [number] 命令，可以输出最近进入 Slow Log 的 number 条命令。<br>使用 slowlog reset 命令，可以重置 Slow Log</li>\n</ul>\n</li>\n<li><h3 id=\"网络引发的延迟\"><a href=\"#网络引发的延迟\" class=\"headerlink\" title=\"网络引发的延迟\"></a>网络引发的延迟</h3><ul>\n<li>尽可能使用长连接或连接池，避免频繁创建销毁连接</li>\n<li>客户端进行的批量数据操作，应使用 Pipeline 特性在一次交互中完成。</li>\n</ul>\n</li>\n<li><h3 id=\"数据持久化引发的延迟\"><a href=\"#数据持久化引发的延迟\" class=\"headerlink\" title=\"数据持久化引发的延迟\"></a>数据持久化引发的延迟</h3><ul>\n<li><p>要根据数据的安全级别和性能要求制定合理的持久化策略</p>\n<ul>\n<li>AOF + fsync always 的设置虽然能够绝对确保数据安全，但每个操作都会触发一次 fsync，会对 Redis 的性能有比较明显的影响</li>\n<li>AOF + fsync every second 是比较好的折中方案，每秒 fsync 一次</li>\n<li>AOF + fsync never 会提供 AOF 持久化方案下的最优性能<br>使用 RDB 持久化通常会提供比使用 AOF 更高的性能，但需要注意 RDB 的策略配置</li>\n<li>每一次 RDB 快照和 AOF Rewrite 都需要 Redis 主进程进行 fork 操作。fork 操作本身可能会产生较高的耗时，与 CPU 和 Redis 占用的内存大小有关。根据具体的情况合理配置 RDB 快照和 AOF Rewrite 时机，避免过于频繁的 fork 带来的延迟</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"Swap-引发的延迟\"><a href=\"#Swap-引发的延迟\" class=\"headerlink\" title=\"Swap 引发的延迟\"></a>Swap 引发的延迟</h3><ul>\n<li><p>当 Linux 将 Redis 所用的内存分页移至 swap 空间时，将会阻塞 Redis 进程，导致 Redis 出现不正常的延迟。Swap 通常在物理内存不足或一些进程在进行大量 I/O 操作时发生，应尽可能避免上述两种情况的出现。<br>/proc//smaps 文件中会保存进程的 swap 记录，通过查看这个文件，能够判断 Redis 的延迟是否由 Swap 产生。如果这个文件中记录了较大的 Swap size，则说明延迟很有可能是 Swap 造成的。</p>\n</li>\n<li><p>数据淘汰引发的延迟<br>当同一秒内有大量 key 过期时，也会引发 Redis 的延迟。在使用时应尽量将 key 的失效时间错开。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"主从复制与集群分片\"><a href=\"#主从复制与集群分片\" class=\"headerlink\" title=\"主从复制与集群分片\"></a>主从复制与集群分片</h2><ul>\n<li><h3 id=\"主从复制\"><a href=\"#主从复制\" class=\"headerlink\" title=\"主从复制\"></a>主从复制</h3><ul>\n<li><p>Redis 支持一主多从的主从复制架构。一个 Master 实例负责处理所有的写请求，Master 将写操作同步至所有 Slave。</p>\n<ul>\n<li><p>借助 Redis 的主从复制，可以实现读写分离和高可用</p>\n<ul>\n<li>实时性要求不是特别高的读请求，可以在 Slave 上完成，提升效率。特别是一些周期性执行的统计任务，这些任务可能需要执行一些长耗时的 Redis 命令，可以专门规划出 1 个或几个 Slave 用于服务这些统计任务</li>\n<li>借助 Redis Sentinel 可以实现高可用，当 Master crash 后，Redis Sentinel 能够自动将一个 Slave 晋升为 Master，继续提供服务</li>\n</ul>\n</li>\n<li><p>Sentinel 做自动 failover</p>\n<ul>\n<li><p>Redis 的主从复制功能本身只是做数据同步，并不提供监控和自动 failover 能力，要通过主从复制功能来实现 Redis 的高可用，还需要引入一个组件：Redis Sentinel<br>Redis Sentinel 是 Redis 官方开发的监控组件，可以监控 Redis 实例的状态，通过 Master 节点自动发现 Slave 节点，并在监测到 Master 节点失效时选举出一个新的 Master，并向所有 Redis 实例推送新的主从配置</p>\n<ul>\n<li>sentinel monitor mymaster 127.0.0.1 6379 2  #Master实例的IP、端口，以及选举需要的赞成票数</li>\n<li>sentinel down-after-milliseconds mymaster 60000  #多长时间没有响应视为Master失效</li>\n<li>sentinel failover-timeout mymaster 180000  #两次failover尝试间的间隔时长</li>\n<li>sentinel parallel-syncs mymaster 1  #如果有多个Slave，可以通过此配置指定同时从新Master进行数据同步的Slave数，避免所有Slave同时进行数据同步导致查询服务也不可用</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"集群分片\"><a href=\"#集群分片\" class=\"headerlink\" title=\"集群分片\"></a>集群分片</h3><ul>\n<li>Redis 中存储的数据量大，一台主机的物理内存已经无法容纳</li>\n<li>Redis 的写请求并发量大，一个 Redis 实例以无法承载</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><ul>\n<li><h3 id=\"缓存和数据库双写一致性问题\"><a href=\"#缓存和数据库双写一致性问题\" class=\"headerlink\" title=\"缓存和数据库双写一致性问题\"></a>缓存和数据库双写一致性问题</h3><ul>\n<li>降低不一致发生的概率，无法完全避免</li>\n<li>只能保证最终一致性</li>\n</ul>\n<p>首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。</p>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"缓存雪崩问题\"><a href=\"#缓存雪崩问题\" class=\"headerlink\" title=\"缓存雪崩问题\"></a>缓存雪崩问题</h3><ul>\n<li>缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"缓存穿透\"><a href=\"#缓存穿透\" class=\"headerlink\" title=\"缓存穿透\"></a>缓存穿透</h3><ul>\n<li>缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常</li>\n</ul>\n</li>\n<li><h3 id=\"缓存击穿问题\"><a href=\"#缓存击穿问题\" class=\"headerlink\" title=\"缓存击穿问题\"></a>缓存击穿问题</h3><ul>\n<li>在第一个查询数据的请求上使用一个互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h2><ul>\n<li><h3 id=\"纯内存操作\"><a href=\"#纯内存操作\" class=\"headerlink\" title=\"纯内存操作\"></a>纯内存操作</h3><ul>\n<li>Redis将所有数据放在内存中，非数据同步正常工作中，是不需要从磁盘读取数据的，0次IO。内存响应时间大约为100纳秒</li>\n</ul>\n</li>\n<li><h3 id=\"单线程操作，避免了频繁的上下文切换\"><a href=\"#单线程操作，避免了频繁的上下文切换\" class=\"headerlink\" title=\"单线程操作，避免了频繁的上下文切换\"></a>单线程操作，避免了频繁的上下文切换</h3><ul>\n<li>第一，单线程简化算法的实现，并发的数据结构实现不但困难且测试也麻烦。第二，单线程避免了线程切换以及加锁释放锁带来的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。当然了，单线程也会有它的缺点，也是Redis的噩梦：阻塞。如果执行一个命令过长，那么会造成其他命令的阻塞，对于Redis是十分致命的，所以Redis是面向快速执行场景的数据库。</li>\n</ul>\n</li>\n<li><h3 id=\"采用了非阻塞I-O多路复用机制\"><a href=\"#采用了非阻塞I-O多路复用机制\" class=\"headerlink\" title=\"采用了非阻塞I/O多路复用机制\"></a>采用了非阻塞I/O多路复用机制</h3><ul>\n<li>当使用read或者write对某一文件描述符（File Descriptor FD）进行读写的时候，如果数据没有收到，那么该线程会被挂起，直到收到数据</li>\n<li><p>I/O多路复用实际上是指多个连接的管理可以在同一进程。多路是指网络连接，复用只是同一个线程</p>\n<ul>\n<li>Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll的read、write、close等都转换成事件，不在网络I/O上浪费过多的时间。实现对多个FD读写的监控，提高性能。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"策略以及内存淘汰机制\"><a href=\"#策略以及内存淘汰机制\" class=\"headerlink\" title=\"策略以及内存淘汰机制\"></a>策略以及内存淘汰机制</h2><ul>\n<li><h3 id=\"删除机制\"><a href=\"#删除机制\" class=\"headerlink\" title=\"删除机制\"></a>删除机制</h3><ul>\n<li><p>定期删除</p>\n<ul>\n<li>用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key</li>\n</ul>\n</li>\n<li><p>惰性删除策略</p>\n<ul>\n<li>所谓惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期了就立即删除，不会给你返回任何东西。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"内存淘汰策略\"><a href=\"#内存淘汰策略\" class=\"headerlink\" title=\"内存淘汰策略\"></a>内存淘汰策略</h3><ul>\n<li><p>noeviction</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，新写入操作会报错</li>\n</ul>\n</li>\n<li><p>allkeys-lru</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key</li>\n</ul>\n</li>\n<li><p>allkeys-random</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在键空间中，随机移除某个key</li>\n</ul>\n</li>\n<li><p>volatile-lru</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。不推荐</li>\n</ul>\n</li>\n<li><p>volatile-random</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。不推荐</li>\n</ul>\n</li>\n<li><p>volatile-ttl</p>\n<ul>\n<li>当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。不推荐</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"持久化策略\"><a href=\"#持久化策略\" class=\"headerlink\" title=\"持久化策略\"></a>持久化策略</h3><ul>\n<li><p>快照（RDB）</p>\n<ul>\n<li>快照是内存数据的二进制序列化形式，在存储上非常紧凑</li>\n<li>RDB是通过Redis主进程fork子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化。RDB记录的是数据</li>\n</ul>\n</li>\n<li><p>日志追加（AOF）</p>\n<ul>\n<li>AOF 日志是连续的增量备份，在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长</li>\n<li>AOF 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的指令记录。AOF记录的是指令</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"节省内存\"><a href=\"#节省内存\" class=\"headerlink\" title=\"节省内存\"></a>节省内存</h2><ul>\n<li><h3 id=\"控制-key-的长度\"><a href=\"#控制-key-的长度\" class=\"headerlink\" title=\"控制 key 的长度\"></a>控制 key 的长度</h3></li>\n<li><h3 id=\"避免存储-bigkey-1\"><a href=\"#避免存储-bigkey-1\" class=\"headerlink\" title=\"避免存储 bigkey\"></a>避免存储 bigkey</h3><ul>\n<li>String：大小控制在 10KB 以下</li>\n<li>List/Hash/Set/ZSet：元素数量控制在 1 万以下</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"选择合适的数据类型\"><a href=\"#选择合适的数据类型\" class=\"headerlink\" title=\"选择合适的数据类型\"></a>选择合适的数据类型</h3><ul>\n<li>String、Set：尽可能存储 int 类型数据</li>\n<li>Hash、ZSet：存储的元素数量控制在转换阈值之下，以压缩列表存储，节约内存</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"把-Redis-当作缓存使用\"><a href=\"#把-Redis-当作缓存使用\" class=\"headerlink\" title=\"把 Redis 当作缓存使用\"></a>把 Redis 当作缓存使用</h3></li>\n<li><h3 id=\"实例设置-maxmemory-淘汰策略\"><a href=\"#实例设置-maxmemory-淘汰策略\" class=\"headerlink\" title=\"实例设置 maxmemory + 淘汰策略\"></a>实例设置 maxmemory + 淘汰策略</h3><ul>\n<li>volatile-lru / allkeys-lru：优先保留最近访问过的数据</li>\n<li>volatile-lfu / allkeys-lfu：优先保留访问次数最频繁的数据（4.0+版本支持）</li>\n<li>volatile-ttl ：优先淘汰即将过期的数据</li>\n<li>volatile-random / allkeys-random：随机淘汰数据</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"数据压缩后写入-Redis\"><a href=\"#数据压缩后写入-Redis\" class=\"headerlink\" title=\"数据压缩后写入 Redis\"></a>数据压缩后写入 Redis</h3></li>\n</ul>\n<h2 id=\"可靠性\"><a href=\"#可靠性\" class=\"headerlink\" title=\"可靠性\"></a>可靠性</h2><ul>\n<li><h3 id=\"按业务线部署实例\"><a href=\"#按业务线部署实例\" class=\"headerlink\" title=\"按业务线部署实例\"></a>按业务线部署实例</h3><ul>\n<li>提升可靠性的第一步，就是「资源隔离」。<br>你最好按不同的业务线来部署 Redis 实例，这样当其中一个实例发生故障时，不会影响到其它业务。<br>这种资源隔离的方案，实施成本是最低的，但成效却是非常大的</li>\n</ul>\n</li>\n<li><h3 id=\"部署主从集群\"><a href=\"#部署主从集群\" class=\"headerlink\" title=\"部署主从集群\"></a>部署主从集群</h3><ul>\n<li>如果你只使用单机版 Redis，那么就会存在机器宕机服务不可用的风险。<br>所以，你需要部署「多副本」实例，即主从集群，这样当主库宕机后，依旧有从库可以使用，避免了数据丢失的风险，也降低了服务不可用的时间。<br>在部署主从集群时，你还需要注意，主从库需要分布在不同机器上，避免交叉部署。<br>这么做的原因在于，通常情况下，Redis 的主库会承担所有的读写流量，所以我们一定要优先保证主库的稳定性，即使从库机器异常，也不要对主库造成影响。<br>而且，有时我们需要对 Redis 做日常维护，例如数据定时备份等操作，这时你就可以只在从库上进行，这只会消耗从库机器的资源，也避免了对主库的影响</li>\n</ul>\n</li>\n<li><h3 id=\"合理配置主从复制参数\"><a href=\"#合理配置主从复制参数\" class=\"headerlink\" title=\"合理配置主从复制参数\"></a>合理配置主从复制参数</h3><ul>\n<li><p>不合理</p>\n<ul>\n<li>主从复制中断</li>\n<li>从库发起全量复制，主库性能受到影响</li>\n</ul>\n</li>\n<li><p>合理</p>\n<ul>\n<li>设置合理的 repl-backlog 参数：过小的 repl-backlog 在写流量比较大的场景下，主从复制中断会引发全量复制数据的风险</li>\n<li>设置合理的 slave client-output-buffer-limit：当从库复制发生问题时，过小的 buffer 会导致从库缓冲区溢出，从而导致复制中断</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"部署哨兵集群，实现故障自动切换\"><a href=\"#部署哨兵集群，实现故障自动切换\" class=\"headerlink\" title=\"部署哨兵集群，实现故障自动切换\"></a>部署哨兵集群，实现故障自动切换</h3><ul>\n<li>只部署了主从节点，但故障发生时是无法自动切换的，所以，你还需要部署哨兵集群，实现故障的「自动切换」。<br>而且，多个哨兵节点需要分布在不同机器上，实例为奇数个，防止哨兵选举失败，影响切换时间</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"日常运维\"><a href=\"#日常运维\" class=\"headerlink\" title=\"日常运维\"></a>日常运维</h2><ul>\n<li><h3 id=\"禁止使用-KEYS-FLUSHALL-FLUSHDB-命令\"><a href=\"#禁止使用-KEYS-FLUSHALL-FLUSHDB-命令\" class=\"headerlink\" title=\"禁止使用 KEYS/FLUSHALL/FLUSHDB 命令\"></a>禁止使用 KEYS/FLUSHALL/FLUSHDB 命令</h3><ul>\n<li><p>执行这些命令，会长时间阻塞 Redis 主线程，危害极大</p>\n<ul>\n<li>SCAN 替换 KEYS</li>\n<li>4.0+版本可使用 FLUSHALL/FLUSHDB ASYNC，清空数据的操作放在后台线程执行</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><h3 id=\"扫描线上实例时，设置休眠时间\"><a href=\"#扫描线上实例时，设置休眠时间\" class=\"headerlink\" title=\"扫描线上实例时，设置休眠时间\"></a>扫描线上实例时，设置休眠时间</h3><ul>\n<li>不管你是使用 SCAN 扫描线上实例，还是对实例做 bigkey 统计分析，我建议你在扫描时一定记得设置休眠时间。<br>防止在扫描过程中，实例 OPS 过高对 Redis 产生性能抖动</li>\n</ul>\n</li>\n<li><h3 id=\"慎用-MONITOR-命令\"><a href=\"#慎用-MONITOR-命令\" class=\"headerlink\" title=\"慎用 MONITOR 命令\"></a>慎用 MONITOR 命令</h3><ul>\n<li>有时在排查 Redis 问题时，你会使用 MONITOR 查看 Redis 正在执行的命令。<br>但如果你的 Redis OPS 比较高，那么在执行 MONITOR 会导致 Redis 输出缓冲区的内存持续增长，这会严重消耗 Redis 的内存资源，甚至会导致实例内存超过 maxmemory，引发数据淘汰，这种情况你需要格外注意</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><h3 id=\"从库必须设置为-slave-read-only\"><a href=\"#从库必须设置为-slave-read-only\" class=\"headerlink\" title=\"从库必须设置为 slave-read-only\"></a>从库必须设置为 slave-read-only</h3><ul>\n<li>你的从库必须设置为 slave-read-only 状态，避免从库写入数据，导致主从数据不一致。<br>除此之外，从库如果是非 read-only 状态，如果你使用的是 4.0 以下的 Redis，它存在这样的 Bug：<br>从库写入了有过期时间的数据，不会做定时清理和释放内存。<br>这会造成从库的内存泄露！这个问题直到 4.0 版本才修复，你在配置从库时需要格外注意</li>\n</ul>\n</li>\n<li><h3 id=\"合理配置-timeout-和-tcp-keepalive-参数\"><a href=\"#合理配置-timeout-和-tcp-keepalive-参数\" class=\"headerlink\" title=\"合理配置 timeout 和 tcp-keepalive 参数\"></a>合理配置 timeout 和 tcp-keepalive 参数</h3><ul>\n<li>如果因为网络原因，导致你的大量客户端连接与 Redis 意外中断，恰好你的 Redis 配置的 maxclients 参数比较小，此时有可能导致客户端无法与服务端建立新的连接（服务端认为超过了 maxclients）。<br>造成这个问题原因在于，客户端与服务端每建立一个连接，Redis 都会给这个客户端分配了一个 client fd。</li>\n</ul>\n<p>当客户端与服务端网络发生问题时，服务端并不会立即释放这个 client fd。</p>\n<p>什么时候释放呢？</p>\n<p>Redis 内部有一个定时任务，会定时检测所有 client 的空闲时间是否超过配置的 timeout 值。<br>如果 Redis 没有开启 tcp-keepalive 的话，服务端直到配置的 timeout 时间后，才会清理释放这个 client fd。</p>\n<p>在没有清理之前，如果还有大量新连接进来，就有可能导致 Redis 服务端内部持有的 client fd 超过了 maxclients，这时新连接就会被拒绝。</p>\n<p>针对这种情况，我给你的优化建议是：<br>不要配置过高的 timeout：让服务端尽快把无效的 client fd 清理掉<br>Redis 开启 tcp-keepalive：这样服务端会定时给客户端发送 TCP 心跳包，检测连接连通性，当网络异常时，可以尽快清理僵尸 client fd</p>\n</li>\n<li><h3 id=\"调整-maxmemory-时，注意主从库的调整顺序\"><a href=\"#调整-maxmemory-时，注意主从库的调整顺序\" class=\"headerlink\" title=\"调整 maxmemory 时，注意主从库的调整顺序\"></a>调整 maxmemory 时，注意主从库的调整顺序</h3><ul>\n<li>从库内存如果超过了 maxmemory，也会触发数据淘汰。<br>在某些场景下，从库是可能优先主库达到 maxmemory 的（例如在从库执行 MONITOR 命令，输出缓冲区占用大量内存），那么此时从库开始淘汰数据，主从库就会产生不一致。</li>\n</ul>\n<p>要想避免此问题，在调整 maxmemory 时，一定要注意主从库的修改顺序：</p>\n<p>调大 maxmemory：先修改从库，再修改主库</p>\n<p>调小 maxmemory：先修改主库，再修改从库</p>\n<p>直到 Redis 5.0，Redis 才增加了一个配置 replica-ignore-maxmemory，默认从库超过 maxmemory 不会淘汰数据，才解决了此问题</p>\n</li>\n</ul>\n<h2 id=\"预防-Redis-问题\"><a href=\"#预防-Redis-问题\" class=\"headerlink\" title=\"预防 Redis 问题\"></a>预防 Redis 问题</h2><ul>\n<li><h3 id=\"合理的资源规划\"><a href=\"#合理的资源规划\" class=\"headerlink\" title=\"合理的资源规划\"></a>合理的资源规划</h3><ul>\n<li>保证机器有足够的 CPU、内存、带宽、磁盘资源</li>\n<li>提前做好容量规划，主库机器预留一半内存资源，防止主从机器网络故障，引发大面积全量同步，导致主库机器内存不足的问题</li>\n<li>单个实例内存建议控制在 10G 以下，大实例在主从全量同步、RDB 备份时有阻塞风险</li>\n</ul>\n</li>\n<li><h3 id=\"完善的监控预警\"><a href=\"#完善的监控预警\" class=\"headerlink\" title=\"完善的监控预警\"></a>完善的监控预警</h3><ul>\n<li>做好机器 CPU、内存、带宽、磁盘监控，资源不足时及时报警，任意资源不足都会影响 Redis 性能</li>\n<li>设置合理的 slowlog 阈值，并对其进行监控，slowlog 过多及时报警</li>\n<li>监控组件采集 Redis INFO 信息时，采用长连接，避免频繁的短连接</li>\n<li>做好实例运行时监控，重点关注 expired_keys、evicted_keys、latest_fork_usec 指标，这些指标短时突增可能会有阻塞风险</li>\n</ul>\n<p>以上命令，应尽量避免传递 [0 -1] 或 [-inf +inf] 这样的参数，来对 Sorted Set 做一次性的完整遍历，特别是在 Sorted Set 的尺寸不可预知的情况下。可以通过 ZSCAN 命令来进行游标式的遍历，或通过 LIMIT 参数来限制返回 member 的数量（适用于 ZRANGEBYSCORE 和 ZREVRANGEBYSCORE 命令），以实现游标式的遍历</p>\n</li>\n</ul>\n<p> 时间复杂度为O(N)，N随着redis中key的数量增加而增加，因此redis有大量的key,keys命令会执行很长时间，而由于Redis是单线程，某个命令耗费过长时间，则会导致后面的的所有请求无法得到响应</p>\n<p> <img src=\"/img/202104/redis.svg\" alt=\"reids总结图\"></p>\n",
            "tags": [
                "redis",
                "redis总结",
                "redis命令"
            ]
        },
        {
            "id": "https://erik.xyz/2020/09/19/inux-doc-lists/",
            "url": "https://erik.xyz/2020/09/19/inux-doc-lists/",
            "title": "常用的Linux命令汇总",
            "date_published": "2020-09-19T03:32:00.000Z",
            "content_html": "<p>一.文件和目录</p>\n<p>1.<br>cd命令，用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径。</p>\n<pre><code>  cd /home    进入 &#39;/ home&#39; 目录\n  cd ..            返回上一级目录 \n  cd ../..         返回上两级目录 \n  cd               进入个人的主目录 \n  cd ~user1   进入个人的主目录 \n  cd -             返回上次所在的目录\n</code></pre><span id=\"more\"></span>\n<p>  2.<br>  pwd命令，显示工作路径</p>\n<pre><code>[erik@erik ~]# pwd\n/root\n</code></pre><p>3.<br>ls命令，查看文件与目录的命令，list之意</p>\n<pre><code>ls 查看目录中的文件 \nls -l 显示文件和目录的详细资料 \nls -a 列出全部文件，包含隐藏文件\nls -R 连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来  \nls [0-9] 显示包含数字的文件名和目录名\n</code></pre><p>4.<br>cp命令，用于复制文件，copy之意，它还可以把多个文件一次性地复制到一个目录下</p>\n<pre><code>-a ：将文件的特性一起复制\n-p ：连同文件的属性一起复制，而非使用默认方式，与-a相似，常用于备份\n-i ：若目标文件已经存在时，在覆盖时会先询问操作的进行\n-r ：递归持续复制，用于目录的复制行为 //经常使用递归复制\n-u ：目标文件与源文件有差异时才会复制\n</code></pre><p>5.<br>mv命令，用于移动文件、目录或更名，move之意</p>\n<pre><code>-f ：force强制的意思，如果目标文件已经存在，不会询问而直接覆盖\n-i ：若目标文件已经存在，就会询问是否覆盖\n-u ：若目标文件已经存在，且比目标文件新，才会更新\n</code></pre><p>6.<br>rm命令，用于删除文件或目录，remove之意</p>\n<pre><code>-f ：就是force的意思，忽略不存在的文件，不会出现警告消息\n-i ：互动模式，在删除前会询问用户是否操作\n-r ：递归删除，最常用于目录删除，它是一个非常危险的参数\n</code></pre><p>二、查看文件内容</p>\n<p>1.<br>cat命令，用于查看文本文件的内容，后接要查看的文件名，通常可用管道与more和less一起使用</p>\n<pre><code>cat file1 从第一个字节开始正向查看文件的内容 \ntac file1 从最后一行开始反向查看一个文件的内容 \ncat -n file1 标示文件的行数 \nmore file1 查看一个长文件的内容 \n\nhead -n 2 file1 查看一个文件的前两行 \ntail -n 2 file1 查看一个文件的最后两行 \ntail -n +1000 file1  从1000行开始显示，显示1000行以后的\ncat filename | head -n 3000 | tail -n +1000  显示1000行到3000行\ncat filename | tail -n +3000 | head -n 1000  从第3000行开始，显示1000(即显示3000~3999行) \n</code></pre><p>三.文件搜索</p>\n<p>1.<br>find命令，用来查找系统的</p>\n<pre><code>find / -name file1 从 &#39;/&#39; 开始进入根文件系统搜索文件和目录 \nfind / -user user1 搜索属于用户 &#39;user1&#39; 的文件和目录 \nfind /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件 \nfind /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件 \nwhereis halt 显示一个二进制文件、源码或man的位置 \nwhich halt 显示一个二进制文件或可执行文件的完整路径\n</code></pre><p>2.<br>删除大于50M的文件：</p>\n<pre><code>find /var/mail/ -size +50M -exec rm &#123;&#125; ＼;\n</code></pre><p>四.文件的权限 - 使用 “+” 设置权限，使用 “-“ 用于取消</p>\n<p>1.<br>chmod命令，改变文件/文件夹权限</p>\n<pre><code>ls -lh 显示权限 \nchmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r，4 ）、写(w，2)和执行(x，1)的权限 \nchmod go-rwx directory1  删除群组(g)与其他人(o)对目录的读写执行权限\n</code></pre><p>2.<br>chown命令，改变文件的所有者</p>\n<pre><code>chown user1 file1 改变一个文件的所有人属性 \nchown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性 \nchown user1:group1 file1 改变一个文件的所有人和群组属性\n</code></pre><p>3.<br>chgrp命令，改变文件所属用户组</p>\n<pre><code>chgrp group1 file1 改变文件的群组\n</code></pre><p>五.文本处理</p>\n<p>1.<br>grep命令，分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工等等</p>\n<pre><code>grep Aug /var/log/messages  在文件 &#39;/var/log/messages&#39;中查找关键词&quot;Aug&quot; \n\ngrep ^Aug /var/log/messages 在文件 &#39;/var/log/messages&#39;中查找以&quot;Aug&quot;开始的词汇 \ngrep [0-9]  /var/log/messages 选择 &#39;/var/log/messages&#39; 文件中所有包含数字的行 \n\ngrep Aug -R /var/log/* 在目录 &#39;/var/log&#39; 及随后的目录中搜索字符串&quot;Aug&quot; \n\nsed &#39;s/stringa1/stringa2/g&#39; example.txt 将example.txt文件中的 &quot;string1&quot; 替换成 &quot;string2&quot; \n\nsed &#39;/^$/d&#39; example.txt 从example.txt文件中删除所有空白行\n</code></pre><p>2.<br>paste命令</p>\n<pre><code>paste file1 file2 合并两个文件或两栏的内容 \npaste -d &#39;+&#39; file1 file2 合并两个文件或两栏的内容，中间用&quot;+&quot;区分\n</code></pre><p>3.<br>sort命令</p>\n<pre><code>sort file1 file2 排序两个文件的内容 \nsort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份) \nsort file1 file2 | uniq -u 删除交集，留下其他的行 \nsort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件)\n</code></pre><p>4.<br>comm命令</p>\n<pre><code>comm -1 file1 file2 比较两个文件的内容只删除 &#39;file1&#39; 所包含的内容 \ncomm -2 file1 file2 比较两个文件的内容只删除 &#39;file2&#39; 所包含的内容 \ncomm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分\n</code></pre><p>六、打包和压缩文件</p>\n<p>1.<br>tar命令，对文件进行打包，默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序（如gzip和bzip等）进行压缩和解压</p>\n<pre><code>-c ：新建打包文件\n-t ：查看打包文件的内容含有哪些文件名\n-x ：解打包或解压缩的功能，可以搭配-C（大写）指定解压的目录，注意-c,-t,-x不能同时出现在同一条命令中\n-j ：通过bzip2的支持进行压缩/解压缩\n-z ：通过gzip的支持进行压缩/解压缩\n-v ：在压缩/解压缩过程中，将正在处理的文件名显示出来\n-f filename ：filename为要处理的文件\n-C dir ：指定压缩/解压缩的目录dir\n</code></pre><p>2.<br>压缩：tar -jcv -f filename.tar.bz2 要被处理的文件或目录名称 查询：tar -jtv -f filename.tar.bz2 解压：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录</p>\n<pre><code>bunzip2 file1.bz2 解压一个叫做 &#39;file1.bz2&#39;的文件 \nbzip2 file1 压缩一个叫做 &#39;file1&#39; 的文件 \ngunzip file1.gz 解压一个叫做 &#39;file1.gz&#39;的文件 \ngzip file1 压缩一个叫做 &#39;file1&#39;的文件 \ngzip -9 file1 最大程度压缩 \nrar a file1.rar test_file 创建一个叫做 &#39;file1.rar&#39; 的包 \nrar a file1.rar file1 file2 dir1 同时压缩 &#39;file1&#39;, &#39;file2&#39; 以及目录 &#39;dir1&#39; \nrar x file1.rar 解压rar包\n\nzip file1.zip file1 创建一个zip格式的压缩包 \nunzip file1.zip 解压一个zip格式压缩包 \nzip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包\n</code></pre><p>七.系统和关机（关机、重启和登出）</p>\n<pre><code>shutdown -h now 关闭系统(1) \ninit 0 关闭系统(2) \ntelinit 0 关闭系统(3) \nshutdown -h hours:minutes &amp; 按预定时间关闭系统 \nshutdown -c 取消按预定时间关闭系统 \nshutdown -r now 重启(1) \nreboot 重启(2) \nlogout 注销 \ntime 测算一个命令（即程序）的执行时间 \n</code></pre><p>八、进程相关的命令</p>\n<p>1.<br>jps命令，显示当前系统的java进程情况，及其id号</p>\n<pre><code>jps(Java Virtual Machine Process Status Tool)是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/unix平台上简单察看当前java进程的一些简单情况。\n</code></pre><p>2.<br>ps命令，用于将某个时间点的进程运行情况选取下来并输出，process之意</p>\n<pre><code>-A ：所有的进程均显示出来\n-a ：不与terminal有关的所有进程\n-u ：有效用户的相关进程\n-x ：一般与a参数一起使用，可列出较完整的信息\n-l ：较长，较详细地将PID的信息列出\n\nps aux # 查看系统所有的进程数据\nps ax # 查看不与terminal有关的所有进程\nps -lA # 查看系统所有的进程数据\nps axjf # 查看连同一部分进程树状态\n</code></pre><p>3.<br>kill命令,用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号，它通常与ps和jobs命令一起使用</p>\n<p>命令格式 : kill[命令参数][进程id]</p>\n<p>命令参数:</p>\n<pre><code>-l  信号，若果不加信号的编号参数，则使用“-l”参数会列出全部的信号名称\n-a  当处理当前进程时，不限制命令名和进程号的对应关系\n-p  指定kill 命令只打印相关进程的进程号，而不发送任何信号\n-s  指定发送信号\n-u  指定用户\n</code></pre><p>实例1：列出所有信号名称 命令：kill -l 输出：</p>\n<pre><code>[root@localhost test6]# kill -l\n 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL\n 5) SIGTRAP      6) SIGABRT      7) SIGBUS       8) SIGFPE\n 9) SIGKILL     10) SIGUSR1     11) SIGSEGV     12) SIGUSR2\n13) SIGPIPE     14) SIGALRM     15) SIGTERM     16) SIGSTKFLT\n17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP\n21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU\n25) SIGXFSZ     26) SIGVTALRM   27) SIGPROF     28) SIGWINCH\n29) SIGIO       30) SIGPWR      31) SIGSYS      34) SIGRTMIN\n35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3  38) SIGRTMIN+4\n39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8\n43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12\n47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14\n51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10\n55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7  58) SIGRTMAX-6\n59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2\n63) SIGRTMAX-1  64) SIGRTMAX\n</code></pre><p>说明：</p>\n<p>只有第9种信号(SIGKILL)才可以无条件终止进程，其他信号进程都有权利忽略。 下面是常用的信号：</p>\n<pre><code>HUP    1    终端断线\nINT     2    中断（同 Ctrl + C）\nQUIT    3    退出（同 Ctrl + \\）\nTERM   15    终止\nKILL    9    强制终止\nCONT   18    继续（与STOP相反， fg/bg命令）\nSTOP    19    暂停（同 Ctrl + Z）\n</code></pre><p>实例2：得到指定信号的数值</p>\n<pre><code>[erik@erik ~]# kill -l KILL\n[erik@erik ~]# kill -l SIGKILL\n[erik@erik ~]# kill -l TERM\n[erik@erik ~]# kill -l SIGTERM\n[erik@erik ~]#\n</code></pre><p>实例3：先用ps查找进程，然后用kill杀掉</p>\n<p>命令：kill 3268</p>\n<pre><code>[erik@erik ~]# ps -ef|grep vim \nroot      3268  2884  0 16:21 pts/1    00:00:00 vim install.log\nroot      3370  2822  0 16:21 pts/0    00:00:00 grep vim\n[root@localhost test6]# kill 3268 \n</code></pre><p>实例4：彻底杀死进程</p>\n<pre><code>命令：kill –9 3268   // -9 强制杀掉进程\nkillall命令，向一个命令启动的进程发送一个信号，用于杀死指定名字的进程\n命令格式 : killall[命令参数][进程名]\n\n命令参数：\n-Z 只杀死拥有scontext 的进程\n-e 要求匹配进程名称\n-I 忽略小写\n-g 杀死进程组而不是进程\n-i 交互模式，杀死进程前先询问用户\n-l 列出所有的已知信号名称\n-q 不输出警告信息\n-s 发送指定的信号\n-v 报告信号是否成功发送\n-w 等待进程死亡\n--help 显示帮助信息\n--version 显示版本显示\n</code></pre><p>示例</p>\n<pre><code>1：杀死所有同名进程\n    killall nginx\n    killall -9 bash\n\n2.向进程发送指定信号\n    killall -TERM ngixn  或者  killall -KILL nginx\n</code></pre><ul>\n<li><p>top命令，是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。<br>如何杀死进程：</p>\n<ol>\n<li>图形化界面的方式</li>\n</ol>\n<ul>\n<li>kill -9 pid  （-9表示强制关闭）</li>\n<li>killall -9 程序的名字</li>\n<li>pkill 程序的名字</li>\n</ul>\n</li>\n</ul>\n<p>查看进程端口号：</p>\n<pre><code>netstat -tunlp|grep 端口号\n</code></pre><p>转载自：<a href=\"https://mp.weixin.qq.com/s/qItOvBZDMUnAi5wntMeaZg\">https://mp.weixin.qq.com/s/qItOvBZDMUnAi5wntMeaZg</a></p>\n",
            "tags": [
                "linux命令",
                "linux命令汇总"
            ]
        },
        {
            "id": "https://erik.xyz/2020/08/04/inux-delete-restore/",
            "url": "https://erik.xyz/2020/08/04/inux-delete-restore/",
            "title": "linux上恢复误删除的文件或目录",
            "date_published": "2020-08-04T03:23:00.000Z",
            "content_html": "<p>Linux不像windows有那么显眼的回收站，不是简单的还原就可以了。 linux删除文件还原可以分为两种情况，一种是删除以后在进程存在删除信息，一种是删除以后进程都找不到，只有借助于工具还原，这里分别检查介绍下。</p>\n<p>一、误删除文件进程还在的情况。</p>\n<p>这种一般是有活动的进程存在持续标准输入或输出，到时文件被删除后，进程PID还是存在。这也就是有些服务器删除一些文件但是磁盘不释放的原因。比如当前举例说明： 通过一个shell终端对一个测试文件做cat追加操作：<br><span id=\"more\"></span></p>\n<pre><code>[root@21yunwei_backup ~]# echo  &quot;hello  py&quot; &gt; testdelete.py\n\n[root@21yunwei_backup ~]# cat  &gt;&gt; testdelete.py \nhello delete\n</code></pre><p>另外一个终端查看这个文件可以清楚看到内容：</p>\n<pre><code>[root@21yunwei_backup ~]# cat testdelete.py \n\nhello  py\n\nhello delete\n</code></pre><p>此时，在当前服务器删除文件rm -f ./testdelete.py</p>\n<p>命令查看这个目录，文件已经不存在了，那么现在我们将其恢复出来。</p>\n<p>lsof查看删除的文件进程是否还存在。<br>这里用到一个命令lsof，如没有安装请自行yum或者apt-get。类似这种情况，我们可以先lsof查看删除的文件 是否还在：</p>\n<pre><code>[root@21yunwei_backup ~]# lsof | grep deleted\nmysqld     1512   mysql    5u      REG              252,3          0    6312397 /tmp/ibzW3Lot (deleted)\ncat       20464    root    1w      REG              252,3         23    1310722 /root/testdelete.py (deleted)\n</code></pre><p>幸运的是这种情况进程还存在 ，那么开始进行恢复 操作。</p>\n<p>恢复。<br>恢复命令：</p>\n<p>cp /proc/pid/fd/1 /指定目录/文件名</p>\n<p>进入 进程目录，一般是进入/proc/pid/fd/,针对当前情况：</p>\n<pre><code>[root@21yunwei_backup ~]# cd   /proc/20464/fd\n[root@21yunwei_backup fd]# ll\ntotal 0\nlrwx------ 1 root root 64 Nov 15 18:12 0 &gt; /dev/pts/1\nl-wx------ 1 root root 64 Nov 15 18:12 1 &gt; /root/testdelete.py (deleted)\nlrwx------ 1 root root 64 Nov 15 18:12 2 &gt; /dev/pts/1\n</code></pre><p>恢复操作：</p>\n<pre><code>cp 1 /tmp/testdelete.py\n</code></pre><p>查看文件：</p>\n<pre><code>[root@21yunwei_backup fd]# cat  /tmp/testdelete.py\nhello  py\nhello delete\n</code></pre><p>恢复完成。</p>\n<p>二、误删除的文件进程已经不存在，借助于工具还原。</p>\n<p>创建准备删除的目录并echo一个 带有内容的文件：</p>\n<pre><code>[root@21yunwei_backup 21yunwei]# tree\n.\n├── deletetest\n│   └── mail\n│       └── test.py\n├── lost+found\n└── passwd\n3 directories, 2 files\n[root@21yunwei_backup 21yunwei]# cat /21yunwei/deletetest/mail/test.py \nhello Dj\n[root@21yunwei_backup 21yunwei]# tail  -2  passwd \nhaproxy:x:500:502::/home/haproxy:/bin/bash\ntcpdump:x:72:72::/:/sbin/nologin\n</code></pre><p>执行删除操作：</p>\n<pre><code>[root@21yunwei_backup 21yunwei]# rm  -rf    ./*\n[root@21yunwei_backup 21yunwei]# ll\ntotal 0\n</code></pre><p>现在开始进行误删除文件的恢复。这种情况一般是没有守护进程或者后台进程对其持续输入，所以删除就删除了，lsof也看不到。就要借助于工具。这里我们采用的工具是extundelete第三方工具。恢复步骤如下：</p>\n<p>1.停止对当前分区做任何操作，防止inode被覆盖。inode被覆盖基本就告别恢复了。比如停止所在分区的服务，卸载目录所在的设备，有必要的情况下都可以断网。</p>\n<p>2.通过dd命令对当前分区进行备份，防止第三方软件恢复失败导致数据丢失。适合数据非常重要的情况，这里测试，就没有备份，如备份可以考虑如下方式：</p>\n<p>dd if=/path/filename of=/dev/vdc1</p>\n<p>1.通过umount命令，对当前设备分区卸载。或者fuser 命令。</p>\n<p>umount /dev/vdb1 或者 umount /21yunwei</p>\n<p>如果提示设备busy，可以用fuser命令强制卸载：</p>\n<p>fuser -m -v -i -k /21yunwei</p>\n<p>1.下载第三方工具extundelete安装，搜索误删除的文件进行还原。</p>\n<pre><code>wget  http://nchc.dl.sourceforge.net/project/extundelete/extundelete/0.2.4/extundelete-0.2.4.tar.bz2\ntar jxvf extundelete-0.2.4.tar.bz2\ncd  extundelete-0.2.4\n./configure \nmake\nmake  install\n</code></pre><p>扫描误删除的文件：</p>\n<pre><code>[root@21yunwei_backup extundelete-0.2.4]# extundelete  --inode 2 /dev/vdb1\nNOTICE: Extended attributes are not restored.\nLoading filesystem metadata ... 8 groups loaded.\nGroup: 0\nContents of inode 2:\n.\n.省略N行\nFile name                                       | Inode number | Deleted status\n.                                                 2\n..                                                2\nlost+found                                        11             Deleted\ndeletetest                                        12             Deleted\npasswd                                            14             Deleted\n</code></pre><p>通过扫描发现了我们删除的文件夹，现在执行恢复操作。</p>\n<p>1.恢复单一文件passwd</p>\n<pre><code>[root@21yunwei_backup /]# extundelete /dev/vdb1 --restore-file passwd   \nNOTICE: Extended attributes are not restored.\nLoading filesystem metadata ... 8 groups loaded.\nLoading journal descriptors ... 46 descriptors loaded.\nSuccessfully restored file passwd\n</code></pre><p>恢复文件是放到了当前目录RECOVERED_FILES。 查看恢复的文件：</p>\n<pre><code>[root@21yunwei_backup /]# tail  -5  RECOVERED_FILES/passwd \nmysql:x:497:500::/home/mysql:/bin/false\nnginx:x:496:501::/home/nginx:/sbin/nologin\nzabbix:x:495:497:Zabbix Monitoring System:/var/lib/zabbix:/sbin/nologin\nhaproxy:x:500:502::/home/haproxy:/bin/bash\ntcpdump:x:72:72::/:/sbin/nologin\n</code></pre><p>2.恢复目录deletetest</p>\n<pre><code>[root@21yunwei_backup /]# extundelete /dev/vdb1 --restore-directory  deletetest \nNOTICE: Extended attributes are not restored.\nLoading filesystem metadata ... 8 groups loaded.\nLoading journal descriptors ... 46 descriptors loaded.\nSearching for recoverable inodes in directory deletetest ... \n5 recoverable inodes found.\nLooking through the directory structure for deleted files ... \n[root@21yunwei_backup /]# cat  RECOVERED_FILES/deletetest/mail/test.py \nhello Dj\n</code></pre><p>3.恢复所有</p>\n<pre><code>[root@21yunwei_backup /]# extundelete /dev/vdb1 --restore-all\nNOTICE: Extended attributes are not restored.\nLoading filesystem metadata ... 8 groups loaded.\nLoading journal descriptors ... 46 descriptors loaded.\nSearching for recoverable inodes in directory / ... \n5 recoverable inodes found.\nLooking through the directory structure for deleted files ... \n0 recoverable inodes still lost. \n[root@21yunwei_backup /]# cd RECOVERED_FILES/\n[root@21yunwei_backup RECOVERED_FILES]# tree\n.\n├── deletetest\n│   └── mail\n│       └── test.py\n└── passwd\n2 directories, 2 files\n</code></pre><p>4.恢复指定inode</p>\n<pre><code>[root@21yunwei_backup /]# extundelete /dev/vdb1 --restore-inode 14\nNOTICE: Extended attributes are not restored.\nLoading filesystem metadata ... 8 groups loaded.\nLoading journal descriptors ... 46 descriptors loaded.\n[root@21yunwei_backup /]# tail  -5   /RECOVERED_FILES/file.14 \nmysql:x:497:500::/home/mysql:/bin/false\nnginx:x:496:501::/home/nginx:/sbin/nologin\nzabbix:x:495:497:Zabbix Monitoring System:/var/lib/zabbix:/sbin/nologin\nhaproxy:x:500:502::/home/haproxy:/bin/bash\ntcpdump:x:72:72::/:/sbin/nologin\n</code></pre><p>注意恢复inode的时候，恢复 出来的文件名和之前不一样，需要单独进行改名。内容是没问题的。</p>\n<p>更多的extundelete用法请参考extundelete –help选项参数说明，当前恢复所有的操作完成。</p>\n",
            "tags": [
                "linux恢复",
                "linux误删"
            ]
        },
        {
            "id": "https://erik.xyz/2020/05/07/elasticsearch-node/",
            "url": "https://erik.xyz/2020/05/07/elasticsearch-node/",
            "title": "linux系统里elasticsearch集群搭建",
            "date_published": "2020-05-07T03:43:00.000Z",
            "content_html": "<h2 id=\"1-在容器中搜索elasticsearch镜像-如图结果，一般选择最上面的一个。\"><a href=\"#1-在容器中搜索elasticsearch镜像-如图结果，一般选择最上面的一个。\" class=\"headerlink\" title=\"1.在容器中搜索elasticsearch镜像,如图结果，一般选择最上面的一个。\"></a>1.在容器中搜索elasticsearch镜像,如图结果，一般选择最上面的一个。</h2><pre><code>    sudo docker search elasticsearch\n</code></pre><p><img src=\"https://erik.xyz/img/202005/07/2020-05-07_114446.jpg\" alt=\"&#39;es图&#39;\"></p>\n<span id=\"more\"></span>\n<h2 id=\"2-到elasticsearch官方网站查询elasticsearch的版本，我用的是最新版7-6-2\"><a href=\"#2-到elasticsearch官方网站查询elasticsearch的版本，我用的是最新版7-6-2\" class=\"headerlink\" title=\"2.到elasticsearch官方网站查询elasticsearch的版本，我用的是最新版7.6.2\"></a>2.到elasticsearch官方网站查询elasticsearch的版本，我用的是最新版7.6.2</h2><h2 id=\"3-拉镜像到本地\"><a href=\"#3-拉镜像到本地\" class=\"headerlink\" title=\"3.拉镜像到本地\"></a>3.拉镜像到本地</h2><pre><code>    sudo docker pull elasticsearch:7.6.2\n</code></pre><h2 id=\"4-查看本地镜像，找到elasticsearch，如下图\"><a href=\"#4-查看本地镜像，找到elasticsearch，如下图\" class=\"headerlink\" title=\"4.查看本地镜像，找到elasticsearch，如下图\"></a>4.查看本地镜像，找到elasticsearch，如下图</h2><pre><code>    sudo docker images\n</code></pre><p><img src=\"https://erik.xyz/img/202005/07/2020-05-07_115053.jpg\" alt=\"&#39;es图&#39;\"></p>\n<h2 id=\"5-创建挂载本地目录\"><a href=\"#5-创建挂载本地目录\" class=\"headerlink\" title=\"5.创建挂载本地目录\"></a>5.创建挂载本地目录</h2><pre><code>mkdir -p es/node1 es/node2 es/node3 &amp;&amp; mkdir es/node1/config es/node1/data es/node1/log es/node1/plugins es/node2/config es/node2/data es/node2/log es/node2/plugins es/node3/config es/node3/data es/node3/log es/node3/plugins\n</code></pre><p>config存放配置文件</p>\n<p>data存放数据</p>\n<p>log存放日志</p>\n<p>plugins存放插件</p>\n<p>给目录开放读写权限</p>\n<pre><code>    sudo chmod -R 777 es/node1 es/node2 es/node3\n</code></pre><h2 id=\"6-创建配置文件\"><a href=\"#6-创建配置文件\" class=\"headerlink\" title=\"6.创建配置文件\"></a>6.创建配置文件</h2><ul>\n<li><p>node1的配置文件  es/node1/config/config.yml</p>\n<pre><code>#集群名称\ncluster.name: erik-es\n#当前该节点的名称\nnode.name: node1\n#是不是有资格竞选主节点\nnode.master: true\n#是否存储数据\nnode.data: true\n#最大集群节点数\nnode.max_local_storage_nodes: 3\n#给当前节点自定义属性（可以省略）\n#node.attr.rack: r1\n#数据存档位置\npath.data: /usr/share/elasticsearch/data\n#日志存放位置\npath.logs: /usr/share/elasticsearch/log\n#是否开启时锁定内存（默认为是）\n#bootstrap.memory_lock: true\n#设置网关地址，我是被这个坑死了，这个地址我原先填写了自己的实际物理IP地址，\n#然后启动一直报无效的IP地址，无法注入9300端口，这里只需要填写0.0.0.0\nnetwork.host: 0.0.0.0\n#设置其它结点和该结点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址，设置当前物理机地址,\n#如果是docker安装节点的IP将会是配置的IP而不是docker网管ip\nnetwork.publish_host: 172.18.0.2\n#设置映射端口\nhttp.port: 9200\n#内部节点之间沟通端口\ntransport.tcp.port: 9300\n#集群发现默认值为127.0.0.1:9300,如果要在其他主机上形成包含节点的群集,如果搭建集群则需要填写\n#es7.x 之后新增的配置，写入候选主节点的设备地址，在开启服务后可以被选为主节点，也就是说把所有的节点都写上\ndiscovery.seed_hosts: [&quot;172.18.0.2:9300&quot;,&quot;172.18.0.3:9301&quot;,&quot;172.18.0.4:9302&quot;]\n#当你在搭建集群的时候，选出合格的节点集群，有些人说的太官方了，\n#其实就是，让你选择比较好的几个节点，在你节点启动时，在这些节点中选一个做领导者，\n#如果你不设置呢，elasticsearch就会自己选举，这里我们把三个节点都写上\ncluster.initial_master_nodes: [&quot;node1&quot;,&quot;node2&quot;,&quot;node3&quot;]\n#在群集完全重新启动后阻止初始恢复，直到启动N个节点\n#简单点说在集群启动后，至少复活多少个节点以上，那么这个服务才可以被使用，否则不可以被使用，\ngateway.recover_after_nodes: 2\n#删除索引是是否需要显示其名称，默认为显示\n#action.destructive_requires_name: true\n</code></pre></li>\n<li><p>node2的配置文件  es/node2/config/config.yml</p>\n<pre><code>  #集群名称\n  cluster.name: erik-es\n  #当前该节点的名称\n  node.name: node2\n  #是不是有资格竞选主节点\n  node.master: true\n  #是否存储数据\n  node.data: true\n  #最大集群节点数\n  node.max_local_storage_nodes: 3\n  #给当前节点自定义属性（可以省略）\n  #node.attr.rack: r1\n  #数据存档位置\n  path.data: /usr/share/elasticsearch/data\n  #日志存放位置\n  path.logs: /usr/share/elasticsearch/log\n  #是否开启时锁定内存（默认为是）\n  #bootstrap.memory_lock: true\n  #设置网关地址，我是被这个坑死了，这个地址我原先填写了自己的实际物理IP地址，\n  #然后启动一直报无效的IP地址，无法注入9300端口，这里只需要填写0.0.0.0\n  network.host: 0.0.0.0\n  #设置其它结点和该结点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址，设置当前物理机地址,\n  #如果是docker安装节点的IP将会是配置的IP而不是docker网管ip\n  network.publish_host: 172.18.0.3\n  #设置映射端口\n  http.port: 9201\n  #内部节点之间沟通端口\n  transport.tcp.port: 9301\n  #集群发现默认值为127.0.0.1:9300,如果要在其他主机上形成包含节点的群集,如果搭建集群则需要填写\n  #es7.x 之后新增的配置，写入候选主节点的设备地址，在开启服务后可以被选为主节点，也就是说把所有的节点都写上\n  discovery.seed_hosts: [&quot;172.18.0.2:9300&quot;,&quot;172.18.0.3:9301&quot;,&quot;172.18.0.4:9302&quot;]\n  #当你在搭建集群的时候，选出合格的节点集群，有些人说的太官方了，\n  #其实就是，让你选择比较好的几个节点，在你节点启动时，在这些节点中选一个做领导者，\n  #如果你不设置呢，elasticsearch就会自己选举，这里我们把三个节点都写上\n  cluster.initial_master_nodes: [&quot;node1&quot;,&quot;node2&quot;,&quot;node3&quot;]\n  #在群集完全重新启动后阻止初始恢复，直到启动N个节点\n  #简单点说在集群启动后，至少复活多少个节点以上，那么这个服务才可以被使用，否则不可以被使用，\n  gateway.recover_after_nodes: 2\n  #删除索引是是否需要显示其名称，默认为显示\n  #action.destructive_requires_name: true\n</code></pre></li>\n<li><p>node3的配置文件  es/node3/config/config.yml</p>\n<pre><code>  #集群名称\n  cluster.name: erik-es\n  #当前该节点的名称\n  node.name: node3\n  #是不是有资格竞选主节点\n  node.master: true\n  #是否存储数据\n  node.data: true\n  #最大集群节点数\n  node.max_local_storage_nodes: 3\n  #给当前节点自定义属性（可以省略）\n  #node.attr.rack: r1\n  #数据存档位置\n  path.data: /usr/share/elasticsearch/data\n  #日志存放位置\n  path.logs: /usr/share/elasticsearch/log\n  #是否开启时锁定内存（默认为是）\n  #bootstrap.memory_lock: true\n  #设置网关地址，我是被这个坑死了，这个地址我原先填写了自己的实际物理IP地址，\n  #然后启动一直报无效的IP地址，无法注入9300端口，这里只需要填写0.0.0.0\n  network.host: 0.0.0.0\n  #设置其它结点和该结点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址，设置当前物理机地址,\n  #如果是docker安装节点的IP将会是配置的IP而不是docker网管ip\n  network.publish_host: 172.18.0.4\n  #设置映射端口\n  http.port: 9202\n  #内部节点之间沟通端口\n  transport.tcp.port: 9302\n  #集群发现默认值为127.0.0.1:9300,如果要在其他主机上形成包含节点的群集,如果搭建集群则需要填写\n  #es7.x 之后新增的配置，写入候选主节点的设备地址，在开启服务后可以被选为主节点，也就是说把所有的节点都写上\n  discovery.seed_hosts: [&quot;172.18.0.2:9300&quot;,&quot;172.18.0.3:9301&quot;,&quot;172.18.0.4:9302&quot;]\n  #当你在搭建集群的时候，选出合格的节点集群，有些人说的太官方了，\n  #其实就是，让你选择比较好的几个节点，在你节点启动时，在这些节点中选一个做领导者，\n  #如果你不设置呢，elasticsearch就会自己选举，这里我们把三个节点都写上\n  cluster.initial_master_nodes: [&quot;node1&quot;,&quot;node2&quot;,&quot;node3&quot;]\n  #在群集完全重新启动后阻止初始恢复，直到启动N个节点\n  #简单点说在集群启动后，至少复活多少个节点以上，那么这个服务才可以被使用，否则不可以被使用，\n  gateway.recover_after_nodes: 2\n  #删除索引是是否需要显示其名称，默认为显示\n  #action.destructive_requires_name: true\n</code></pre></li>\n</ul>\n<h2 id=\"7-创建网络\"><a href=\"#7-创建网络\" class=\"headerlink\" title=\"7.创建网络\"></a>7.创建网络</h2><p>如果需要安装kibana等其他，需要创建一个网络，名字任意取，让他们在同一个网络，使得elasticsearch和kibana通信，网络名称可以自定义</p>\n<pre><code>sudo docker network create es-net\n</code></pre><p> 查看已创建的网络，如下图</p>\n<pre><code>    sudo docker network ls\n</code></pre><p><img src=\"https://erik.xyz/img/202005/07/2020-05-07_125720.jpg\" alt=\"\"></p>\n<h2 id=\"8-创建节点\"><a href=\"#8-创建节点\" class=\"headerlink\" title=\"8.创建节点\"></a>8.创建节点</h2><ul>\n<li><p>node1</p>\n<pre><code>    sudo docker run --privileged -ti -e ES_JAVA_OPTS=&quot;-Xms512m -Xmx512m&quot; --network es-net -d -p 9200:9200 -p 9300:9300 -v /home/project/es/node1/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /home/project/es/node1/plugins:/usr/share/elasticsearch/plugins -v /home/project/es/node1/data:/usr/share/elasticsearch/data -v /home/project/es/node1/log:/usr/share/elasticsearch/log --name es-node1 elasticsearch:7.6.2\n</code></pre><p>这时候你会发现过会容器节点es-node1自动停止了。查查容器日志，如下<br><img src=\"https://erik.xyz/img/202005/07/2020-05-07_133110.jpg\" alt=\"\"></p>\n<p>本地系统最大虚拟值太小，一般就是本地没有设置，而用了默认的，打开</p>\n<pre><code>    sudo leafpad  /etc/sysctl.conf\n</code></pre><p>在sysctl.conf中找找vm.max_map_count，如果找不到就添加vm.max_map_count=262144<br>退出编辑，执行加载</p>\n<pre><code>    sudo sysctl -p\n</code></pre><p>重新启动es-node1</p>\n<p>查询此时容器es-node1的IP地址</p>\n<pre><code>    sudo docker inspect es-node1 | grep &#39;&quot;IPAddress&quot;&#39;\n</code></pre><p>然后更改es-node1配置文件中的network.publish_host和discovery.seed_hostsd地址，其他两个节点也是如此。</p>\n</li>\n<li><p>node2</p>\n<pre><code>sudo docker run --privileged -ti -e ES_JAVA_OPTS=&quot;-Xms512m -Xmx512m&quot; --network es-net -d -p 9201:9201 -p 9301:9301 -v /home/project/es/node2/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /home/project/es/node2/plugins:/usr/share/elasticsearch/plugins -v /home/project/es/node2/data:/usr/share/elasticsearch/data -v /home/project/es/node2/log:/usr/share/elasticsearch/log --name es-node2 elasticsearch:7.6.2\n</code></pre></li>\n</ul>\n<p>改配置ip同node1</p>\n<ul>\n<li><p>node3</p>\n<pre><code>sudo docker run --privileged -ti -e ES_JAVA_OPTS=&quot;-Xms512m -Xmx512m&quot; --network es-net -d -p 9202:9202 -p 9302:9302 -v /home/project/es/node3/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /home/project/es/node3/plugins:/usr/share/elasticsearch/plugins -v /home/project/es/node3/data:/usr/share/elasticsearch/data -v /home/project/es/node3/log:/usr/share/elasticsearch/log --name es-node3 elasticsearch:7.6.2\n</code></pre></li>\n</ul>\n<p>改配置ip同node1</p>\n<p>修改完所有节点的配置文件后记得重启所有节点。</p>\n<h2 id=\"9-测试结果\"><a href=\"#9-测试结果\" class=\"headerlink\" title=\"9.测试结果\"></a>9.测试结果</h2><p>在浏览器端输入（ip是我本地的）<a href=\"http://172.18.0.2:9200/_cat/nodes?pretty\">http://172.18.0.2:9200/_cat/nodes?pretty</a><br>展示如下图</p>\n<p><img src=\"https://erik.xyz/img/202005/07/2020-05-07_140004.jpg\" alt=\"\"></p>\n<p>表示成功</p>\n<h2 id=\"10-安装Kibana\"><a href=\"#10-安装Kibana\" class=\"headerlink\" title=\"10.安装Kibana\"></a>10.安装Kibana</h2><p>在docker中拉取Kibana</p>\n<pre><code>sudo docker pull kibana:7.6.2\n</code></pre><p>创建kibana目录，并添加文件</p>\n<pre><code>    sudo chmod -R 777 kibana/config\n\n    leafpad kibana/config/kibana.yml\n</code></pre><p>配置文件内容</p>\n<pre><code>#Kibana的映射端口\nserver.port: 5601\n\n#网关地址\nserver.host: &quot;0.0.0.0&quot;\n\n#Kibana实例对外展示的名称\nserver.name: &quot;kibana-192.168.31.190&quot;\n\n#Elasticsearch的集群地址，也就是说所有的集群IP\nelasticsearch.hosts: [&quot;http://172.18.0.2:9200&quot;,&quot;http://172.18.0.3:9201&quot;,&quot;http://172.18.0.4:9202&quot;]\n\n#设置页面语言，中文使用zh-CN，英文使用en\ni18n.locale: &quot;zh-CN&quot;\n\n#这个配置还没理解清楚………………\nxpack.monitoring.ui.container.elasticsearch.enabled: true\n</code></pre><p>安装容器</p>\n<pre><code>sudo docker run --privileged -ti -d -p 5601:5601 -v /home/project/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml --network es-net --name kibana kibana:7.6.2\n</code></pre><p>成功后在浏览器输入地址（第一次启动会比较慢）<a href=\"http://127.0.0.1:5601，展示如下图\">http://127.0.0.1:5601，展示如下图</a></p>\n<p><img src=\"https://erik.xyz/img/202005/07/2020-05-07_142240.jpg\" alt=\"\"></p>\n<p>参考文章：<a href=\"https://blog.csdn.net/gfk3009/article/details/104560431/\">https://blog.csdn.net/gfk3009/article/details/104560431/</a></p>\n",
            "tags": [
                "elasticsearch",
                "elasticsearch搭建",
                "elasticsearch集群"
            ]
        },
        {
            "id": "https://erik.xyz/2020/03/26/openresty-desc/",
            "url": "https://erik.xyz/2020/03/26/openresty-desc/",
            "title": "openresty的介绍",
            "date_published": "2020-03-25T17:56:00.000Z",
            "content_html": "<p>今天给一家公司投简历，问我用过openresty没，确实没用过，回答后没结果了。这就查了查。</p>\n<p>官方介绍如下：</p>\n<pre><code>        OpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。\n\nOpenResty® 通过汇聚各种设计精良的 Nginx 模块（主要由 OpenResty 团队自主开发），从而将 Nginx 有效地变成一个强大的通用 Web 应用平台。这样，Web 开发人员和系统工程师可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块，快速构造出足以胜任 10K 乃至 1000K 以上单机并发连接的高性能 Web 应用系统。\n\nOpenResty® 的目标是让你的Web服务直接跑在 Nginx 服务内部，充分利用 Nginx 的非阻塞 I/O 模型，不仅仅对 HTTP 客户端请求,甚至于对远程后端诸如 MySQL、PostgreSQL、Memcached 以及 Redis 等都进行一致的高性能响应。\n</code></pre>  <span id=\"more\"></span>\n<p>  另外还有一篇博客专门介绍了一下<a href=\"https://blog.openresty.com.cn/cn/how-or-alloc-mem\">OpenResty 和 Nginx 如何分配和管理内存</a></p>\n<p>  因为我用的是kali在官方提供的方法里安装源不支持，只能用包编译安装。</p>\n<p>  这里是下载不同系统和不同版本的页面 <a href=\"https://openresty.org/cn/download.html\">openresty</a><br>  <img src=\"https://erik.xyz/img/202003/2020-03-26_020859.jpg\" alt=\"版本图片\"></p>\n<p>  源配置教程 <a href=\"https://openresty.org/en/linux-packages.html\">openresty</a></p>\n<p>  <img src=\"https://erik.xyz/img/202003/yum.jpg\" alt=\"源图片\"></p>\n<p>  我<a href=\"https://openresty.org/download/openresty-1.15.8.3.tar.gz\">下载</a>的编译包</p>\n<p>  解压，后进入目录,执行如下命令（参数根据自己需要来添加）</p>\n<pre><code>      ./configure --prefix=/opt/openresty --with-pcre-jit --with-ipv6 --without-http_redis2_module --with-http_iconv_module --with-http_postgres_module -j8 --with-luajit\n</code></pre><p>然后执行</p>\n<ul>\n<li><p>如果电脑支持多核 make 工作的特性就用</p>\n<pre><code>   make j2\n</code></pre></li>\n<li><p>否则用</p>\n<pre><code>   make\n</code></pre></li>\n</ul>\n<p>以上执行完毕后，执行</p>\n<pre><code>sudo make install\n</code></pre><p>然后测试是否安装成功</p>\n<p>在任意目录创建work文件</p>\n<p>我是在/home/project/下创建文件work，并在work文件中创建conf和logs文件</p>\n<p>然后，在conf目录创建nginx.conf，并放入一下代码</p>\n<pre><code>  worker_processes  1;\n  error_log logs/error.log;\n  events &#123;\n      worker_connections 1024;\n  &#125;\n  http &#123;\n      server &#123;\n          listen 8080;\n          location / &#123;\n              default_type text/html;\n              content_by_lua_block &#123;\n                  ngx.say(&quot;&lt;p&gt;https://erik.xyz&lt;/p&gt;&quot;)\n              &#125;\n          &#125;\n      &#125;\n  &#125;\n</code></pre><p>根据我的安装在work目录下，执行：/opt/openresty/nginx/sbin/nginx -p `pwd`/ -c conf/nginx.conf</p>\n<p>启动nginx，然后浏览器或者用curl命令访问本地8080端口，就可以看到定义好输出的网址。</p>\n",
            "tags": [
                "服务器",
                "openresty"
            ]
        },
        {
            "id": "https://erik.xyz/2019/09/16/dai-li-fu-wu-qi-da-jian/",
            "url": "https://erik.xyz/2019/09/16/dai-li-fu-wu-qi-da-jian/",
            "title": "代理服务搭建",
            "date_published": "2019-09-16T07:53:00.000Z",
            "content_html": "<p>代理服务器（Proxy）主要是用户有因特网数据要求时，Proxy会帮用户去向目的地取得用户所需要的数据。</p>\n<h5 id=\"Proxy获取信息的工作流程\"><a href=\"#Proxy获取信息的工作流程\" class=\"headerlink\" title=\"Proxy获取信息的工作流程\"></a>Proxy获取信息的工作流程</h5><ul>\n<li>当Proxy的缓存拥有用户所想要的数据时<ul>\n<li>Client端向Server端发送一个数据需求数据包。</li>\n<li>Server端接收后，先比对这个数据包的来源与预计要前往的目标网站是否为可接受？如果来源与目标合法，或者说，来源与目标网站Proxy都能帮忙取得数据时，那么Server端会开始替Client取得数据。</li>\n<li>Server首先会检查自己缓存数据，如果有Client所需的数据，那就将数据取出，而不经过向Internet要求数据的程序。</li>\n<li>最后将数据发送给Client端。<span id=\"more\"></span></li>\n</ul>\n</li>\n<li>当Proxy的缓存没有用户所想要的数据时<ul>\n<li>Client端向Server端发送一个数据需求数据包。</li>\n<li>Server端接收后，开始进行数据比对。</li>\n<li>Server发现缓存并没有Client所需要的数据时，准备前往因特网获取数据。</li>\n<li>Server开始向Internet发送要求与取得相关数据。</li>\n<li>最后将数据回送给Client端。</li>\n</ul>\n</li>\n</ul>\n <font color=\"red\">\n 注意：Proxy对于Cache的速度要求是很高的，而这个Cache就是硬盘。当然，硬盘容量必须要足够大，而且还有足够快。\n  </font>\n\n\n<p> Proxy服务器可以作为上层代理，起到一定的分流作用。目前大部分Proxy已经停止对外开，仅针对自己网段内的用户提供服务。如果要自行设置Proxy，需要到当初申请的ISP搜寻一下，才能有效的设置好服务器。否则，设置错误的话，上层Proxy根本不提供服务。</p>\n<h5 id=\"代理服务器与NAT服务器的差异\"><a href=\"#代理服务器与NAT服务器的差异\" class=\"headerlink\" title=\"代理服务器与NAT服务器的差异\"></a>代理服务器与NAT服务器的差异</h5><ul>\n<li><p>NAT服务器的功能</p>\n<pre><code>NAT的主要功能是通过数据包过滤的方式，并使用iptables的nat表格进行IP伪装（SNAT），让客户端自行前往因特网上的任何地方的一种方式。主要的运作行为是在OSI七层协议的二、三、四层。由于是通过数据包过滤与伪装，因此客户端可以使用的端口号码（第四层）弹性较大。\n</code></pre></li>\n<li><p>Proxy服务器的功能</p>\n<pre><code>  通过Proxy的服务程序（daemon）提供网络代理的任务，因此Proxy能不能进项某些工作，与该服务的程序功能有关。\n</code></pre></li>\n</ul>\n<p>由上可知：NAT服务器是由较底层的网络去进行分析的工作。Proxy则主要是由一个daemon的功能实现的，所以必须要符合该daemon的需求，才能实现某些功能。</p>\n<h5 id=\"搭建代理服务器的用途与优缺点\"><a href=\"#搭建代理服务器的用途与优缺点\" class=\"headerlink\" title=\"搭建代理服务器的用途与优缺点\"></a>搭建代理服务器的用途与优缺点</h5><ul>\n<li><p>用途</p>\n<ul>\n<li>作为WWW的网页数据获取代理人。</li>\n<li>作为内部局域网的单点对外防火墙系统。</li>\n</ul>\n</li>\n<li><p>优点</p>\n<ul>\n<li>节省单点对外的宽带网络，降低网络负载。</li>\n<li>以较短的路径取得网络数据，有网络加速的感觉。</li>\n<li>通过上层代理服务器的辅助，达到自动数据分流的效果。</li>\n<li>提供防火墙内部的计算机连上Internet。</li>\n</ul>\n<font color=\"red\">\n注：如果是连接国外的网页，一定要使用ISP提供的代理服务器来帮忙，因为不但可以节省宽带，并且速度上会快上很多很多。\n</font>\n\n\n</li>\n</ul>\n<ul>\n<li>缺点<ul>\n<li>容易被内部局域网的人员滥用。</li>\n<li>需要较高的配置技巧与排错程序。</li>\n<li>可能会取得旧的错误数据。</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"架设代理服务器的条件\"><a href=\"#架设代理服务器的条件\" class=\"headerlink\" title=\"架设代理服务器的条件\"></a>架设代理服务器的条件</h5><ul>\n<li>Client端用户不少，而且大部分仅需要WWW这个网路服务而已。</li>\n<li>Proxy还兼做防火墙的任务</li>\n<li>Client端常常需要连接到传输速度很慢的网站。</li>\n<li>Client端常常浏览的网站是静态网站，而不是动态网站</li>\n</ul>\n<h5 id=\"Proxy搭建\"><a href=\"#Proxy搭建\" class=\"headerlink\" title=\"Proxy搭建\"></a>Proxy搭建</h5><ol>\n<li><p>在centos中我用squid软件，在命令窗口执行安装</p>\n<pre><code> yum install squid\n</code></pre></li>\n<li><p>进入squid的配置目录（/etc/squid/）可以看到有以下配置文件<br><img src=\"/img/201909/2019-09-16_165357.jpg\" alt=\"配置文件目录\"></p>\n<p> squid.conf是主要配置文件，所有squid需要的设置都是放在这个文件当中的</p>\n<p> mime.conf是设置squid支持Internet上面的文件格式，默认配置就够了，一般不需要更改。</p>\n<p> /usr/sbin/squid  提供squid的主程序</p>\n<p> /var/spool/squid  默认的squid缓存存储目录</p>\n<p> /usr/lib64/squid 提供squid额外的控制模块</p>\n</li>\n<li><p>在centos中默认的squid特色</p>\n<ul>\n<li>仅有本机来源可以使用这个squid功能。</li>\n<li>squid所监听的Proxy服务端口在port 3128。</li>\n<li>缓存目录所在的位置在/var/spool/squid/，且仅有100MB的磁盘高速缓存量。</li>\n<li>除了squid程序所需要的基本内存之外，尚提供8MB的内存来给热门文件缓存在内存中。</li>\n<li>默认启动squid程序的用户为squid这个账号。</li>\n</ul>\n</li>\n<li><p>squid.conf配置文件</p>\n<pre><code>     #\n     # Recommended minimum configuration:\n     #\n\n     # Example rule allowing access from your local networks.\n     # Adapt to list your (internal) IP networks from where browsing\n     # should be allowed\n     # 信任用户与目标控制，定义可能使用proxy的外部用户（内网）\n     acl localnet src 10.0.0.0/8    # RFC1918 possible internal network\n     acl localnet src 172.16.0.0/12    # RFC1918 possible internal network\n     acl localnet src 192.168.0.0/16    # RFC1918 possible internal network\n     acl localnet src fc00::/7       # RFC 4193 local private network range\n     acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines\n\n     # 定义可取得的数据端口\n     acl SSL_ports port 443\n     acl Safe_ports port 80        # http\n     acl Safe_ports port 21        # ftp\n     acl Safe_ports port 443        # https\n     acl Safe_ports port 70        # gopher\n     acl Safe_ports port 210        # wais\n     acl Safe_ports port 1025-65535    # unregistered ports\n     acl Safe_ports port 280        # http-mgmt\n     acl Safe_ports port 488        # gss-http\n     acl Safe_ports port 591        # filemaker\n     acl Safe_ports port 777        # multiling http\n     acl CONNECT method CONNECT\n\n     #\n     # Recommended minimum Access Permission configuration:\n     #\n     # Deny requests to certain unsafe ports \n     # 拒绝非正规的端口连接要求\n     http_access deny !Safe_ports \n\n     # Deny CONNECT to other than secure SSL ports \n     # 拒绝非正规的加密端口连接要求\n     http_access deny CONNECT !SSL_ports\n\n     # Only allow cachemgr access from localhost\n     # 放行管理本机的功能\n     http_access allow localhost manager\n\n     # 其他管理来源都予以拒绝\n     http_access deny manager\n\n     # We strongly recommend the following be uncommented to protect innocent\n     # web applications running on the proxy server who think the only\n     # one who can access services on &quot;localhost&quot; is a local user\n     #http_access deny to_localhost\n\n     #\n     # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS\n     #\n\n     # Example rule allowing access from your local networks.\n     # Adapt localnet in the ACL section to list your (internal) IP networks\n     # from where browsing should be allowed\n     # 放行内部网络的用户来源\n     http_access allow localnet\n\n     # 放行本机的使用\n     http_access allow localhost\n\n     auth_param basic program /usr/lib64/squid/basic_ncsa_auth /etc/squid/passwd \n     auth_param basic children 5 \n     auth_param basic realm hehe \n     auth_param basic credentialsttl 2 hours \n     acl myproxy proxy_auth REQUIRED \n     http_access allow myproxy \n\n     # And finally deny all other access to this proxy\n     # 全部予以拒绝\n     http_access deny all\n\n     # Squid normally listens to port 3128\n     # 默认监听客户端要求的端口\n     http_port 3128\n\n     # Uncomment and adjust the following to add a disk cache directory.\n     # 磁盘高速缓存，即放置缓存数据的目录所在与相关设置\n     cache_dir ufs /var/spool/squid 100 16 256\n\n     # Leave coredumps in the first cache dir\n     coredump_dir /var/spool/squid\n\n     #隐藏真实IP变成匿名ip\n     via off \n     forwarded_for delete \n     #\n     # Add any of your own refresh_pattern entries above these.\n     #\n     refresh_pattern ^ftp:        1440    20%    10080\n     refresh_pattern ^gopher:    1440    0%    1440\n     refresh_pattern -i (/cgi-bin/|\\?) 0    0%    0\n     refresh_pattern .        0    20%    4320\n</code></pre></li>\n</ol>\n<p>以上配置好后关闭squid</p>\n<pre><code>systemctl stop squid.service \n</code></pre><p>执行初始化缓存</p>\n<pre><code>squid -z\n</code></pre><p>启动squid</p>\n<pre><code>systemctl start squid.service \n</code></pre><p>squid加入开机启动</p>\n<pre><code>systemctl enable squid.service \n</code></pre><p>需要添加密码认证的就不做介绍了，如果想验证是否成功，可以通过浏览器代理或者本地代理验证操作。</p>\n",
            "tags": [
                "proxy代理搭建",
                "代理服务器搭建",
                "proxy服务器"
            ]
        },
        {
            "id": "https://erik.xyz/2019/06/18/kali-zhuo-mian-you-jian-han-hua/",
            "url": "https://erik.xyz/2019/06/18/kali-zhuo-mian-you-jian-han-hua/",
            "title": "kali桌面右键汉化",
            "date_published": "2019-06-18T04:28:00.000Z",
            "content_html": "<p>本来用了好久的kali自己笔记本已经配置的比较完美，老项目用的是php5.6。用自己的笔记本，然后各种折腾，结果系统根本不支持php5.6。我的完美系统被搞砸了，熬夜折腾回来一部分，php5.6只好用docker安装。最近离职了，彻底离职了。kali右键不显示中文问题还没解决，今天处理一下。<span id=\"more\"></span></p>\n<p> 根据搜索引擎得到的结果，桌面图标有两种解决方法安装desktop-icons-enhanced或者nemo插件之前用过nemo隐隐约约记得是用nemo解决的。今天就试试。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install nemo</span><br></pre></td></tr></table></figure>\n<p> 安装nemo。然后创建desktop并编辑</p>\n<p> <code>sudo leafpad  ~/.config/autostart/nemo-autostart-with-gnome.desktop</code></p>\n<p>文件中填入</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[Desktop Entry]</span><br><span class=\"line\">Type=Application</span><br><span class=\"line\">Name=Nemo</span><br><span class=\"line\">Comment=Start Nemo desktop at log in</span><br><span class=\"line\">Exec=nemo-desktop</span><br><span class=\"line\">OnlyShowIn=GNOME;</span><br><span class=\"line\">AutostartCondition=GSettings org.nemo.desktop show-desktop-icons</span><br><span class=\"line\">X-GNOME-AutoRestart=true</span><br><span class=\"line\">NoDisplay=true</span><br></pre></td></tr></table></figure>\n<p>保存，退出。<br>注销，重新登录就可以使用中文右键了。</p>\n",
            "tags": [
                "linux",
                "kali右键汉化",
                "kali桌面右键汉化",
                "kali右键创建文件"
            ]
        },
        {
            "id": "https://erik.xyz/2019/05/30/linux-yun-xing-bu-cun-zai-de-bao-cuo-ming-ling/",
            "url": "https://erik.xyz/2019/05/30/linux-yun-xing-bu-cun-zai-de-bao-cuo-ming-ling/",
            "title": "linux运行不存在的命令报错",
            "date_published": "2019-05-30T04:28:00.000Z",
            "content_html": "<h6 id=\"在Linux中运行一个命令尝试是否存在，突然报错了\"><a href=\"#在Linux中运行一个命令尝试是否存在，突然报错了\" class=\"headerlink\" title=\"在Linux中运行一个命令尝试是否存在，突然报错了\"></a><a href=\"#在Linux中运行一个命令尝试是否存在，突然报错了\" title=\"在Linux中运行一个命令尝试是否存在，突然报错了\"></a>在Linux中运行一个命令尝试是否存在，突然报错了</h6><p><img src=\"https://erik.xyz/wp-content/uploads/2019/2019-05-30_09-48.png\" alt=\"\"><br><span id=\"more\"></span>&gt; Could not find the database of available applications, run update-command-not-found as root to fix this</p>\n<blockquote>\n<p>Sorry, command-not-found has crashed! Please file a bug report at:<br><a href=\"http://www.debian.org/Bugs/Reporting\">http://www.debian.org/Bugs/Reporting</a><br>Please include the following information with the report:&gt; command-not-found version: 0.3<br>Python version: 3.7.3 candidate 1<br>Distributor ID:    Kali<br>Description:    Kali GNU/Linux Rolling<br>Release:    2019.2<br>Codename:    n/a<br>Exception information:&gt; local variable ‘cnf’ referenced before assignment<br>Traceback (most recent call last):<br>  File “/usr/share/command-not-found/CommandNotFound/util.py”, line 23, in crash_guard<br>    callback()<br>  File “/usr/lib/command-not-found”, line 93, in main<br>    if not cnf.advise(args[0], options.ignore_installed) and not options.no_failure_msg:<br>UnboundLocalError: local variable ‘cnf’ referenced before assignment&gt; 根据报错提示需要以root用户运行update-commond-not-found&gt; 结果又报错了<br><img src=\"https://erik.xyz/wp-content/uploads/2019/2019-05-30_09-49.png\" alt=\"\">&gt; 根据报错提示执行编辑报错文件<br><img src=\"https://erik.xyz/wp-content/uploads/2019/2019-05-30_09-50_1.png\" alt=\"\">&gt; 打开报错文件找到如图<br><img src=\"https://erik.xyz/wp-content/uploads/2019/2019-05-30_09-51.png\" alt=\"\">&gt; 如有同样报错，继续编辑报错文件，添加所报错的缺失项<br><img src=\"https://erik.xyz/wp-content/uploads/2019/2019-05-30_09-49_1.png\" alt=\"\">&gt; 最后执行自己的测试命令，就不存在错误了<br><img src=\"https://erik.xyz/wp-content/uploads/2019/2019-05-30_09-52.png\" alt=\"\"></p>\n</blockquote>\n",
            "tags": [
                "linux",
                "linux报错",
                "linux中update-command-not-found",
                "linux运行命令报错"
            ]
        },
        {
            "id": "https://erik.xyz/2017/12/01/centos-shang-ru-he-an-zhuang-steam/",
            "url": "https://erik.xyz/2017/12/01/centos-shang-ru-he-an-zhuang-steam/",
            "title": "centos上如何安装steam",
            "date_published": "2017-12-01T13:22:00.000Z",
            "content_html": "<p>最近想把win系统的东西统统转到centos上，偶然发现爱你deepin竟然之steam。去官网查到steam有deb的安装包。 然后就自己尝试把deb转成rpm好像能安装成功就是，总是报错GPU无法渲染，痛苦。<br><img src=\"http://erik.xyz/wp-content/uploads/2017/11/2017-11-25-11-27-46-的屏幕截图.png\" alt=\"\"><br><span id=\"more\"></span>意外的发现steam有一个安装yum支持。 添加安装源 yum-config-manager —add-repo</p>\n<p><img src=\"http://jump.bdimg.com/safecheck/index?url=x+Z5mMbGPAsZOF0aZ3nolIs4smsi7XcaVy9iE2/DAeMYM23XArLL/Pcg4iOwT6wY4qa+xKqX1jFqj6RVAA1ROAXD85Awz94K2uSdvSjzCTeuIai3OgnuzBVWKO/W++3xWZWJPUQllzP0RWHiYm/X80/TKe9kSg+odj2oeHoEzTI=\" alt=\"http://negativo17.org/repos/epel-steam.repo\">  </p>\n<p>执行安装steam yum -y install steam 直接提示报错<br><img src=\"http://erik.xyz/wp-content/uploads/2017/11/2017-11-25-12-47-57-的屏幕截图.png\" alt=\"\"> </p>\n<p>那就去软件仓库搜索一下 <a href=\"https://www.rpmfind.net/linux/rpm2html/search.php?query=libva-intel-driver&amp;submit=Search+...&amp;system=&amp;arch=\">https://www.rpmfind.net/linux/rpm2html/search.php?query=libva-intel-driver&amp;submit=Search+...&amp;system=&amp;arch=</a><br><img src=\"http://erik.xyz/wp-content/uploads/2017/11/2017-11-25-12-52-12-的屏幕截图.png\" alt=\"\"> </p>\n<p>那就wget一下32和64位的，steam只支持32，我系统是64的 wget <a href=\"https://www.rpmfind.net/linux/rpmfusion/free/fedora/releases/27/Everything/x86\\_64/os/Packages/l/libva-intel-driver-1.8.3-2.fc27.i686.rpm\">https://www.rpmfind.net/linux/rpmfusion/free/fedora/releases/27/Everything/x86\\_64/os/Packages/l/libva-intel-driver-1.8.3-2.fc27.i686.rpm</a> wget <a href=\"https://www.rpmfind.net/linux/rpmfusion/free/fedora/releases/27/Everything/x86\\_64/os/Packages/l/libva-intel-driver-1.8.3-2.fc27.x86_64.rpm\">https://www.rpmfind.net/linux/rpmfusion/free/fedora/releases/27/Everything/x86\\_64/os/Packages/l/libva-intel-driver-1.8.3-2.fc27.x86_64.rpm</a> </p>\n<p>然后执行 yum -y install libva-intel-driver*rpm yum -y install steam 安装成功 如果无法启动就执行 rm /usr/lib/libxcb-dri3.so.0<br><img src=\"http://erik.xyz/wp-content/uploads/2017/11/2017-11-25-13-14-03-的屏幕截图.png\" alt=\"\"></p>\n",
            "tags": [
                "centos7安装steam",
                "centos安装steam",
                "centos安装吃鸡steam",
                "linux安装steam",
                "steam安装"
            ]
        },
        {
            "id": "https://erik.xyz/2017/11/25/centos-ru-he-an-zhuang-deb-ruan-jian-bao-yuan-ming-linux-xi-tong-xia-zen-me-yong-checkinstall-cong-yuan-ma-chuang-jian-yi-ge-rpm-huo-deb-bao/",
            "url": "https://erik.xyz/2017/11/25/centos-ru-he-an-zhuang-deb-ruan-jian-bao-yuan-ming-linux-xi-tong-xia-zen-me-yong-checkinstall-cong-yuan-ma-chuang-jian-yi-ge-rpm-huo-deb-bao/",
            "title": "centos如何安装deb软件包/rpm转换成deb(原名：Linux系统下怎么用CheckInstall从源码创建一个RPM或DEB包)",
            "date_published": "2017-11-25T02:38:00.000Z",
            "content_html": "<p>正如我确信，你们一定知道Linux下的多种软件安装方式：使用发行版所提供的包管理系统（<a href=\"http://www.tecmint.com/linux-package-management/\">aptitude，yum，或者zypper</a>，还可以举很多例子），从源码编译（尽管现在很少用了，但在Linux发展早期却是唯一可用的方法），或者使用各自的低级工具dpkg用于.deb，以及rpm用于.rpm，预编译包，如此这般。</p>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/150902085681941.png\" alt=\"Convert RPM to DEB and DEB to RPM\"><br><span id=\"more\"></span><br><em>使用Alien将RPM转换成DEB以及将DEB转换成RPM</em></p>\n<p>在本文中，我们将为你介绍alien，一个用于在各种不同的Linux包格式相互转换的工具，其最常见的用法是将.rpm转换成.deb（或者反过来）。 如果你需要某个特定类型的包，而你只能找到其它格式的包的时候，该工具迟早能派得上用场——即使是其作者不再维护，并且在其网站声明：alien将可能永远维持在实验状态。 例如，有一次，我正查找一个用于喷墨打印机的.deb驱动，但是却没有找到——生产厂家只提供.rpm包，这时候alien拯救了我。我安装了alien，将包进行转换，不久之后我就可以使用我的打印机了，没有任何问题。 即便如此，我们也必须澄清一下，这个工具不应当用来转换重要的系统文件和库，因为它们在不同的发行版中有不同的配置。只有在前面说的那种情况下所建议的安装方法根本不适合时，alien才能作为最后手段使用。 最后一项要点是，我们必须注意，虽然我们在本文中使用<a href=\"http://www.linuxidc.com/topicnews.aspx?tid=14\" title=\"CentOS\">CentOS</a>和Debian，除了前两个发行版及其各自的家族体系外，据我们所知，alien可以工作在Slackware中，甚至Solaris中。  </p>\n<h4 id=\"步骤1：安装Alien及其依赖包\"><a href=\"#步骤1：安装Alien及其依赖包\" class=\"headerlink\" title=\"步骤1：安装Alien及其依赖包\"></a>步骤1：安装Alien及其依赖包</h4><p>要安装alien到CentOS/RHEL 7中，你需要启用EPEL和Nux Dextop（是的，是Dextop——不是Desktop）仓库，顺序如下：</p>\n<ol>\n<li><code># yum install epel-release</code></li>\n</ol>\n<p>启用Nux Dextop仓库的包的当前最新版本是0.5（2015年8月10日发布），在安装之前你可以查看<a href=\"http://li.nux.ro/download/nux/dextop/el7/x86_64/\">http://li.nux.ro/download/nux/dextop/el7/x86_64/</a>上是否有更新的版本。</p>\n<ol>\n<li><code># rpm --import http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro</code></li>\n<li><code># rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm</code></li>\n</ol>\n<p>然后再做，</p>\n<ol>\n<li><code># yum update &amp;&amp; yum install alien</code></li>\n</ol>\n<p>在<a href=\"http://www.linuxidc.com/topicnews.aspx?tid=5\" title=\"Fedora\">Fedora</a>中，你只需要运行上面的命令即可。 在Debian及其衍生版中，只需要：</p>\n<ol>\n<li><code># aptitude install alien</code></li>\n</ol>\n<h4 id=\"步骤2：将-deb转换成-rpm包\"><a href=\"#步骤2：将-deb转换成-rpm包\" class=\"headerlink\" title=\"步骤2：将.deb转换成.rpm包\"></a>步骤2：将.deb转换成.rpm包</h4><p>对于本次测试，我们选择了date工具，它提供了一系列日期和时间工具用于处理大量金融数据。我们将下载.deb包到我们的CentOS 7机器中，将它转换成.rpm并安装：</p>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/150902085681942.png\" alt=\"Check CentOS Version\"></p>\n<p><em>Check CentOS Version</em></p>\n<p>检查CentOS版本</p>\n<ol>\n<li><code># cat /etc/centos-release</code></li>\n<li><code># wget http://ftp.us.debian.org/debian/pool/main/d/dateutils/dateutils_0.3.1-1.1_amd64.deb</code></li>\n<li><code># alien --to-rpm --scripts dateutils_0.3.1-1.1_amd64.deb</code></li>\n</ol>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/150902085681943.png\" alt=\"Convert .deb to .rpm package in Linux\"></p>\n<p><em>在Linux中将.deb转换成.rpm</em></p>\n<p><strong>重要</strong>：（请注意alien是怎样来增加目标包的次版本号的。如果你想要无视该行为，请添加-keep-version标识）。 如果我们尝试马上安装该包，我们将碰到些许问题：</p>\n<ol>\n<li><code># rpm -Uvh dateutils-0.3.1-2.1.x86_64.rpm</code></li>\n</ol>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/150902085681945.png\" alt=\"Install RPM Package\"></p>\n<p><em>安装RPM包</em></p>\n<p>要解决该问题，我们需要启用epel-testing仓库，然后安装rpmbuild工具来编辑该包的配置以重建包：</p>\n<ol>\n<li><code># yum --enablerepo=epel-testing install rpmrebuild</code></li>\n</ol>\n<p>然后运行，</p>\n<ol>\n<li><code># rpmrebuild -pe dateutils-0.3.1-2.1.x86_64.rpm</code></li>\n</ol>\n<p>它会打开你的默认文本编辑器。请转到<code>%files</code>章节并删除涉及到错误信息中提到的目录的行，然后保存文件并退出：</p>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/150902085681944.png\" alt=\"Convert .deb to Alien Version\"></p>\n<p><em>转换.deb到Alien版</em></p>\n<p>但你退出该文件后，将提示你继续去重构。如果你选择“Y”，该文件会重构到指定的目录（与当前工作目录不同）：</p>\n<ol>\n<li><code># rpmrebuild –pe dateutils-0.3.1-2.1.x86_64.rpm</code></li>\n</ol>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/150902085681946.png\" alt=\"Build RPM Package\"></p>\n<p><em>构建RPM包</em></p>\n<p>现在你可以像以往一样继续来安装包并验证：</p>\n<ol>\n<li><code># rpm -Uvh /root/rpmbuild/RPMS/x86_64/dateutils-0.3.1-2.1.x86_64.rpm</code></li>\n<li><code># rpm -qa | grep dateutils</code></li>\n</ol>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/150902085681947.png\" alt=\"Install Build RPM Package\"></p>\n<p><em>安装构建RPM包</em></p>\n<p>最后，你可以列出date工具包含的各个工具，也可以查看各自的手册页：</p>\n<ol>\n<li><code># ls -l /usr/bin | grep dateutils</code></li>\n</ol>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/150902085681948.png\" alt=\"Verify Installed RPM Package\"></p>\n<p><em>验证安装的RPM包</em></p>\n<h4 id=\"步骤3：将-rpm转换成-deb包\"><a href=\"#步骤3：将-rpm转换成-deb包\" class=\"headerlink\" title=\"步骤3：将.rpm转换成.deb包\"></a>步骤3：将.rpm转换成.deb包</h4><p>在本节中，我们将演示如何将.rpm转换成.deb。在一台32位的Debian Wheezy机器中，让我们从CentOS 6操作系统仓库中下载用于zsh shell的.rpm包。注意，该shell在Debian及其衍生版的默认安装中是不可用的。</p>\n<ol>\n<li><code># cat /etc/shells</code></li>\n<li><code># lsb_release -a | tail -n 4</code></li>\n</ol>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/150902085681949.png\" alt=\"Check Shell and Debian OS Version\"></p>\n<p><em>检查Shell和Debian操作系统版本</em></p>\n<ol>\n<li><code># wget http://mirror.centos.org/centos/6/os/i386/Packages/zsh-4.3.11-4.el6.centos.i686.rpm</code></li>\n<li><code># alien --to-deb --scripts zsh-4.3.11-4.el6.centos.i686.rpm</code></li>\n</ol>\n<p>你可以安全地无视关于签名丢失的信息：</p>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/1509020856819410.png\" alt=\"Convert .rpm to .deb Package\"></p>\n<p><em>将.rpm转换成.deb包</em></p>\n<p>过了一会儿后，.deb包应该已经生成，并可以安装了：</p>\n<ol>\n<li><code># dpkg -i zsh_4.3.11-5_i386.deb</code></li>\n</ol>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/1509020856819412.png\" alt=\"Install RPM Converted Deb Package\"></p>\n<p><em>安装RPM转换来的Deb包</em></p>\n<p>安装完后，你看看可以zsh是否添加到了合法shell列表中：</p>\n<ol>\n<li><code># cat /etc/shells</code></li>\n</ol>\n<p><img src=\"http://www.linuxidc.com/upload/2015_09/1509020856819411.png\" alt=\"Confirm Installed Zsh Package\"></p>\n<p><em>确认安装的Zsh包</em></p>\n<p>转载：<a href=\"http://www.linuxidc.com/Linux/2015-09/122573.htm\">http://www.linuxidc.com/Linux/2015-09/122573.htm</a> 本文地址：<a href=\"http://erik.xyz/?p=1398\">http://erik.xyz/?p=1398</a></p>\n",
            "tags": [
                "centos",
                "deb",
                "deb/rpm互转",
                "deb转rpm",
                "rpm互转"
            ]
        },
        {
            "id": "https://erik.xyz/2017/11/24/centos7-an-zhuang-redis-desktop-manager-de-yi-bo-san-zhe/",
            "url": "https://erik.xyz/2017/11/24/centos7-an-zhuang-redis-desktop-manager-de-yi-bo-san-zhe/",
            "title": "centos7安装Redis Desktop Manager的一波三折",
            "date_published": "2017-11-24T13:21:00.000Z",
            "content_html": "<p>一波三折的centos7安装redis desktop 根据官方reids桌面去github下载对应的编译包，然而根目录下3rdparty好多空的文件夹，只好去git上一一对应下载 cd ./src ./configure 后会提示执行 qmake-qt5 如果你直接执行就会报错，找不到命令。与编译已经安装了，没有启用全局命令，你得到安装目录下执行。 例如我的 /usr/lib64/qt5/bin/qmake-qt5 然后执行 make 如果报错cahrts不存在就安装qtcharts<br><span id=\"more\"></span></p>\n<p>git clone <a href=\"https://github.com/erikaaron/qtcharts\">https://github.com/erikaaron/qtcharts</a></p>\n<p>cd qtcharts</p>\n<p><strong>git checkout</strong> <strong>5.7</strong></p>\n<p>qmake</p>\n<p>make</p>\n<p>sudo make install</p>\n<p>报错不存在 third_party/lss/linux_syscall_support.h<br><img src=\"http://erik.xyz/wp-content/uploads/2017/11/linux_syscall_support.png\" alt=\"\"> </p>\n<p>google搜索后找到这里<a href=\"https://chromium.googlesource.com/chromiumos/platform/google-breakpad/+/0.11.241.B/src/third\\_party/lss/linux\\_syscall_support.h\">https://chromium.googlesource.com/chromiumos/platform/google-breakpad/+/0.11.241.B/src/third\\_party/lss/linux\\_syscall_support.h</a> 直接提供了，复制下来本地目录创建相应文件报存。 执行 make clean &amp;&amp; make 又报错了 3rdparty/gbreakpad/src/client/linux/libbreakpad_client.a 文件找不到。<br><img src=\"http://erik.xyz/wp-content/uploads/2017/11/libbreakpad_client.a.png\" alt=\"\"> </p>\n<p>google搜索给出的方法是下载google-break包然后编译生成，搞了好久没弄成，感觉那里不对阿。 看看搜索结果好多说是编译break的 直接去3rdparty/gbreakpad  执行 ./configure &amp;&amp; make &amp;&amp; make install 然后 libbreakpad_client.a就出来了 在回到根文件下的src 执行 make clean &amp;&amp; make make 成功后会提示 make isntall 要指定那个目录<br><img src=\"http://erik.xyz/wp-content/uploads/2017/11/2017-11-23-14-54-17-的屏幕截图.png\" alt=\"\"> </p>\n<p>例如我的 make install -m 755 -p /home/linux/rdm/src/resources/qt.conf /usr/share/redis-desktop-manager/bin/ cd /usr/share/redis-desktop-manager/bin sudo mv qt.conf qt.backup 到此大功告成。<br><img src=\"http://erik.xyz/wp-content/uploads/2017/11/wc.png\" alt=\"\"> </p>\n<p>最新版更新处理源码  <a href=\"https://github.com/erikaaron/redis\\_desktop\\_manager\">https://github.com/erikaaron/redis\\_desktop\\_manager</a></p>\n",
            "tags": [
                "centos7安装Redis Desktop Manager",
                "centos7安装redis桌面",
                "centos安装redis桌面",
                "linux安装centos7安装Redis Desktop Manager",
                "Redis Desktop Manager",
                "redis桌面"
            ]
        },
        {
            "id": "https://erik.xyz/2017/09/29/wget-zhua-qu-wang-zhan/",
            "url": "https://erik.xyz/2017/09/29/wget-zhua-qu-wang-zhan/",
            "title": "wget抓取网站",
            "date_published": "2017-09-29T13:23:00.000Z",
            "content_html": "<p>最近需要套个模板，当然模板不需去购买。那就抓取一个，百度一下发现wget是个不错的用法。<br>wget -r -p -np -k  <a href=\"https://erik.xyz\">https://erik.xyz</a>   就可抓取整个站点模板到本地。</p>\n<p>然后打包压缩，拷贝到win电脑就可以修修改改。<br>顺便查查wget使用方法<br>-a&lt;日志文件&gt;：在指定的日志文件中记录资料的执行过程；</p>\n<p>-A&lt;后缀名&gt;：指定要下载文件的后缀名，多个后缀名之间使用逗号进行分隔； </p>\n<p>-b：进行后台的方式运行wget； <span id=\"more\"></span></p>\n<p>-B&lt;连接地址&gt;：设置参考的连接地址的基地地址； </p>\n<p>-c：继续执行上次终端的任务；</p>\n<p>-C&lt;标志&gt;：设置服务器数据块功能标志on为激活，off为关闭，默认值为on； </p>\n<p>-d：调试模式运行指令； </p>\n<p>-D&lt;域名列表&gt;：设置顺着的域名列表，域名之间用“，”分隔； </p>\n<p>-e&lt;指令&gt;：作为文件“.wgetrc”中的一部分执行指定的指令； </p>\n<p>-h：显示指令帮助信息；</p>\n<p>-i&lt;文件&gt;：从指定文件获取要下载的URL地址；</p>\n<p>-l&lt;目录列表&gt;：设置顺着的目录列表，多个目录用“，”分隔； </p>\n<p>-L：仅顺着关联的连接； </p>\n<p>-r：递归下载方式；</p>\n<p>-nc：文件存在时，下载文件不覆盖原有文件；</p>\n<p>-nv：下载时只显示更新和出错信息，不显示指令的详细执行过程； </p>\n<p>-q：不显示指令执行过程； </p>\n<p>-nh：不查询主机名称； </p>\n<p>-v：显示详细执行过程； </p>\n<p>-V：显示版本信息； </p>\n<p>—passive-ftp：使用被动模式PASV连接FTP服务器； </p>\n<p>—follow-ftp：从HTML文件中下载FTP连接文件。</p>\n",
            "tags": [
                "wget",
                "wget抓取",
                "网站抓取"
            ]
        },
        {
            "id": "https://erik.xyz/2017/06/29/hadoop2-8-0-de-bu-shu-an-zhuang-jiao-cheng/",
            "url": "https://erik.xyz/2017/06/29/hadoop2-8-0-de-bu-shu-an-zhuang-jiao-cheng/",
            "title": "hadoop2.8.0的部署安装教程",
            "date_published": "2017-06-29T00:27:00.000Z",
            "content_html": "<p>Hadoop部署准备 本地vmware安装 Linux系统家族中 centos7 下载地址<a href=\"http://101.110.118.58/isoredirect.centos.org/centos/7/isos/x86\\_64/CentOS-7-x86\\_64-Minimal-1611.iso\">http://101.110.118.58/isoredirect.centos.org/centos/7/isos/x86\\_64/CentOS-7-x86\\_64-Minimal-1611.iso</a>   Java对应版本1.8.0_121   Hadoop版本2.8.0下载地址 <a href=\"http://mirror.bit.edu.cn/apache/hadoop/common/\">http://mirror.bit.edu.cn/apache/hadoop/common/</a> 可以根据自己喜好的版本下载</p>\n<h1 id=\"1-基本配置\"><a href=\"#1-基本配置\" class=\"headerlink\" title=\"1.基本配置\"></a>1.基本配置</h1><p>首先安装一个centos7并配置好java Java环境配置 我的java安装地址 /usr/java/ jdk1.8.0_121   编辑java环境 vi ~/.bash_profile 添加或修改 export JAVA_HOME=/usr/java/jdk1.8.0_121 export PATH=$JAVA_HOME/bin:$PATH 执行 . ~/.bash_profile 使变量生效  <span id=\"more\"></span></p>\n<h1 id=\"2-ssh配置\"><a href=\"#2-ssh配置\" class=\"headerlink\" title=\"2.ssh配置\"></a>2.ssh配置</h1><p>先 yum install ssh  安装   然后执行 ssh-keygen -t dsa -P ‘’ -f ~/.ssh/id_dsa 生成密匙</p>\n<h1 id=\"3-hadoop配置\"><a href=\"#3-hadoop配置\" class=\"headerlink\" title=\"3.hadoop配置\"></a>3.hadoop配置</h1><p>把下载好的hadoop解压出来。（我的地址在/roo目录,即完整地址/root/hadoop）   配置环境变量 vi ~/.bash_profile export HADOOP_HOME=/root/hadoop export PATH=$JAVA_HOME/bin:$PATH:$HOME/bin:$HADOOP_HOME/bin 执行 . ~/.bash_profile 使变量生效  </p>\n<h1 id=\"4-hadoop文件配置\"><a href=\"#4-hadoop文件配置\" class=\"headerlink\" title=\"4.hadoop文件配置\"></a>4.hadoop文件配置</h1><p>首先给本机命名个名字：例如我这边是s204   就执行 hostnamectl set-hostname s204 变更主机名字   然后在/root/hadoop目录下 依次执行编辑</p>\n<h2 id=\"vim-etc-hadoop-core-site-xml\"><a href=\"#vim-etc-hadoop-core-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/core-site.xml\"></a>vim etc/hadoop/core-site.xml</h2><p>  在<configuration></configuration>中加入 <property> <name>fs.defaultFS</name> <value>hdfs://s204:9000</value> </property> <property> <name>hadoop.tmp.dir</name> <value>file:/root/hadoop/tmp</value> </property> <property> <name>io.file.buffer.size</name> <value>131702</value> </property> <property> <name>hadoop.proxyuser.hadoop.hosts</name> <value>*</value> </property>   <property> <name>hadoop.proxyuser.hadoop.groups</name> <value>*</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-hdfs-site-xml\"><a href=\"#vim-etc-hadoop-hdfs-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/hdfs-site.xml\"></a>vim etc/hadoop/hdfs-site.xml</h2><p>在<configuration></configuration>中加入   <property> <name>dfs.namenode.name.dir</name> <value>file:/root/hadoop/hdfs/name</value> </property> <property> <name>dfs.datanode.data.dir</name> <value>file:/root/hadoop/hdfs/data</value> </property> <property> <name>dfs.replication</name> <value>3</value> </property> <property> <name>dfs.namenode.secondary.http-address</name> <value>s204:9001</value> </property> <property> <name>dfs.webhdfs.enabled</name> <value>true</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-mapred-site-xml\"><a href=\"#vim-etc-hadoop-mapred-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/mapred-site.xml\"></a>vim etc/hadoop/mapred-site.xml</h2><p>在<configuration></configuration>中加入   <property> <name>mapreduce.framework.name</name> <value>yarn</value> </property> <property> <name>mapreduce.jobhistory.address</name> <value>s204:10020</value> </property> <property> <name>mapreduce.jobhistory.webapp.address</name> <value>s204:19888</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-yarn-site-xml\"><a href=\"#vim-etc-hadoop-yarn-site-xml\" class=\"headerlink\" title=\"vim etc/hadoop/yarn-site.xml\"></a>vim etc/hadoop/yarn-site.xml</h2><p>在<configuration></configuration>中加入 <property> <name>yarn.nodemanager.aux-services</name> <value>mapreduce_shuffle</value> </property> <property> <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name> <value>org.apache.hadoop.mapred.ShuffleHandler</value> </property> <property> <name>yarn.resourcemanager.address</name> <value>s204:8032</value> </property> <property> <name>yarn.resourcemanager.scheduler.address</name> <value>s204:8030</value> </property> <property> <name>yarn.resourcemanager.resource-tracker.address</name> <value>s204:8031</value> </property> <property> <name>yarn.resourcemanager.admin.address</name> <value>s204:8033</value> </property> <property> <name>yarn.resourcemanager.webapp.address</name> <value>s204:8088</value> </property> <property> <name>yarn.nodemanager.resource.memory-mb</name> <value>6078</value> </property>  </p>\n<h2 id=\"vim-etc-hadoop-yarn-env-sh\"><a href=\"#vim-etc-hadoop-yarn-env-sh\" class=\"headerlink\" title=\"vim etc/hadoop/yarn-env.sh\"></a>vim etc/hadoop/yarn-env.sh</h2><p>  中找到 export JAVA_HOME 去掉注释 编辑java地址 export JAVA_HOME=/usr/java/jdk1.8.0_121   找到JAVA_HEAP_MAX=-Xmx1000m 改为 JAVA_HEAP_MAX=-Xmx1024m  </p>\n<h2 id=\"vim-etc-hadoop-slaves\"><a href=\"#vim-etc-hadoop-slaves\" class=\"headerlink\" title=\"vim etc/hadoop/slaves\"></a>vim etc/hadoop/slaves</h2><p>  清空添加 s204    </p>\n<h1 id=\"网络配置\"><a href=\"#网络配置\" class=\"headerlink\" title=\"网络配置\"></a>网络配置</h1><p>我这ip是 192.168.5.9   编辑网络固定ip vim /etc/sysconfig/network-scripts/ifcfg-ens33   指定固定ip   TYPE=”Ethernet” #BOOTPROTO=”dhcp” DEFROUTE=”yes” PEERDNS=”yes” PEERROUTES=”yes” IPV4_FAILURE_FATAL=”no” IPV6INIT=”yes” IPV6_AUTOCONF=”yes” IPV6_DEFROUTE=”yes” IPV6_PEERDNS=”yes” IPV6_PEERROUTES=”yes” IPV6_FAILURE_FATAL=”no” IPV6_ADDR_GEN_MODE=”stable-privacy” NAME=”ens33” UUID=”b9fe1e5c-be20-47f1-a2d3-e12f5ddb6aa1” DEVICE=”ens33” ONBOOT=”yes” IPADDR0=192.168.5.9 PREFIX0=24 GATEWAY0=192.168.5.2 DNS1=114.114.114.114   然后重启网络 systemctl  restart  network   执行 ip add  查看网络ip是否和设定的一致  </p>\n<h1 id=\"Hadopp启动\"><a href=\"#Hadopp启动\" class=\"headerlink\" title=\"Hadopp启动\"></a>Hadopp启动</h1><p>  进入/root/hadoop目录   执行编译 ./bin/hdfs namenode –format   结果倒数第五行出现 Exiting with status 0 则为成功   然后启动 ./sbin/start-all.sh   启动完毕执行./bin/hdfs dfsadmin –report 查看是否有节点 如果返回 无法连接则为启动失败   执行systemctl stop firewalld.service关闭防火墙  在浏览器输入s204:8088则可以看到hadoop界面  </p>\n<h1 id=\"其他节点配置\"><a href=\"#其他节点配置\" class=\"headerlink\" title=\"其他节点配置\"></a>其他节点配置</h1><p>以上配置完毕后，关闭centos7 然后完全克隆，在新克隆的系统中，更改ip地址和主机名 其中hadoop配置文件 etc/hadoop/hdfs-site.xml  中 <property> <name>dfs.datanode.data.dir</name> <value>file:/root/hadoop/hdfs/data</value> </property>   的file地址不能一样。 我这边三个地址分别为 file:/root/hadoop/hdfs/data file:/root/hadoop/hdfs/data/205 file:/root/hadoop/hdfs/data/206   克隆完毕，配置文件和ip、主机名修改好后。在s204机器中编辑 vim etc/hadoop/slaves 加入 s205 s206   复制ssh令牌免密登录 例如复制到s205 scp ~/.ssh/authorized_keys root@s205:~/.ssh/   其他另个机器也一样操作   另外几个机器也要编译一下   然后在s204停止hadoop   ./sbin/stop-all.sh   再次启动./sbin/start-all.sh   在浏览器就可以看到三个节点。</p>\n",
            "tags": [
                "hadoop",
                "hadoop2.8.0",
                "hadoop安装教程",
                "hadoop安装详细教程",
                "hadoop教程",
                "hadoop部署"
            ]
        }
    ]
}